{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoFPr16YTLRr"
      },
      "source": [
        "#Data Import\n"
      ],
      "id": "SoFPr16YTLRr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83645d8b-566f-4056-89f7-e388a59e577a"
      },
      "outputs": [],
      "source": [
        "!pip install -q import_ipynb\n",
        "!pip install -q tensorflow_addons\n",
        "from google.colab import drive\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras.layers import Input, Conv1D, ReLU, BatchNormalization,\\\n",
        "                                    Add, AveragePooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.size'] = '14'\n",
        "\n",
        "import import_ipynb\n",
        "from Analysis_branch import AnalysisBranch1D\n",
        "from Synthesis_Branch import SynthesisBranch1D\n",
        "from Summing_unit_for_synthesis import Add1D\n",
        "from Pywavelets import ImpulseRespones2BPRFB\n",
        "#from Trainable_1D_Conv import Conv1DBNMish"
      ],
      "id": "83645d8b-566f-4056-89f7-e388a59e577a"
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Activation\n",
        "from keras.applications.efficientnet import EfficientNetB3\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Flatten, Dropout\n",
        "from keras.callbacks import History \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ],
      "metadata": {
        "id": "ak_uoksKuxDn"
      },
      "id": "ak_uoksKuxDn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6Ax5zdXMklu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "W6Ax5zdXMklu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-dk5R_QTQJd"
      },
      "outputs": [],
      "source": [
        "\n",
        "training_data = pd.read_csv (r'training.csv')\n",
        "testing_data = pd.read_csv(r'testing.csv')\n"
      ],
      "id": "U-dk5R_QTQJd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbjdIYmFMZYf"
      },
      "source": [
        "# Data Preprocessing"
      ],
      "id": "fbjdIYmFMZYf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebwDaBY0lG72"
      },
      "outputs": [],
      "source": [
        "\n",
        "training_data = pd.read_csv (r'training.csv')\n",
        "testing_data = pd.read_csv(r'testing.csv')\n",
        "\n",
        "training_data = training_data[training_data[\"Temp\"].str.contains(\"  NaN\") == False]\n",
        "\n",
        "testing_data = testing_data[testing_data[\"Temp\"].str.contains(\"  NaN\") == False]\n",
        "testing_data = testing_data[testing_data[\"RH\"].str.contains(\"  NaN\") == False]\n",
        "\n",
        "# removing the date column\n",
        "training_data = training_data.iloc[: , 1:]\n",
        "training_data = training_data.dropna()\n",
        "\n",
        "testing_data = testing_data.iloc[: , 1:]\n",
        "testing_data = testing_data.dropna()\n",
        "\n",
        "# keeping the height and channels in x_train \n",
        "x_train = training_data.iloc[: , :23]\n",
        "x_train = x_train.reset_index()\n",
        "x_train = x_train.drop(columns=['index'])\n",
        "\n",
        "# keeping the weather parameters in y_train\n",
        "y_train = training_data.iloc[: , 23:]\n",
        "y_train = y_train.reset_index()\n",
        "y_train = y_train.drop(columns=['index'])\n",
        "\n",
        "\n",
        "# repeating same steps for test data\n",
        "x_test = testing_data.iloc[: , :23]\n",
        "x_test = x_test.reset_index()\n",
        "x_test = x_test.drop(columns=['index'])\n",
        "\n",
        "\n",
        "y_test = testing_data.iloc[: , 23:]\n",
        "y_test = y_test.reset_index()\n",
        "y_test = y_test.drop(columns=['index'])\n",
        "\n"
      ],
      "id": "ebwDaBY0lG72"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tlw4Fnvf61yN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# changing from pandas to numpy and dropping columns with NaN values\n",
        "x_train = x_train.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "indexList = [np.any(i) for i in np.isnan(x_train)]\n",
        "x_train = np.delete(x_train, indexList, axis=0)\n",
        "\n",
        "x_test = x_test.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "indexList = [np.any(i) for i in np.isnan(x_test)]\n",
        "x_test = np.delete(x_test, indexList, axis=0)"
      ],
      "id": "Tlw4Fnvf61yN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5_8iwwIlVHN"
      },
      "outputs": [],
      "source": [
        "# converting all values in array to float\n",
        "x_train = x_train.astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "\n"
      ],
      "id": "K5_8iwwIlVHN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RippOHN-lc9y",
        "outputId": "51451d55-0023-445e-ee00-e5c890c295bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9389, 23)\n",
            "(9389, 3)\n",
            "(4258, 23)\n",
            "(4258, 3)\n"
          ]
        }
      ],
      "source": [
        "# the shape of all arrays can be now visualised\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "id": "RippOHN-lc9y"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7fc2dI62df7"
      },
      "source": [
        "# Model Creation"
      ],
      "id": "f7fc2dI62df7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bD0KKoRfZXSX"
      },
      "outputs": [],
      "source": [
        "err = lambda xn, xn_hat:np.round(np.sum(abs((xn-xn_hat.T)[0]/xn))/len(xn) * 100,5)\n",
        "global h0n, h1n, g0n, g1n\n",
        "\n",
        "\n",
        "mother_wavelet = 'coif1'  # <<----\n",
        "\n",
        "w = ImpulseRespones2BPRFB(mother_wavelet)\n",
        "h0n, h1n = w.analysis()\n",
        "g0n, g1n = w.synthesis()\n",
        "\n",
        "filt_len = len(h0n)\n",
        "del w"
      ],
      "id": "bD0KKoRfZXSX"
    },
    {
      "cell_type": "code",
      "source": [
        "# define system parameters\n",
        "lr = 10e-4\n",
        "input_shape = 23,1\n",
        "bs = 300\n",
        "num_epochs = 1000\n",
        "val_split = 0.10\n"
      ],
      "metadata": {
        "id": "GFb9ZeRIvBFz"
      },
      "id": "GFb9ZeRIvBFz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the input layer\n",
        "inputs = Input(input_shape)\n",
        "\n",
        "# Define the encoder layers\n",
        "encoder_block1 = layers.MultiHeadAttention(num_heads=18, key_dim=64, dropout=0.1)\n",
        "encoder_block2 = layers.MultiHeadAttention(num_heads=8, key_dim=64, dropout=0.3)\n",
        "encoder_block3 = layers.MultiHeadAttention(num_heads=8, key_dim=64, dropout=0.3)\n",
        "encoder_dense = layers.Dense(32, activation=lambda x: tfa.activations.mish(x))\n",
        "\n",
        "# Define the decoder layers\n",
        "decoder_block1 = layers.MultiHeadAttention(num_heads=18, key_dim=64, dropout=0.1)\n",
        "decoder_block2 = layers.MultiHeadAttention(num_heads=8, key_dim=64, dropout=0.2)\n",
        "decoder_block3 = layers.MultiHeadAttention(num_heads=8, key_dim=64, dropout=0.3)\n",
        "decoder_dense = layers.Dense(1, activation=lambda x: tfa.activations.mish(x))\n",
        "\n",
        "# Encode the input sequence\n",
        "encoded = encoder_block1(inputs, inputs)\n",
        "encoded = encoder_block2(encoded, encoded)\n",
        "encoded = encoder_block3(encoded, encoded)\n",
        "encoded = encoder_dense(encoded)\n",
        "\n",
        "# Decode the hidden representation\n",
        "decoded = decoder_block1(encoded, encoded)\n",
        "decoded = decoder_block2(decoded, encoded)\n",
        "decoded = decoder_block3(decoded, encoded)\n",
        "decoded = decoder_dense(decoded)\n",
        "# output=Flatten()(decoded)\n",
        "# output=Dense(1)(output)\n",
        "\n",
        "# Define the model\n",
        "model = keras.Model(inputs=inputs, outputs=decoded)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=\"MeanSquaredError\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ajUPJOLbZww0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38fc9b59-40d3-46aa-8ef0-ef383764fe9a"
      },
      "id": "ajUPJOLbZww0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None, 23, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " multi_head_attention_26 (Multi  (None, 23, 1)       8065        ['input_12[0][0]',               \n",
            " HeadAttention)                                                   'input_12[0][0]']               \n",
            "                                                                                                  \n",
            " multi_head_attention_27 (Multi  (None, 23, 1)       3585        ['multi_head_attention_26[0][0]',\n",
            " HeadAttention)                                                   'multi_head_attention_26[0][0]']\n",
            "                                                                                                  \n",
            " multi_head_attention_28 (Multi  (None, 23, 1)       3585        ['multi_head_attention_27[0][0]',\n",
            " HeadAttention)                                                   'multi_head_attention_27[0][0]']\n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 23, 32)       64          ['multi_head_attention_28[0][0]']\n",
            "                                                                                                  \n",
            " multi_head_attention_29 (Multi  (None, 23, 32)      150944      ['dense_10[0][0]',               \n",
            " HeadAttention)                                                   'dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " multi_head_attention_30 (Multi  (None, 23, 32)      67104       ['multi_head_attention_29[0][0]',\n",
            " HeadAttention)                                                   'dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " multi_head_attention_31 (Multi  (None, 23, 32)      67104       ['multi_head_attention_30[0][0]',\n",
            " HeadAttention)                                                   'dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 23, 1)        33          ['multi_head_attention_31[0][0]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 300,484\n",
            "Trainable params: 300,484\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-J0kvt35Dn8"
      },
      "outputs": [],
      "source": [
        "encoder_block1 = layers.MultiHeadAttention(num_heads=18, key_dim=64, dropout=0.1)\n",
        "decoder_block1 = layers.MultiHeadAttention(num_heads=18, key_dim=64, dropout=0.1)\n",
        "\n",
        "\n",
        "lstm1 = tf.keras.layers.LSTM(50,return_sequences=True)\n",
        "lstm2 = tf.keras.layers.LSTM(50,return_sequences=True)\n",
        "gru = tf.keras.layers.GRU(50,return_sequences=True)\n",
        "\n",
        "\n",
        "def Conv1Duser(inputs:tf) -> tf:\n",
        "    cnn_layer = tf.keras.layers.Conv1D(filters=1,kernel_size=30,padding='same')\n",
        "    inputs = cnn_layer(inputs)\n",
        "    x = BatchNormalization()(inputs)\n",
        "    return tfa.activations.mish(x)\n",
        "\n",
        "def Conv1Duser_2(inputs:tf) -> tf:\n",
        "    cnn_layer = tf.keras.layers.Conv1D(filters=1,kernel_size=25,padding='same')\n",
        "    inputs = cnn_layer(inputs)\n",
        "    x = BatchNormalization()(inputs)\n",
        "    return tfa.activations.mish(x)\n",
        "\n",
        "def dwt_2BPRFB(input_shape:tuple):\n",
        "    \n",
        "    global h0n, h1n, g0n, g1n\n",
        "\n",
        "    inputs = Input(input_shape)\n",
        "    inputs = encoder_block1(inputs, inputs)\n",
        "\n",
        "    ##Analysis FB\n",
        "    Ψ1 = AnalysisBranch1D(h1n)(inputs)\n",
        "    ϕ1 = AnalysisBranch1D(h0n)(inputs)\n",
        "    \n",
        "    T1 = lstm1(ϕ1)\n",
        "    \n",
        "    #T1=Conv1Duser(ϕ1)\n",
        "    T1 = gru(T1)\n",
        "    T1 = lstm1(ϕ1)\n",
        "    Temp=tf.concat([T1,Ψ1],2)\n",
        "  \n",
        "    #T2=Conv1Duser(Temp)\n",
        "    T2 = lstm2(Temp)\n",
        "    T2 = lstm2(Temp)\n",
        "\n",
        "\n",
        "    #T2=Conv1Duser(Ψ1)\n",
        "    Temp2=tf.concat([T1,T2],2)\n",
        "\n",
        "    output=Conv1Duser_2(Temp2)\n",
        "    output = decoder_block1(output,output)\n",
        "    output=Flatten()(output)\n",
        "    output=Dense(1)(output)\n",
        "\n",
        "    ##Synthesis FB\n",
        "    #p_part1 = SynthesisBranch1D(g1n)(T2)\n",
        "    #p_part2 = SynthesisBranch1D(g0n)(T1)\n",
        "    #output = Add1D(g0n)([p_part1, p_part2])\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "id": "q-J0kvt35Dn8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvCS7kUR1nUr",
        "outputId": "7d83ed52-ba81-4b7e-99de-ca8536622bd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_22 (InputLayer)          [(None, 23, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " analysis_branch1d_17 (Analysis  (None, 14, 1)       7           ['input_22[0][0]']               \n",
            " Branch1D)                                                                                        \n",
            "                                                                                                  \n",
            " lstm_16 (LSTM)                 (None, 14, 50)       10400       ['analysis_branch1d_17[1][0]']   \n",
            "                                                                                                  \n",
            " analysis_branch1d_16 (Analysis  (None, 14, 1)       7           ['input_22[0][0]']               \n",
            " Branch1D)                                                                                        \n",
            "                                                                                                  \n",
            " tf.concat_16 (TFOpLambda)      (None, 14, 51)       0           ['lstm_16[2][0]',                \n",
            "                                                                  'analysis_branch1d_16[1][0]']   \n",
            "                                                                                                  \n",
            " lstm_17 (LSTM)                 (None, 14, 50)       20400       ['tf.concat_16[1][0]']           \n",
            "                                                                                                  \n",
            " tf.concat_17 (TFOpLambda)      (None, 14, 100)      0           ['lstm_16[2][0]',                \n",
            "                                                                  'lstm_17[2][0]']                \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 14, 1)        2501        ['tf.concat_17[1][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 14, 1)       4           ['conv1d_8[1][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_8 (TFOpLa  (None, 14, 1)       0           ['batch_normalization_8[1][0]']  \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.softplus_8 (TFOpLambda  (None, 14, 1)       0           ['tf.convert_to_tensor_8[1][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_8 (TFOpLambda)    (None, 14, 1)        0           ['tf.math.softplus_8[1][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply_8 (TFOpLambda  (None, 14, 1)       0           ['tf.convert_to_tensor_8[1][0]', \n",
            " )                                                                'tf.math.tanh_8[1][0]']         \n",
            "                                                                                                  \n",
            " multi_head_attention_39 (Multi  (None, 14, 1)       8065        ['tf.math.multiply_8[1][0]',     \n",
            " HeadAttention)                                                   'tf.math.multiply_8[1][0]']     \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)            (None, 14)           0           ['multi_head_attention_39[1][0]']\n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 1)            15          ['flatten_8[1][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 41,399\n",
            "Trainable params: 41,383\n",
            "Non-trainable params: 16\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = dwt_2BPRFB(input_shape)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss='MeanSquaredError', metrics=['accuracy'])\n"
      ],
      "id": "CvCS7kUR1nUr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cSynwTz4OPI",
        "outputId": "f1eb9068-81ad-4280-ebdf-bdec19eb2505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9389, 23, 1)\n",
            "(9389, 1)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "k_band = RH         First 8 features + height\n",
        "v_band = Temp       Last 14 features + height\n",
        "'''\n",
        "\n",
        "x_fit = tf.constant(x_train, dtype=tf.float32, name='x_train')\n",
        "x_fit = tf.reshape(x_fit, [len(x_fit),len(x_fit[0]), 1])\n",
        "\n",
        "y_fit = tf.constant(y_train[:,2], dtype=tf.float32, name='y_train')\n",
        "y_fit.shape[0]\n",
        "y_fit = tf.reshape(y_fit, [9389,1])\n",
        "\n",
        "print(x_fit.shape)\n",
        "print(y_fit.shape)\n"
      ],
      "id": "_cSynwTz4OPI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruk-3EumbkfD"
      },
      "source": [
        "# Training"
      ],
      "id": "ruk-3EumbkfD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzIPqYMQ4oW0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d6189b7-6532-4512-e8fb-3e4d76e93ecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "29/29 [==============================] - 9s 79ms/step - loss: 4186.8267 - accuracy: 0.0000e+00 - val_loss: 2358.1128 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 3348.3342 - accuracy: 1.1834e-04 - val_loss: 1853.0459 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 893.2360 - accuracy: 1.1834e-04 - val_loss: 360.0301 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 288.3271 - accuracy: 1.1834e-04 - val_loss: 336.6565 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 263.4538 - accuracy: 1.1834e-04 - val_loss: 337.6046 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 257.9835 - accuracy: 1.1834e-04 - val_loss: 307.6566 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 255.2203 - accuracy: 1.1834e-04 - val_loss: 384.9073 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 250.5610 - accuracy: 1.1834e-04 - val_loss: 308.0318 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 249.0439 - accuracy: 1.1834e-04 - val_loss: 311.6591 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 246.7065 - accuracy: 1.1834e-04 - val_loss: 296.2566 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 244.7479 - accuracy: 1.1834e-04 - val_loss: 351.8495 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 241.5763 - accuracy: 1.1834e-04 - val_loss: 318.3493 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 241.9629 - accuracy: 1.1834e-04 - val_loss: 515.7620 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 242.4441 - accuracy: 1.1834e-04 - val_loss: 320.7867 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 240.7697 - accuracy: 1.1834e-04 - val_loss: 785.8701 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 238.6829 - accuracy: 1.1834e-04 - val_loss: 282.2524 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 240.5815 - accuracy: 1.1834e-04 - val_loss: 307.9359 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 236.9501 - accuracy: 1.1834e-04 - val_loss: 278.9523 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 237.7758 - accuracy: 1.1834e-04 - val_loss: 304.3122 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 244.0574 - accuracy: 1.1834e-04 - val_loss: 1218.3322 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 237.4530 - accuracy: 1.1834e-04 - val_loss: 531.8677 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 232.7029 - accuracy: 1.1834e-04 - val_loss: 285.9233 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 228.9035 - accuracy: 1.1834e-04 - val_loss: 303.6150 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 229.5631 - accuracy: 1.1834e-04 - val_loss: 317.0873 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 227.5214 - accuracy: 1.1834e-04 - val_loss: 610.3753 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 227.4570 - accuracy: 1.1834e-04 - val_loss: 281.1292 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 223.0049 - accuracy: 1.1834e-04 - val_loss: 448.9237 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 221.2453 - accuracy: 1.1834e-04 - val_loss: 1273.7717 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 227.6387 - accuracy: 1.1834e-04 - val_loss: 1293.2223 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 221.0961 - accuracy: 1.1834e-04 - val_loss: 1123.4749 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 218.6788 - accuracy: 1.1834e-04 - val_loss: 653.4130 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 214.2031 - accuracy: 1.1834e-04 - val_loss: 277.9282 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 215.2455 - accuracy: 1.1834e-04 - val_loss: 262.7850 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 218.5338 - accuracy: 1.1834e-04 - val_loss: 1134.3365 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 216.3799 - accuracy: 1.1834e-04 - val_loss: 488.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 208.9739 - accuracy: 1.1834e-04 - val_loss: 770.6091 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 207.2583 - accuracy: 1.1834e-04 - val_loss: 1626.1528 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 212.9956 - accuracy: 1.1834e-04 - val_loss: 266.1643 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 208.9446 - accuracy: 1.1834e-04 - val_loss: 1974.9203 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 204.4283 - accuracy: 1.1834e-04 - val_loss: 262.3876 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 211.0354 - accuracy: 1.1834e-04 - val_loss: 348.5642 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 202.7659 - accuracy: 1.1834e-04 - val_loss: 253.2223 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 201.8845 - accuracy: 1.1834e-04 - val_loss: 356.6396 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 201.6979 - accuracy: 1.1834e-04 - val_loss: 293.8073 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 198.4037 - accuracy: 1.1834e-04 - val_loss: 337.4641 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 196.5858 - accuracy: 1.1834e-04 - val_loss: 538.6036 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 197.8975 - accuracy: 1.1834e-04 - val_loss: 460.8646 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 194.6833 - accuracy: 1.1834e-04 - val_loss: 210.4941 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 194.5554 - accuracy: 1.1834e-04 - val_loss: 263.3890 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 202.1156 - accuracy: 1.1834e-04 - val_loss: 336.1271 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 191.7231 - accuracy: 1.1834e-04 - val_loss: 234.3968 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/1000\n",
            "29/29 [==============================] - 1s 19ms/step - loss: 190.6875 - accuracy: 1.1834e-04 - val_loss: 476.6215 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 197.0101 - accuracy: 1.1834e-04 - val_loss: 667.0048 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 193.0648 - accuracy: 1.1834e-04 - val_loss: 276.2790 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 195.6660 - accuracy: 1.1834e-04 - val_loss: 249.9208 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 194.6042 - accuracy: 1.1834e-04 - val_loss: 608.5115 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 190.8981 - accuracy: 1.1834e-04 - val_loss: 744.2860 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 190.1475 - accuracy: 1.1834e-04 - val_loss: 261.3302 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 188.3670 - accuracy: 1.1834e-04 - val_loss: 230.9743 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 189.2238 - accuracy: 1.1834e-04 - val_loss: 282.2515 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 188.7721 - accuracy: 1.1834e-04 - val_loss: 326.3316 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 189.2456 - accuracy: 1.1834e-04 - val_loss: 278.5281 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 185.0197 - accuracy: 1.1834e-04 - val_loss: 277.0559 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 185.6387 - accuracy: 1.1834e-04 - val_loss: 248.3385 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 187.3097 - accuracy: 1.1834e-04 - val_loss: 464.7104 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 184.0773 - accuracy: 1.1834e-04 - val_loss: 310.6453 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 189.7749 - accuracy: 1.1834e-04 - val_loss: 309.1326 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 186.8050 - accuracy: 1.1834e-04 - val_loss: 211.4601 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 183.4405 - accuracy: 1.1834e-04 - val_loss: 267.6358 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 181.7501 - accuracy: 1.1834e-04 - val_loss: 341.0750 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 179.9453 - accuracy: 1.1834e-04 - val_loss: 434.0962 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 183.0215 - accuracy: 1.1834e-04 - val_loss: 242.3663 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 184.2107 - accuracy: 1.1834e-04 - val_loss: 351.9922 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 184.1961 - accuracy: 1.1834e-04 - val_loss: 357.1225 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 184.8600 - accuracy: 1.1834e-04 - val_loss: 493.6013 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 184.2916 - accuracy: 1.1834e-04 - val_loss: 622.5446 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 181.9946 - accuracy: 1.1834e-04 - val_loss: 396.7978 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 179.6384 - accuracy: 1.1834e-04 - val_loss: 282.7307 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 176.8221 - accuracy: 1.1834e-04 - val_loss: 458.7794 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 181.3449 - accuracy: 1.1834e-04 - val_loss: 245.2937 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 176.8147 - accuracy: 1.1834e-04 - val_loss: 490.1325 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 178.7258 - accuracy: 1.1834e-04 - val_loss: 267.9936 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 178.7495 - accuracy: 1.1834e-04 - val_loss: 331.9431 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 173.8341 - accuracy: 1.1834e-04 - val_loss: 830.5414 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 171.8394 - accuracy: 1.1834e-04 - val_loss: 435.8405 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 172.7174 - accuracy: 1.1834e-04 - val_loss: 431.6748 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/1000\n",
            "29/29 [==============================] - 1s 31ms/step - loss: 179.2666 - accuracy: 1.1834e-04 - val_loss: 520.3142 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/1000\n",
            "29/29 [==============================] - 1s 32ms/step - loss: 182.8954 - accuracy: 1.1834e-04 - val_loss: 391.6510 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 172.1970 - accuracy: 1.1834e-04 - val_loss: 470.5667 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 175.0224 - accuracy: 1.1834e-04 - val_loss: 345.0789 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 173.1105 - accuracy: 1.1834e-04 - val_loss: 410.0757 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 173.2260 - accuracy: 1.1834e-04 - val_loss: 677.9741 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 177.7717 - accuracy: 1.1834e-04 - val_loss: 324.5151 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 172.9008 - accuracy: 1.1834e-04 - val_loss: 243.6387 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 179.2537 - accuracy: 1.1834e-04 - val_loss: 296.6573 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 173.1349 - accuracy: 1.1834e-04 - val_loss: 293.5790 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 168.2010 - accuracy: 1.1834e-04 - val_loss: 482.9809 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 168.4618 - accuracy: 1.1834e-04 - val_loss: 470.3492 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 167.6400 - accuracy: 1.1834e-04 - val_loss: 1052.6946 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 175.3165 - accuracy: 1.1834e-04 - val_loss: 312.0254 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 165.5928 - accuracy: 1.1834e-04 - val_loss: 538.3162 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 183.0527 - accuracy: 1.1834e-04 - val_loss: 555.3256 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 165.1044 - accuracy: 1.1834e-04 - val_loss: 584.2504 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 164.9056 - accuracy: 1.1834e-04 - val_loss: 441.9957 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 162.9966 - accuracy: 1.1834e-04 - val_loss: 661.4434 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 164.4609 - accuracy: 1.1834e-04 - val_loss: 645.8486 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 169.1763 - accuracy: 1.1834e-04 - val_loss: 369.0327 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 161.2112 - accuracy: 1.1834e-04 - val_loss: 847.3101 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 165.6353 - accuracy: 1.1834e-04 - val_loss: 389.5143 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 166.3680 - accuracy: 1.1834e-04 - val_loss: 232.3789 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 159.5630 - accuracy: 1.1834e-04 - val_loss: 1635.6158 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 160.0731 - accuracy: 1.1834e-04 - val_loss: 352.1544 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 160.8821 - accuracy: 1.1834e-04 - val_loss: 2003.8024 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 163.8887 - accuracy: 1.1834e-04 - val_loss: 263.0166 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 157.7607 - accuracy: 1.1834e-04 - val_loss: 342.2866 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 155.3037 - accuracy: 1.1834e-04 - val_loss: 845.7628 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 153.5332 - accuracy: 1.1834e-04 - val_loss: 230.7481 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 156.7207 - accuracy: 1.1834e-04 - val_loss: 367.6394 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 156.2919 - accuracy: 1.1834e-04 - val_loss: 324.9485 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 154.6258 - accuracy: 1.1834e-04 - val_loss: 567.4451 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 153.9635 - accuracy: 1.1834e-04 - val_loss: 523.5709 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 153.6646 - accuracy: 1.1834e-04 - val_loss: 478.8812 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 149.4507 - accuracy: 1.1834e-04 - val_loss: 312.4937 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 148.0446 - accuracy: 1.1834e-04 - val_loss: 331.3478 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 148.6296 - accuracy: 1.1834e-04 - val_loss: 345.4051 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 144.0216 - accuracy: 1.1834e-04 - val_loss: 2029.1239 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 147.0184 - accuracy: 1.1834e-04 - val_loss: 261.7752 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 146.4320 - accuracy: 1.1834e-04 - val_loss: 337.2314 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 148.0885 - accuracy: 1.1834e-04 - val_loss: 417.8522 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 152.2695 - accuracy: 1.1834e-04 - val_loss: 609.2520 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 149.0026 - accuracy: 1.1834e-04 - val_loss: 359.8308 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 148.2207 - accuracy: 1.1834e-04 - val_loss: 304.4760 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 156.9157 - accuracy: 1.1834e-04 - val_loss: 337.3609 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 147.0573 - accuracy: 1.1834e-04 - val_loss: 451.0891 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 155.7226 - accuracy: 1.1834e-04 - val_loss: 648.9695 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 154.0313 - accuracy: 1.1834e-04 - val_loss: 1148.2236 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 143.1818 - accuracy: 1.1834e-04 - val_loss: 495.3828 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 152.9095 - accuracy: 1.1834e-04 - val_loss: 296.1736 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 146.8163 - accuracy: 1.1834e-04 - val_loss: 417.7885 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 141.0691 - accuracy: 1.1834e-04 - val_loss: 885.7050 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 141.5798 - accuracy: 1.1834e-04 - val_loss: 320.4561 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 136.4900 - accuracy: 1.1834e-04 - val_loss: 551.0306 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 134.8633 - accuracy: 1.1834e-04 - val_loss: 492.7911 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 144.6345 - accuracy: 1.1834e-04 - val_loss: 534.1558 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 139.5839 - accuracy: 1.1834e-04 - val_loss: 375.8853 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 138.8224 - accuracy: 1.1834e-04 - val_loss: 255.6419 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 138.7653 - accuracy: 1.1834e-04 - val_loss: 604.3685 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 140.5561 - accuracy: 1.1834e-04 - val_loss: 341.7819 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 139.6514 - accuracy: 1.1834e-04 - val_loss: 834.1496 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/1000\n",
            "29/29 [==============================] - 1s 32ms/step - loss: 136.1591 - accuracy: 1.1834e-04 - val_loss: 301.5354 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 140.6556 - accuracy: 1.1834e-04 - val_loss: 770.2344 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 137.1612 - accuracy: 1.1834e-04 - val_loss: 750.3429 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 144.1723 - accuracy: 1.1834e-04 - val_loss: 287.7271 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 133.4660 - accuracy: 1.1834e-04 - val_loss: 377.6913 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 134.5418 - accuracy: 1.1834e-04 - val_loss: 790.3790 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 137.1995 - accuracy: 1.1834e-04 - val_loss: 751.0801 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 150.9011 - accuracy: 1.1834e-04 - val_loss: 992.8943 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 138.9019 - accuracy: 1.1834e-04 - val_loss: 437.8404 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 141.3790 - accuracy: 1.1834e-04 - val_loss: 800.4373 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 134.3099 - accuracy: 1.1834e-04 - val_loss: 307.0843 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 134.8302 - accuracy: 1.1834e-04 - val_loss: 374.9745 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 145.1442 - accuracy: 1.1834e-04 - val_loss: 1108.1560 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 138.3921 - accuracy: 1.1834e-04 - val_loss: 1172.4519 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 135.0521 - accuracy: 1.1834e-04 - val_loss: 269.8539 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 137.1374 - accuracy: 1.1834e-04 - val_loss: 332.9201 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 132.5879 - accuracy: 1.1834e-04 - val_loss: 333.3932 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 130.0854 - accuracy: 1.1834e-04 - val_loss: 386.3068 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 132.5283 - accuracy: 1.1834e-04 - val_loss: 303.1303 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 126.8520 - accuracy: 1.1834e-04 - val_loss: 473.1802 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 135.8810 - accuracy: 1.1834e-04 - val_loss: 305.6497 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 134.7949 - accuracy: 1.1834e-04 - val_loss: 555.3663 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 130.1133 - accuracy: 1.1834e-04 - val_loss: 332.3029 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 128.6733 - accuracy: 1.1834e-04 - val_loss: 268.0161 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 124.0994 - accuracy: 1.1834e-04 - val_loss: 354.3312 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 128.2455 - accuracy: 1.1834e-04 - val_loss: 254.4695 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 130.5378 - accuracy: 1.1834e-04 - val_loss: 256.0761 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 132.1279 - accuracy: 1.1834e-04 - val_loss: 212.3611 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 132.2097 - accuracy: 1.1834e-04 - val_loss: 276.8828 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 123.3129 - accuracy: 1.1834e-04 - val_loss: 359.1136 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 128.5997 - accuracy: 1.1834e-04 - val_loss: 470.6847 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 124.9026 - accuracy: 1.1834e-04 - val_loss: 383.1675 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 123.6235 - accuracy: 1.1834e-04 - val_loss: 301.7785 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 129.8179 - accuracy: 1.1834e-04 - val_loss: 372.4609 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 126.1568 - accuracy: 1.1834e-04 - val_loss: 360.2322 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 123.2706 - accuracy: 1.1834e-04 - val_loss: 545.7012 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 126.6509 - accuracy: 1.1834e-04 - val_loss: 293.7408 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 122.6344 - accuracy: 1.1834e-04 - val_loss: 278.8493 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 129.6109 - accuracy: 1.1834e-04 - val_loss: 250.8234 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 125.3574 - accuracy: 1.1834e-04 - val_loss: 351.2683 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 126.1156 - accuracy: 1.1834e-04 - val_loss: 370.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 118.0882 - accuracy: 1.1834e-04 - val_loss: 256.7146 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 123.2783 - accuracy: 1.1834e-04 - val_loss: 841.9058 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 123.0143 - accuracy: 1.1834e-04 - val_loss: 278.8699 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 122.4753 - accuracy: 1.1834e-04 - val_loss: 319.0456 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 129.5988 - accuracy: 1.1834e-04 - val_loss: 279.3274 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 126.8325 - accuracy: 1.1834e-04 - val_loss: 290.4818 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 118.9819 - accuracy: 1.1834e-04 - val_loss: 371.3363 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 115.5261 - accuracy: 1.1834e-04 - val_loss: 359.4535 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 120.3478 - accuracy: 1.1834e-04 - val_loss: 277.6431 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 133.0788 - accuracy: 1.1834e-04 - val_loss: 240.8743 - val_accuracy: 0.0000e+00\n",
            "Epoch 201/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 118.0462 - accuracy: 1.1834e-04 - val_loss: 262.7359 - val_accuracy: 0.0000e+00\n",
            "Epoch 202/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 120.7539 - accuracy: 1.1834e-04 - val_loss: 348.6940 - val_accuracy: 0.0000e+00\n",
            "Epoch 203/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 117.5338 - accuracy: 1.1834e-04 - val_loss: 264.4665 - val_accuracy: 0.0000e+00\n",
            "Epoch 204/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 114.3775 - accuracy: 1.1834e-04 - val_loss: 231.3635 - val_accuracy: 0.0000e+00\n",
            "Epoch 205/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 116.6487 - accuracy: 1.1834e-04 - val_loss: 240.9412 - val_accuracy: 0.0000e+00\n",
            "Epoch 206/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 116.8276 - accuracy: 1.1834e-04 - val_loss: 288.2244 - val_accuracy: 0.0000e+00\n",
            "Epoch 207/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 119.9259 - accuracy: 1.1834e-04 - val_loss: 464.5305 - val_accuracy: 0.0000e+00\n",
            "Epoch 208/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 126.9796 - accuracy: 1.1834e-04 - val_loss: 282.1286 - val_accuracy: 0.0000e+00\n",
            "Epoch 209/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 114.0766 - accuracy: 1.1834e-04 - val_loss: 240.7599 - val_accuracy: 0.0000e+00\n",
            "Epoch 210/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 109.4010 - accuracy: 1.1834e-04 - val_loss: 286.4619 - val_accuracy: 0.0000e+00\n",
            "Epoch 211/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 114.3937 - accuracy: 1.1834e-04 - val_loss: 299.7084 - val_accuracy: 0.0000e+00\n",
            "Epoch 212/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 109.6183 - accuracy: 1.1834e-04 - val_loss: 230.4570 - val_accuracy: 0.0000e+00\n",
            "Epoch 213/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 117.2296 - accuracy: 1.1834e-04 - val_loss: 333.0478 - val_accuracy: 0.0000e+00\n",
            "Epoch 214/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 110.2425 - accuracy: 1.1834e-04 - val_loss: 304.5045 - val_accuracy: 0.0000e+00\n",
            "Epoch 215/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 105.7253 - accuracy: 1.1834e-04 - val_loss: 314.2438 - val_accuracy: 0.0000e+00\n",
            "Epoch 216/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 114.0394 - accuracy: 1.1834e-04 - val_loss: 361.9059 - val_accuracy: 0.0000e+00\n",
            "Epoch 217/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 115.2838 - accuracy: 1.1834e-04 - val_loss: 345.0668 - val_accuracy: 0.0000e+00\n",
            "Epoch 218/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 118.6136 - accuracy: 1.1834e-04 - val_loss: 281.1744 - val_accuracy: 0.0000e+00\n",
            "Epoch 219/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 112.4958 - accuracy: 1.1834e-04 - val_loss: 367.1331 - val_accuracy: 0.0000e+00\n",
            "Epoch 220/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 111.9954 - accuracy: 1.1834e-04 - val_loss: 583.2089 - val_accuracy: 0.0000e+00\n",
            "Epoch 221/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 117.1968 - accuracy: 1.1834e-04 - val_loss: 422.8325 - val_accuracy: 0.0000e+00\n",
            "Epoch 222/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 111.3473 - accuracy: 1.1834e-04 - val_loss: 210.3948 - val_accuracy: 0.0000e+00\n",
            "Epoch 223/1000\n",
            "29/29 [==============================] - 1s 34ms/step - loss: 109.1026 - accuracy: 1.1834e-04 - val_loss: 266.4536 - val_accuracy: 0.0000e+00\n",
            "Epoch 224/1000\n",
            "29/29 [==============================] - 1s 33ms/step - loss: 110.7299 - accuracy: 1.1834e-04 - val_loss: 233.2131 - val_accuracy: 0.0000e+00\n",
            "Epoch 225/1000\n",
            "29/29 [==============================] - 1s 32ms/step - loss: 118.8621 - accuracy: 1.1834e-04 - val_loss: 272.1454 - val_accuracy: 0.0000e+00\n",
            "Epoch 226/1000\n",
            "29/29 [==============================] - 1s 35ms/step - loss: 108.5109 - accuracy: 1.1834e-04 - val_loss: 336.7618 - val_accuracy: 0.0000e+00\n",
            "Epoch 227/1000\n",
            "29/29 [==============================] - 1s 33ms/step - loss: 104.7016 - accuracy: 1.1834e-04 - val_loss: 287.1893 - val_accuracy: 0.0000e+00\n",
            "Epoch 228/1000\n",
            "29/29 [==============================] - 1s 37ms/step - loss: 103.9021 - accuracy: 1.1834e-04 - val_loss: 308.7848 - val_accuracy: 0.0000e+00\n",
            "Epoch 229/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 107.1937 - accuracy: 1.1834e-04 - val_loss: 250.9518 - val_accuracy: 0.0000e+00\n",
            "Epoch 230/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 104.6249 - accuracy: 1.1834e-04 - val_loss: 341.1455 - val_accuracy: 0.0000e+00\n",
            "Epoch 231/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 110.6020 - accuracy: 1.1834e-04 - val_loss: 272.4249 - val_accuracy: 0.0000e+00\n",
            "Epoch 232/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 106.5226 - accuracy: 1.1834e-04 - val_loss: 303.5236 - val_accuracy: 0.0000e+00\n",
            "Epoch 233/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 105.3495 - accuracy: 1.1834e-04 - val_loss: 349.5718 - val_accuracy: 0.0000e+00\n",
            "Epoch 234/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 104.8859 - accuracy: 1.1834e-04 - val_loss: 276.5279 - val_accuracy: 0.0000e+00\n",
            "Epoch 235/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 101.7128 - accuracy: 1.1834e-04 - val_loss: 250.0678 - val_accuracy: 0.0000e+00\n",
            "Epoch 236/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 103.3245 - accuracy: 1.1834e-04 - val_loss: 311.9491 - val_accuracy: 0.0000e+00\n",
            "Epoch 237/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 102.9568 - accuracy: 1.1834e-04 - val_loss: 293.2177 - val_accuracy: 0.0000e+00\n",
            "Epoch 238/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 102.6389 - accuracy: 1.1834e-04 - val_loss: 345.1229 - val_accuracy: 0.0000e+00\n",
            "Epoch 239/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 104.6441 - accuracy: 1.1834e-04 - val_loss: 358.7764 - val_accuracy: 0.0000e+00\n",
            "Epoch 240/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 101.5339 - accuracy: 1.1834e-04 - val_loss: 264.7244 - val_accuracy: 0.0000e+00\n",
            "Epoch 241/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 101.2889 - accuracy: 1.1834e-04 - val_loss: 422.6219 - val_accuracy: 0.0000e+00\n",
            "Epoch 242/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 105.2751 - accuracy: 1.1834e-04 - val_loss: 268.8124 - val_accuracy: 0.0000e+00\n",
            "Epoch 243/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 100.6309 - accuracy: 1.1834e-04 - val_loss: 291.7212 - val_accuracy: 0.0000e+00\n",
            "Epoch 244/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 99.5820 - accuracy: 1.1834e-04 - val_loss: 272.8572 - val_accuracy: 0.0000e+00\n",
            "Epoch 245/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 98.7793 - accuracy: 1.1834e-04 - val_loss: 230.4624 - val_accuracy: 0.0000e+00\n",
            "Epoch 246/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 96.7602 - accuracy: 1.1834e-04 - val_loss: 353.1523 - val_accuracy: 0.0000e+00\n",
            "Epoch 247/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 95.9829 - accuracy: 1.1834e-04 - val_loss: 299.5954 - val_accuracy: 0.0000e+00\n",
            "Epoch 248/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 103.3536 - accuracy: 1.1834e-04 - val_loss: 303.5841 - val_accuracy: 0.0000e+00\n",
            "Epoch 249/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 96.6465 - accuracy: 1.1834e-04 - val_loss: 356.5261 - val_accuracy: 0.0000e+00\n",
            "Epoch 250/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 98.0954 - accuracy: 1.1834e-04 - val_loss: 372.2657 - val_accuracy: 0.0000e+00\n",
            "Epoch 251/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 98.1265 - accuracy: 1.1834e-04 - val_loss: 382.2437 - val_accuracy: 0.0000e+00\n",
            "Epoch 252/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 106.8980 - accuracy: 1.1834e-04 - val_loss: 261.8935 - val_accuracy: 0.0000e+00\n",
            "Epoch 253/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 95.4812 - accuracy: 1.1834e-04 - val_loss: 471.9583 - val_accuracy: 0.0000e+00\n",
            "Epoch 254/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 98.5208 - accuracy: 1.1834e-04 - val_loss: 389.4071 - val_accuracy: 0.0000e+00\n",
            "Epoch 255/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 99.1998 - accuracy: 1.1834e-04 - val_loss: 342.5837 - val_accuracy: 0.0000e+00\n",
            "Epoch 256/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 106.1852 - accuracy: 1.1834e-04 - val_loss: 302.2520 - val_accuracy: 0.0000e+00\n",
            "Epoch 257/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 97.1810 - accuracy: 1.1834e-04 - val_loss: 329.6581 - val_accuracy: 0.0000e+00\n",
            "Epoch 258/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 98.9946 - accuracy: 1.1834e-04 - val_loss: 318.8618 - val_accuracy: 0.0000e+00\n",
            "Epoch 259/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 95.6944 - accuracy: 1.1834e-04 - val_loss: 387.7321 - val_accuracy: 0.0000e+00\n",
            "Epoch 260/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 97.9565 - accuracy: 1.1834e-04 - val_loss: 444.4358 - val_accuracy: 0.0000e+00\n",
            "Epoch 261/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 97.6355 - accuracy: 1.1834e-04 - val_loss: 315.6099 - val_accuracy: 0.0000e+00\n",
            "Epoch 262/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 94.4365 - accuracy: 1.1834e-04 - val_loss: 355.2309 - val_accuracy: 0.0000e+00\n",
            "Epoch 263/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 95.6624 - accuracy: 1.1834e-04 - val_loss: 445.7344 - val_accuracy: 0.0000e+00\n",
            "Epoch 264/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 99.0862 - accuracy: 1.1834e-04 - val_loss: 322.5168 - val_accuracy: 0.0000e+00\n",
            "Epoch 265/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 91.8859 - accuracy: 1.1834e-04 - val_loss: 492.1780 - val_accuracy: 0.0000e+00\n",
            "Epoch 266/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 92.5601 - accuracy: 1.1834e-04 - val_loss: 338.2812 - val_accuracy: 0.0000e+00\n",
            "Epoch 267/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 94.4242 - accuracy: 1.1834e-04 - val_loss: 324.3866 - val_accuracy: 0.0000e+00\n",
            "Epoch 268/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 94.4242 - accuracy: 1.1834e-04 - val_loss: 268.6589 - val_accuracy: 0.0000e+00\n",
            "Epoch 269/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 93.7370 - accuracy: 1.1834e-04 - val_loss: 336.5619 - val_accuracy: 0.0000e+00\n",
            "Epoch 270/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 94.9334 - accuracy: 1.1834e-04 - val_loss: 331.1185 - val_accuracy: 0.0000e+00\n",
            "Epoch 271/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 89.8717 - accuracy: 1.1834e-04 - val_loss: 328.6289 - val_accuracy: 0.0000e+00\n",
            "Epoch 272/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 89.0337 - accuracy: 1.1834e-04 - val_loss: 354.1122 - val_accuracy: 0.0000e+00\n",
            "Epoch 273/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 88.3560 - accuracy: 1.1834e-04 - val_loss: 379.7800 - val_accuracy: 0.0000e+00\n",
            "Epoch 274/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 86.3862 - accuracy: 1.1834e-04 - val_loss: 298.4977 - val_accuracy: 0.0000e+00\n",
            "Epoch 275/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 98.9319 - accuracy: 1.1834e-04 - val_loss: 256.3356 - val_accuracy: 0.0000e+00\n",
            "Epoch 276/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 92.2552 - accuracy: 1.1834e-04 - val_loss: 399.6368 - val_accuracy: 0.0000e+00\n",
            "Epoch 277/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 94.1999 - accuracy: 1.1834e-04 - val_loss: 453.8936 - val_accuracy: 0.0000e+00\n",
            "Epoch 278/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 89.1004 - accuracy: 1.1834e-04 - val_loss: 330.0987 - val_accuracy: 0.0000e+00\n",
            "Epoch 279/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 84.5548 - accuracy: 1.1834e-04 - val_loss: 370.9536 - val_accuracy: 0.0000e+00\n",
            "Epoch 280/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 91.0731 - accuracy: 1.1834e-04 - val_loss: 335.6870 - val_accuracy: 0.0000e+00\n",
            "Epoch 281/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 89.4136 - accuracy: 1.1834e-04 - val_loss: 321.9012 - val_accuracy: 0.0000e+00\n",
            "Epoch 282/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 88.1650 - accuracy: 1.1834e-04 - val_loss: 483.2149 - val_accuracy: 0.0000e+00\n",
            "Epoch 283/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 98.5225 - accuracy: 1.1834e-04 - val_loss: 361.3803 - val_accuracy: 0.0000e+00\n",
            "Epoch 284/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 90.3112 - accuracy: 1.1834e-04 - val_loss: 430.6895 - val_accuracy: 0.0000e+00\n",
            "Epoch 285/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 87.2605 - accuracy: 1.1834e-04 - val_loss: 362.9324 - val_accuracy: 0.0000e+00\n",
            "Epoch 286/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 83.0939 - accuracy: 1.1834e-04 - val_loss: 395.4956 - val_accuracy: 0.0000e+00\n",
            "Epoch 287/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 85.1651 - accuracy: 1.1834e-04 - val_loss: 377.3586 - val_accuracy: 0.0000e+00\n",
            "Epoch 288/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 94.8042 - accuracy: 1.1834e-04 - val_loss: 371.9576 - val_accuracy: 0.0000e+00\n",
            "Epoch 289/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 88.3119 - accuracy: 1.1834e-04 - val_loss: 491.0346 - val_accuracy: 0.0000e+00\n",
            "Epoch 290/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 84.3382 - accuracy: 1.1834e-04 - val_loss: 357.9080 - val_accuracy: 0.0000e+00\n",
            "Epoch 291/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 98.8034 - accuracy: 1.1834e-04 - val_loss: 323.3874 - val_accuracy: 0.0000e+00\n",
            "Epoch 292/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 88.9361 - accuracy: 1.1834e-04 - val_loss: 367.4063 - val_accuracy: 0.0000e+00\n",
            "Epoch 293/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 83.9501 - accuracy: 1.1834e-04 - val_loss: 301.9490 - val_accuracy: 0.0000e+00\n",
            "Epoch 294/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 80.6456 - accuracy: 1.1834e-04 - val_loss: 390.2235 - val_accuracy: 0.0000e+00\n",
            "Epoch 295/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 84.6947 - accuracy: 1.1834e-04 - val_loss: 361.7640 - val_accuracy: 0.0000e+00\n",
            "Epoch 296/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 85.4781 - accuracy: 1.1834e-04 - val_loss: 445.7527 - val_accuracy: 0.0000e+00\n",
            "Epoch 297/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 89.5786 - accuracy: 1.1834e-04 - val_loss: 497.8386 - val_accuracy: 0.0000e+00\n",
            "Epoch 298/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 82.6560 - accuracy: 1.1834e-04 - val_loss: 442.4368 - val_accuracy: 0.0000e+00\n",
            "Epoch 299/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 86.9622 - accuracy: 1.1834e-04 - val_loss: 358.6103 - val_accuracy: 0.0000e+00\n",
            "Epoch 300/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 81.9764 - accuracy: 1.1834e-04 - val_loss: 374.3105 - val_accuracy: 0.0000e+00\n",
            "Epoch 301/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 85.3570 - accuracy: 1.1834e-04 - val_loss: 313.6257 - val_accuracy: 0.0000e+00\n",
            "Epoch 302/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 81.7300 - accuracy: 1.1834e-04 - val_loss: 537.0366 - val_accuracy: 0.0000e+00\n",
            "Epoch 303/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 84.1998 - accuracy: 1.1834e-04 - val_loss: 441.1563 - val_accuracy: 0.0000e+00\n",
            "Epoch 304/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 82.9801 - accuracy: 1.1834e-04 - val_loss: 436.9796 - val_accuracy: 0.0000e+00\n",
            "Epoch 305/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 83.0844 - accuracy: 1.1834e-04 - val_loss: 381.9145 - val_accuracy: 0.0000e+00\n",
            "Epoch 306/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 78.6735 - accuracy: 1.1834e-04 - val_loss: 350.0150 - val_accuracy: 0.0000e+00\n",
            "Epoch 307/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 82.9757 - accuracy: 1.1834e-04 - val_loss: 558.0088 - val_accuracy: 0.0000e+00\n",
            "Epoch 308/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 103.7914 - accuracy: 1.1834e-04 - val_loss: 633.8807 - val_accuracy: 0.0000e+00\n",
            "Epoch 309/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 92.9158 - accuracy: 1.1834e-04 - val_loss: 374.9809 - val_accuracy: 0.0000e+00\n",
            "Epoch 310/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 84.5093 - accuracy: 1.1834e-04 - val_loss: 287.3823 - val_accuracy: 0.0000e+00\n",
            "Epoch 311/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 82.6502 - accuracy: 1.1834e-04 - val_loss: 377.4121 - val_accuracy: 0.0000e+00\n",
            "Epoch 312/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 82.1846 - accuracy: 1.1834e-04 - val_loss: 434.7801 - val_accuracy: 0.0000e+00\n",
            "Epoch 313/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 84.5916 - accuracy: 1.1834e-04 - val_loss: 352.3418 - val_accuracy: 0.0000e+00\n",
            "Epoch 314/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 83.9449 - accuracy: 1.1834e-04 - val_loss: 373.7233 - val_accuracy: 0.0000e+00\n",
            "Epoch 315/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 77.2126 - accuracy: 1.1834e-04 - val_loss: 323.4408 - val_accuracy: 0.0000e+00\n",
            "Epoch 316/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 80.1872 - accuracy: 1.1834e-04 - val_loss: 342.6145 - val_accuracy: 0.0000e+00\n",
            "Epoch 317/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 79.4487 - accuracy: 1.1834e-04 - val_loss: 398.7773 - val_accuracy: 0.0000e+00\n",
            "Epoch 318/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 73.8358 - accuracy: 1.1834e-04 - val_loss: 428.9602 - val_accuracy: 0.0000e+00\n",
            "Epoch 319/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 86.7699 - accuracy: 1.1834e-04 - val_loss: 373.2229 - val_accuracy: 0.0000e+00\n",
            "Epoch 320/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 77.7442 - accuracy: 1.1834e-04 - val_loss: 290.8701 - val_accuracy: 0.0000e+00\n",
            "Epoch 321/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 77.1627 - accuracy: 1.1834e-04 - val_loss: 297.7864 - val_accuracy: 0.0000e+00\n",
            "Epoch 322/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 77.3042 - accuracy: 1.1834e-04 - val_loss: 424.0948 - val_accuracy: 0.0000e+00\n",
            "Epoch 323/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 78.5618 - accuracy: 1.1834e-04 - val_loss: 289.4281 - val_accuracy: 0.0000e+00\n",
            "Epoch 324/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 75.0884 - accuracy: 1.1834e-04 - val_loss: 320.8070 - val_accuracy: 0.0000e+00\n",
            "Epoch 325/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 73.5799 - accuracy: 1.1834e-04 - val_loss: 300.9233 - val_accuracy: 0.0000e+00\n",
            "Epoch 326/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 75.7117 - accuracy: 1.1834e-04 - val_loss: 324.8379 - val_accuracy: 0.0000e+00\n",
            "Epoch 327/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 80.1875 - accuracy: 1.1834e-04 - val_loss: 328.1159 - val_accuracy: 0.0000e+00\n",
            "Epoch 328/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 79.3469 - accuracy: 1.1834e-04 - val_loss: 368.3461 - val_accuracy: 0.0000e+00\n",
            "Epoch 329/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 73.5725 - accuracy: 1.1834e-04 - val_loss: 305.5454 - val_accuracy: 0.0000e+00\n",
            "Epoch 330/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 77.0465 - accuracy: 1.1834e-04 - val_loss: 348.6793 - val_accuracy: 0.0000e+00\n",
            "Epoch 331/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 72.3315 - accuracy: 1.1834e-04 - val_loss: 393.8389 - val_accuracy: 0.0000e+00\n",
            "Epoch 332/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 72.7656 - accuracy: 1.1834e-04 - val_loss: 382.7038 - val_accuracy: 0.0000e+00\n",
            "Epoch 333/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 74.3733 - accuracy: 1.1834e-04 - val_loss: 353.8185 - val_accuracy: 0.0000e+00\n",
            "Epoch 334/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 74.6924 - accuracy: 1.1834e-04 - val_loss: 261.2178 - val_accuracy: 0.0000e+00\n",
            "Epoch 335/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 74.3021 - accuracy: 1.1834e-04 - val_loss: 294.4813 - val_accuracy: 0.0000e+00\n",
            "Epoch 336/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 73.2963 - accuracy: 1.1834e-04 - val_loss: 376.8150 - val_accuracy: 0.0000e+00\n",
            "Epoch 337/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 73.6418 - accuracy: 1.1834e-04 - val_loss: 406.7710 - val_accuracy: 0.0000e+00\n",
            "Epoch 338/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 71.3290 - accuracy: 1.1834e-04 - val_loss: 419.0827 - val_accuracy: 0.0000e+00\n",
            "Epoch 339/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 73.8484 - accuracy: 1.1834e-04 - val_loss: 344.6653 - val_accuracy: 0.0000e+00\n",
            "Epoch 340/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 73.8170 - accuracy: 1.1834e-04 - val_loss: 342.7955 - val_accuracy: 0.0000e+00\n",
            "Epoch 341/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 74.3384 - accuracy: 1.1834e-04 - val_loss: 347.9650 - val_accuracy: 0.0000e+00\n",
            "Epoch 342/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 69.8934 - accuracy: 1.1834e-04 - val_loss: 361.4015 - val_accuracy: 0.0000e+00\n",
            "Epoch 343/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 69.8368 - accuracy: 1.1834e-04 - val_loss: 349.7698 - val_accuracy: 0.0000e+00\n",
            "Epoch 344/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 81.7383 - accuracy: 1.1834e-04 - val_loss: 330.5904 - val_accuracy: 0.0000e+00\n",
            "Epoch 345/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 71.7542 - accuracy: 1.1834e-04 - val_loss: 352.1098 - val_accuracy: 0.0000e+00\n",
            "Epoch 346/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 71.3989 - accuracy: 1.1834e-04 - val_loss: 275.5542 - val_accuracy: 0.0000e+00\n",
            "Epoch 347/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 74.5473 - accuracy: 1.1834e-04 - val_loss: 359.9037 - val_accuracy: 0.0000e+00\n",
            "Epoch 348/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 71.7862 - accuracy: 1.1834e-04 - val_loss: 343.2368 - val_accuracy: 0.0000e+00\n",
            "Epoch 349/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 71.8291 - accuracy: 1.1834e-04 - val_loss: 322.9657 - val_accuracy: 0.0000e+00\n",
            "Epoch 350/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 68.8648 - accuracy: 1.1834e-04 - val_loss: 315.7146 - val_accuracy: 0.0000e+00\n",
            "Epoch 351/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 69.4828 - accuracy: 1.1834e-04 - val_loss: 399.2654 - val_accuracy: 0.0000e+00\n",
            "Epoch 352/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 70.3555 - accuracy: 1.1834e-04 - val_loss: 422.9220 - val_accuracy: 0.0000e+00\n",
            "Epoch 353/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 74.9060 - accuracy: 1.1834e-04 - val_loss: 382.7230 - val_accuracy: 0.0000e+00\n",
            "Epoch 354/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 72.0437 - accuracy: 1.1834e-04 - val_loss: 314.8703 - val_accuracy: 0.0000e+00\n",
            "Epoch 355/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 70.7397 - accuracy: 1.1834e-04 - val_loss: 270.5336 - val_accuracy: 0.0000e+00\n",
            "Epoch 356/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 77.9044 - accuracy: 1.1834e-04 - val_loss: 353.5704 - val_accuracy: 0.0000e+00\n",
            "Epoch 357/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 66.4327 - accuracy: 1.1834e-04 - val_loss: 333.6771 - val_accuracy: 0.0000e+00\n",
            "Epoch 358/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 65.2777 - accuracy: 1.1834e-04 - val_loss: 339.1154 - val_accuracy: 0.0000e+00\n",
            "Epoch 359/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 66.8850 - accuracy: 1.1834e-04 - val_loss: 453.7333 - val_accuracy: 0.0000e+00\n",
            "Epoch 360/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 77.8164 - accuracy: 1.1834e-04 - val_loss: 367.6691 - val_accuracy: 0.0000e+00\n",
            "Epoch 361/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 73.1099 - accuracy: 1.1834e-04 - val_loss: 412.0486 - val_accuracy: 0.0000e+00\n",
            "Epoch 362/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 67.0456 - accuracy: 1.1834e-04 - val_loss: 450.9821 - val_accuracy: 0.0000e+00\n",
            "Epoch 363/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 67.0027 - accuracy: 1.1834e-04 - val_loss: 331.2408 - val_accuracy: 0.0000e+00\n",
            "Epoch 364/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 67.3907 - accuracy: 1.1834e-04 - val_loss: 323.0454 - val_accuracy: 0.0000e+00\n",
            "Epoch 365/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 70.1497 - accuracy: 1.1834e-04 - val_loss: 317.1668 - val_accuracy: 0.0000e+00\n",
            "Epoch 366/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 74.9922 - accuracy: 1.1834e-04 - val_loss: 389.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 367/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 75.2176 - accuracy: 1.1834e-04 - val_loss: 511.0987 - val_accuracy: 0.0000e+00\n",
            "Epoch 368/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 70.0299 - accuracy: 1.1834e-04 - val_loss: 320.1562 - val_accuracy: 0.0000e+00\n",
            "Epoch 369/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 68.0237 - accuracy: 1.1834e-04 - val_loss: 335.8201 - val_accuracy: 0.0000e+00\n",
            "Epoch 370/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 65.4427 - accuracy: 1.1834e-04 - val_loss: 309.2533 - val_accuracy: 0.0000e+00\n",
            "Epoch 371/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 62.0246 - accuracy: 1.1834e-04 - val_loss: 353.9618 - val_accuracy: 0.0000e+00\n",
            "Epoch 372/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 64.2464 - accuracy: 1.1834e-04 - val_loss: 397.9100 - val_accuracy: 0.0000e+00\n",
            "Epoch 373/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 70.4401 - accuracy: 1.1834e-04 - val_loss: 343.8049 - val_accuracy: 0.0000e+00\n",
            "Epoch 374/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 61.4090 - accuracy: 1.1834e-04 - val_loss: 338.1221 - val_accuracy: 0.0000e+00\n",
            "Epoch 375/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 64.4249 - accuracy: 1.1834e-04 - val_loss: 351.5294 - val_accuracy: 0.0000e+00\n",
            "Epoch 376/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 67.5348 - accuracy: 1.1834e-04 - val_loss: 383.0372 - val_accuracy: 0.0000e+00\n",
            "Epoch 377/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 62.6779 - accuracy: 1.1834e-04 - val_loss: 326.7541 - val_accuracy: 0.0000e+00\n",
            "Epoch 378/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 62.3946 - accuracy: 1.1834e-04 - val_loss: 325.1661 - val_accuracy: 0.0000e+00\n",
            "Epoch 379/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 64.7457 - accuracy: 1.1834e-04 - val_loss: 396.5886 - val_accuracy: 0.0000e+00\n",
            "Epoch 380/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 68.4717 - accuracy: 1.1834e-04 - val_loss: 313.4709 - val_accuracy: 0.0000e+00\n",
            "Epoch 381/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 62.0817 - accuracy: 1.1834e-04 - val_loss: 353.1527 - val_accuracy: 0.0000e+00\n",
            "Epoch 382/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 61.7983 - accuracy: 1.1834e-04 - val_loss: 444.7328 - val_accuracy: 0.0000e+00\n",
            "Epoch 383/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 60.3849 - accuracy: 1.1834e-04 - val_loss: 268.4387 - val_accuracy: 0.0000e+00\n",
            "Epoch 384/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 62.0140 - accuracy: 1.1834e-04 - val_loss: 417.2658 - val_accuracy: 0.0000e+00\n",
            "Epoch 385/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 62.1694 - accuracy: 1.1834e-04 - val_loss: 296.3822 - val_accuracy: 0.0000e+00\n",
            "Epoch 386/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 64.5416 - accuracy: 1.1834e-04 - val_loss: 297.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 387/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 60.3465 - accuracy: 1.1834e-04 - val_loss: 329.5848 - val_accuracy: 0.0000e+00\n",
            "Epoch 388/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 61.5657 - accuracy: 1.1834e-04 - val_loss: 385.8067 - val_accuracy: 0.0000e+00\n",
            "Epoch 389/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 63.6531 - accuracy: 1.1834e-04 - val_loss: 612.3505 - val_accuracy: 0.0000e+00\n",
            "Epoch 390/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 63.2699 - accuracy: 1.1834e-04 - val_loss: 396.2858 - val_accuracy: 0.0000e+00\n",
            "Epoch 391/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 61.9394 - accuracy: 1.1834e-04 - val_loss: 338.6125 - val_accuracy: 0.0000e+00\n",
            "Epoch 392/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 62.8840 - accuracy: 1.1834e-04 - val_loss: 326.2296 - val_accuracy: 0.0000e+00\n",
            "Epoch 393/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 59.8720 - accuracy: 1.1834e-04 - val_loss: 347.1953 - val_accuracy: 0.0000e+00\n",
            "Epoch 394/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 61.8975 - accuracy: 1.1834e-04 - val_loss: 339.6119 - val_accuracy: 0.0000e+00\n",
            "Epoch 395/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 64.9110 - accuracy: 1.1834e-04 - val_loss: 344.1852 - val_accuracy: 0.0000e+00\n",
            "Epoch 396/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 60.4601 - accuracy: 1.1834e-04 - val_loss: 371.8969 - val_accuracy: 0.0000e+00\n",
            "Epoch 397/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 71.8797 - accuracy: 1.1834e-04 - val_loss: 288.0865 - val_accuracy: 0.0000e+00\n",
            "Epoch 398/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 64.1455 - accuracy: 1.1834e-04 - val_loss: 308.0941 - val_accuracy: 0.0000e+00\n",
            "Epoch 399/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 58.8872 - accuracy: 1.1834e-04 - val_loss: 343.8668 - val_accuracy: 0.0000e+00\n",
            "Epoch 400/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 63.7529 - accuracy: 1.1834e-04 - val_loss: 391.5801 - val_accuracy: 0.0000e+00\n",
            "Epoch 401/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 63.5327 - accuracy: 1.1834e-04 - val_loss: 319.1697 - val_accuracy: 0.0000e+00\n",
            "Epoch 402/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 62.5338 - accuracy: 1.1834e-04 - val_loss: 416.4156 - val_accuracy: 0.0000e+00\n",
            "Epoch 403/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 56.6723 - accuracy: 1.1834e-04 - val_loss: 375.9732 - val_accuracy: 0.0000e+00\n",
            "Epoch 404/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 63.9590 - accuracy: 1.1834e-04 - val_loss: 352.6815 - val_accuracy: 0.0000e+00\n",
            "Epoch 405/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 55.9571 - accuracy: 1.1834e-04 - val_loss: 302.8217 - val_accuracy: 0.0000e+00\n",
            "Epoch 406/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 57.9032 - accuracy: 1.1834e-04 - val_loss: 364.2532 - val_accuracy: 0.0000e+00\n",
            "Epoch 407/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 58.8617 - accuracy: 1.1834e-04 - val_loss: 339.1872 - val_accuracy: 0.0000e+00\n",
            "Epoch 408/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 57.7734 - accuracy: 1.1834e-04 - val_loss: 345.8407 - val_accuracy: 0.0000e+00\n",
            "Epoch 409/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 57.9763 - accuracy: 1.1834e-04 - val_loss: 391.0213 - val_accuracy: 0.0000e+00\n",
            "Epoch 410/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 64.0075 - accuracy: 1.1834e-04 - val_loss: 413.7356 - val_accuracy: 0.0000e+00\n",
            "Epoch 411/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 57.1033 - accuracy: 1.1834e-04 - val_loss: 337.0672 - val_accuracy: 0.0000e+00\n",
            "Epoch 412/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 58.7524 - accuracy: 1.1834e-04 - val_loss: 420.8222 - val_accuracy: 0.0000e+00\n",
            "Epoch 413/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 57.5344 - accuracy: 1.1834e-04 - val_loss: 374.7680 - val_accuracy: 0.0000e+00\n",
            "Epoch 414/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 56.0383 - accuracy: 1.1834e-04 - val_loss: 314.0789 - val_accuracy: 0.0000e+00\n",
            "Epoch 415/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 57.1326 - accuracy: 1.1834e-04 - val_loss: 374.7125 - val_accuracy: 0.0000e+00\n",
            "Epoch 416/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 53.1204 - accuracy: 1.1834e-04 - val_loss: 388.2324 - val_accuracy: 0.0000e+00\n",
            "Epoch 417/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 56.6181 - accuracy: 1.1834e-04 - val_loss: 322.9158 - val_accuracy: 0.0000e+00\n",
            "Epoch 418/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 61.3122 - accuracy: 1.1834e-04 - val_loss: 287.1080 - val_accuracy: 0.0000e+00\n",
            "Epoch 419/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 57.1183 - accuracy: 1.1834e-04 - val_loss: 349.9989 - val_accuracy: 0.0000e+00\n",
            "Epoch 420/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 57.9106 - accuracy: 1.1834e-04 - val_loss: 373.1473 - val_accuracy: 0.0000e+00\n",
            "Epoch 421/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 55.1392 - accuracy: 1.1834e-04 - val_loss: 337.1603 - val_accuracy: 0.0000e+00\n",
            "Epoch 422/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 58.3370 - accuracy: 1.1834e-04 - val_loss: 391.8030 - val_accuracy: 0.0000e+00\n",
            "Epoch 423/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 57.0565 - accuracy: 1.1834e-04 - val_loss: 339.7236 - val_accuracy: 0.0000e+00\n",
            "Epoch 424/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 54.5134 - accuracy: 1.1834e-04 - val_loss: 362.8149 - val_accuracy: 0.0000e+00\n",
            "Epoch 425/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 60.1988 - accuracy: 1.1834e-04 - val_loss: 356.3837 - val_accuracy: 0.0000e+00\n",
            "Epoch 426/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 60.1323 - accuracy: 1.1834e-04 - val_loss: 331.2515 - val_accuracy: 0.0000e+00\n",
            "Epoch 427/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 52.6915 - accuracy: 1.1834e-04 - val_loss: 316.9284 - val_accuracy: 0.0000e+00\n",
            "Epoch 428/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 55.9292 - accuracy: 1.1834e-04 - val_loss: 348.6115 - val_accuracy: 0.0000e+00\n",
            "Epoch 429/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 55.0869 - accuracy: 1.1834e-04 - val_loss: 368.7562 - val_accuracy: 0.0000e+00\n",
            "Epoch 430/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 54.4514 - accuracy: 1.1834e-04 - val_loss: 393.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 431/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 56.2425 - accuracy: 1.1834e-04 - val_loss: 291.7337 - val_accuracy: 0.0000e+00\n",
            "Epoch 432/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 52.4529 - accuracy: 1.1834e-04 - val_loss: 365.6027 - val_accuracy: 0.0000e+00\n",
            "Epoch 433/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 53.0990 - accuracy: 1.1834e-04 - val_loss: 302.3530 - val_accuracy: 0.0000e+00\n",
            "Epoch 434/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 53.5079 - accuracy: 1.1834e-04 - val_loss: 345.8423 - val_accuracy: 0.0000e+00\n",
            "Epoch 435/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 54.0960 - accuracy: 1.1834e-04 - val_loss: 354.6397 - val_accuracy: 0.0000e+00\n",
            "Epoch 436/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 54.3518 - accuracy: 1.1834e-04 - val_loss: 328.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 437/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 59.5498 - accuracy: 1.1834e-04 - val_loss: 416.6052 - val_accuracy: 0.0000e+00\n",
            "Epoch 438/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 51.4627 - accuracy: 1.1834e-04 - val_loss: 326.7535 - val_accuracy: 0.0000e+00\n",
            "Epoch 439/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 50.7478 - accuracy: 1.1834e-04 - val_loss: 330.0632 - val_accuracy: 0.0000e+00\n",
            "Epoch 440/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 51.3835 - accuracy: 1.1834e-04 - val_loss: 351.6464 - val_accuracy: 0.0000e+00\n",
            "Epoch 441/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 54.9829 - accuracy: 1.1834e-04 - val_loss: 356.7028 - val_accuracy: 0.0000e+00\n",
            "Epoch 442/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 53.7533 - accuracy: 1.1834e-04 - val_loss: 390.7374 - val_accuracy: 0.0000e+00\n",
            "Epoch 443/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 54.3331 - accuracy: 1.1834e-04 - val_loss: 318.0582 - val_accuracy: 0.0000e+00\n",
            "Epoch 444/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 55.8489 - accuracy: 1.1834e-04 - val_loss: 424.0736 - val_accuracy: 0.0000e+00\n",
            "Epoch 445/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 59.5682 - accuracy: 1.1834e-04 - val_loss: 317.7941 - val_accuracy: 0.0000e+00\n",
            "Epoch 446/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 50.8629 - accuracy: 1.1834e-04 - val_loss: 422.5363 - val_accuracy: 0.0000e+00\n",
            "Epoch 447/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 50.5738 - accuracy: 1.1834e-04 - val_loss: 339.5049 - val_accuracy: 0.0000e+00\n",
            "Epoch 448/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 49.4603 - accuracy: 1.1834e-04 - val_loss: 310.8056 - val_accuracy: 0.0000e+00\n",
            "Epoch 449/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 55.5030 - accuracy: 1.1834e-04 - val_loss: 350.4191 - val_accuracy: 0.0000e+00\n",
            "Epoch 450/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 51.1344 - accuracy: 1.1834e-04 - val_loss: 323.9892 - val_accuracy: 0.0000e+00\n",
            "Epoch 451/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 50.5377 - accuracy: 1.1834e-04 - val_loss: 330.6856 - val_accuracy: 0.0000e+00\n",
            "Epoch 452/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 54.7141 - accuracy: 1.1834e-04 - val_loss: 352.5245 - val_accuracy: 0.0000e+00\n",
            "Epoch 453/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 51.1662 - accuracy: 1.1834e-04 - val_loss: 380.4031 - val_accuracy: 0.0000e+00\n",
            "Epoch 454/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 54.5386 - accuracy: 1.1834e-04 - val_loss: 399.5609 - val_accuracy: 0.0000e+00\n",
            "Epoch 455/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 49.7006 - accuracy: 1.1834e-04 - val_loss: 341.2499 - val_accuracy: 0.0000e+00\n",
            "Epoch 456/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 50.4974 - accuracy: 1.1834e-04 - val_loss: 311.9054 - val_accuracy: 0.0000e+00\n",
            "Epoch 457/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 49.0612 - accuracy: 1.1834e-04 - val_loss: 393.2482 - val_accuracy: 0.0000e+00\n",
            "Epoch 458/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 56.4955 - accuracy: 1.1834e-04 - val_loss: 379.6155 - val_accuracy: 0.0000e+00\n",
            "Epoch 459/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 47.3635 - accuracy: 1.1834e-04 - val_loss: 403.1102 - val_accuracy: 0.0000e+00\n",
            "Epoch 460/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 56.6797 - accuracy: 1.1834e-04 - val_loss: 391.0646 - val_accuracy: 0.0000e+00\n",
            "Epoch 461/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 47.7985 - accuracy: 1.1834e-04 - val_loss: 361.1213 - val_accuracy: 0.0000e+00\n",
            "Epoch 462/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 52.6635 - accuracy: 1.1834e-04 - val_loss: 472.0864 - val_accuracy: 0.0000e+00\n",
            "Epoch 463/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 60.0608 - accuracy: 1.1834e-04 - val_loss: 361.9400 - val_accuracy: 0.0000e+00\n",
            "Epoch 464/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 52.7500 - accuracy: 1.1834e-04 - val_loss: 374.5842 - val_accuracy: 0.0000e+00\n",
            "Epoch 465/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 50.3919 - accuracy: 1.1834e-04 - val_loss: 339.0505 - val_accuracy: 0.0000e+00\n",
            "Epoch 466/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 51.1407 - accuracy: 1.1834e-04 - val_loss: 364.5341 - val_accuracy: 0.0000e+00\n",
            "Epoch 467/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 55.8135 - accuracy: 1.1834e-04 - val_loss: 403.2800 - val_accuracy: 0.0000e+00\n",
            "Epoch 468/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 50.6311 - accuracy: 1.1834e-04 - val_loss: 393.0555 - val_accuracy: 0.0000e+00\n",
            "Epoch 469/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 47.0754 - accuracy: 1.1834e-04 - val_loss: 362.0463 - val_accuracy: 0.0000e+00\n",
            "Epoch 470/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 51.0221 - accuracy: 1.1834e-04 - val_loss: 372.6489 - val_accuracy: 0.0000e+00\n",
            "Epoch 471/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 50.7243 - accuracy: 1.1834e-04 - val_loss: 338.7419 - val_accuracy: 0.0000e+00\n",
            "Epoch 472/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 45.3881 - accuracy: 1.1834e-04 - val_loss: 428.6436 - val_accuracy: 0.0000e+00\n",
            "Epoch 473/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 51.3628 - accuracy: 1.1834e-04 - val_loss: 355.0284 - val_accuracy: 0.0000e+00\n",
            "Epoch 474/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 45.7535 - accuracy: 1.1834e-04 - val_loss: 372.4677 - val_accuracy: 0.0000e+00\n",
            "Epoch 475/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 45.8698 - accuracy: 1.1834e-04 - val_loss: 340.7236 - val_accuracy: 0.0000e+00\n",
            "Epoch 476/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 46.8933 - accuracy: 1.1834e-04 - val_loss: 356.0407 - val_accuracy: 0.0000e+00\n",
            "Epoch 477/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 47.2753 - accuracy: 1.1834e-04 - val_loss: 434.3846 - val_accuracy: 0.0000e+00\n",
            "Epoch 478/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 47.1484 - accuracy: 1.1834e-04 - val_loss: 451.0231 - val_accuracy: 0.0000e+00\n",
            "Epoch 479/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 49.6269 - accuracy: 1.1834e-04 - val_loss: 338.5341 - val_accuracy: 0.0000e+00\n",
            "Epoch 480/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 53.7707 - accuracy: 1.1834e-04 - val_loss: 360.9799 - val_accuracy: 0.0000e+00\n",
            "Epoch 481/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 47.1221 - accuracy: 1.1834e-04 - val_loss: 388.3335 - val_accuracy: 0.0000e+00\n",
            "Epoch 482/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 56.0685 - accuracy: 1.1834e-04 - val_loss: 334.7888 - val_accuracy: 0.0000e+00\n",
            "Epoch 483/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 50.2441 - accuracy: 1.1834e-04 - val_loss: 339.4679 - val_accuracy: 0.0000e+00\n",
            "Epoch 484/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 48.6726 - accuracy: 1.1834e-04 - val_loss: 423.3282 - val_accuracy: 0.0000e+00\n",
            "Epoch 485/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 46.5014 - accuracy: 1.1834e-04 - val_loss: 354.1583 - val_accuracy: 0.0000e+00\n",
            "Epoch 486/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 47.4407 - accuracy: 1.1834e-04 - val_loss: 333.2873 - val_accuracy: 0.0000e+00\n",
            "Epoch 487/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 47.8071 - accuracy: 1.1834e-04 - val_loss: 328.7582 - val_accuracy: 0.0000e+00\n",
            "Epoch 488/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 48.9453 - accuracy: 1.1834e-04 - val_loss: 335.6194 - val_accuracy: 0.0000e+00\n",
            "Epoch 489/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 45.7422 - accuracy: 1.1834e-04 - val_loss: 323.1684 - val_accuracy: 0.0000e+00\n",
            "Epoch 490/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 46.8252 - accuracy: 1.1834e-04 - val_loss: 368.2217 - val_accuracy: 0.0000e+00\n",
            "Epoch 491/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 44.0265 - accuracy: 1.1834e-04 - val_loss: 332.8439 - val_accuracy: 0.0000e+00\n",
            "Epoch 492/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 46.6924 - accuracy: 1.1834e-04 - val_loss: 372.2871 - val_accuracy: 0.0000e+00\n",
            "Epoch 493/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 49.4309 - accuracy: 1.1834e-04 - val_loss: 429.6289 - val_accuracy: 0.0000e+00\n",
            "Epoch 494/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 48.7751 - accuracy: 1.1834e-04 - val_loss: 365.6713 - val_accuracy: 0.0000e+00\n",
            "Epoch 495/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 45.6844 - accuracy: 1.1834e-04 - val_loss: 422.8818 - val_accuracy: 0.0000e+00\n",
            "Epoch 496/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 46.3281 - accuracy: 1.1834e-04 - val_loss: 349.4211 - val_accuracy: 0.0000e+00\n",
            "Epoch 497/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 45.2261 - accuracy: 1.1834e-04 - val_loss: 397.6957 - val_accuracy: 0.0000e+00\n",
            "Epoch 498/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 46.3422 - accuracy: 1.1834e-04 - val_loss: 359.5409 - val_accuracy: 0.0000e+00\n",
            "Epoch 499/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 42.3153 - accuracy: 1.1834e-04 - val_loss: 366.5103 - val_accuracy: 0.0000e+00\n",
            "Epoch 500/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 46.3230 - accuracy: 1.1834e-04 - val_loss: 349.8464 - val_accuracy: 0.0000e+00\n",
            "Epoch 501/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 46.3473 - accuracy: 1.1834e-04 - val_loss: 381.8677 - val_accuracy: 0.0000e+00\n",
            "Epoch 502/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 44.3603 - accuracy: 1.1834e-04 - val_loss: 364.0533 - val_accuracy: 0.0000e+00\n",
            "Epoch 503/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 45.1959 - accuracy: 1.1834e-04 - val_loss: 370.5538 - val_accuracy: 0.0000e+00\n",
            "Epoch 504/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 43.5266 - accuracy: 1.1834e-04 - val_loss: 391.4979 - val_accuracy: 0.0000e+00\n",
            "Epoch 505/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 46.6371 - accuracy: 1.1834e-04 - val_loss: 358.9833 - val_accuracy: 0.0000e+00\n",
            "Epoch 506/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 43.9981 - accuracy: 1.1834e-04 - val_loss: 383.1124 - val_accuracy: 0.0000e+00\n",
            "Epoch 507/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 42.6543 - accuracy: 1.1834e-04 - val_loss: 395.9758 - val_accuracy: 0.0000e+00\n",
            "Epoch 508/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 49.3560 - accuracy: 1.1834e-04 - val_loss: 351.8254 - val_accuracy: 0.0000e+00\n",
            "Epoch 509/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 52.9171 - accuracy: 1.1834e-04 - val_loss: 437.1342 - val_accuracy: 0.0000e+00\n",
            "Epoch 510/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 45.7386 - accuracy: 1.1834e-04 - val_loss: 362.6361 - val_accuracy: 0.0000e+00\n",
            "Epoch 511/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 42.1266 - accuracy: 1.1834e-04 - val_loss: 398.8834 - val_accuracy: 0.0000e+00\n",
            "Epoch 512/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 43.6331 - accuracy: 1.1834e-04 - val_loss: 411.8635 - val_accuracy: 0.0000e+00\n",
            "Epoch 513/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 41.4023 - accuracy: 1.1834e-04 - val_loss: 433.3405 - val_accuracy: 0.0000e+00\n",
            "Epoch 514/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 44.2572 - accuracy: 1.1834e-04 - val_loss: 393.8534 - val_accuracy: 0.0000e+00\n",
            "Epoch 515/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 42.5539 - accuracy: 1.1834e-04 - val_loss: 410.6772 - val_accuracy: 0.0000e+00\n",
            "Epoch 516/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 44.0957 - accuracy: 1.1834e-04 - val_loss: 408.8532 - val_accuracy: 0.0000e+00\n",
            "Epoch 517/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 44.8228 - accuracy: 1.1834e-04 - val_loss: 406.5596 - val_accuracy: 0.0000e+00\n",
            "Epoch 518/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 53.5555 - accuracy: 1.1834e-04 - val_loss: 449.8993 - val_accuracy: 0.0000e+00\n",
            "Epoch 519/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 50.5227 - accuracy: 1.1834e-04 - val_loss: 438.4166 - val_accuracy: 0.0000e+00\n",
            "Epoch 520/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 48.9500 - accuracy: 1.1834e-04 - val_loss: 405.7968 - val_accuracy: 0.0000e+00\n",
            "Epoch 521/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 43.5551 - accuracy: 1.1834e-04 - val_loss: 353.1799 - val_accuracy: 0.0000e+00\n",
            "Epoch 522/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 43.0546 - accuracy: 1.1834e-04 - val_loss: 453.4794 - val_accuracy: 0.0000e+00\n",
            "Epoch 523/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 45.3278 - accuracy: 1.1834e-04 - val_loss: 373.7544 - val_accuracy: 0.0000e+00\n",
            "Epoch 524/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 44.9756 - accuracy: 1.1834e-04 - val_loss: 364.8465 - val_accuracy: 0.0000e+00\n",
            "Epoch 525/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 51.3062 - accuracy: 1.1834e-04 - val_loss: 356.1504 - val_accuracy: 0.0000e+00\n",
            "Epoch 526/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 43.8502 - accuracy: 1.1834e-04 - val_loss: 459.1563 - val_accuracy: 0.0000e+00\n",
            "Epoch 527/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 44.4276 - accuracy: 1.1834e-04 - val_loss: 350.8826 - val_accuracy: 0.0000e+00\n",
            "Epoch 528/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 43.7960 - accuracy: 1.1834e-04 - val_loss: 426.9451 - val_accuracy: 0.0000e+00\n",
            "Epoch 529/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 52.9747 - accuracy: 1.1834e-04 - val_loss: 395.3990 - val_accuracy: 0.0000e+00\n",
            "Epoch 530/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 41.5154 - accuracy: 1.1834e-04 - val_loss: 433.7549 - val_accuracy: 0.0000e+00\n",
            "Epoch 531/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 47.7139 - accuracy: 1.1834e-04 - val_loss: 359.2194 - val_accuracy: 0.0000e+00\n",
            "Epoch 532/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 41.9288 - accuracy: 1.1834e-04 - val_loss: 419.4444 - val_accuracy: 0.0000e+00\n",
            "Epoch 533/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 40.2278 - accuracy: 1.1834e-04 - val_loss: 395.5042 - val_accuracy: 0.0000e+00\n",
            "Epoch 534/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 40.7087 - accuracy: 1.1834e-04 - val_loss: 383.2081 - val_accuracy: 0.0000e+00\n",
            "Epoch 535/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 41.3854 - accuracy: 1.1834e-04 - val_loss: 379.7909 - val_accuracy: 0.0000e+00\n",
            "Epoch 536/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 41.6450 - accuracy: 1.1834e-04 - val_loss: 422.8490 - val_accuracy: 0.0000e+00\n",
            "Epoch 537/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 40.9450 - accuracy: 1.1834e-04 - val_loss: 447.0005 - val_accuracy: 0.0000e+00\n",
            "Epoch 538/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 41.3801 - accuracy: 1.1834e-04 - val_loss: 391.6044 - val_accuracy: 0.0000e+00\n",
            "Epoch 539/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 42.9546 - accuracy: 1.1834e-04 - val_loss: 370.5407 - val_accuracy: 0.0000e+00\n",
            "Epoch 540/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 40.6168 - accuracy: 1.1834e-04 - val_loss: 443.6239 - val_accuracy: 0.0000e+00\n",
            "Epoch 541/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 41.2306 - accuracy: 1.1834e-04 - val_loss: 391.8569 - val_accuracy: 0.0000e+00\n",
            "Epoch 542/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 43.4363 - accuracy: 1.1834e-04 - val_loss: 399.6986 - val_accuracy: 0.0000e+00\n",
            "Epoch 543/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 38.8134 - accuracy: 1.1834e-04 - val_loss: 378.0206 - val_accuracy: 0.0000e+00\n",
            "Epoch 544/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 41.1482 - accuracy: 1.1834e-04 - val_loss: 423.5551 - val_accuracy: 0.0000e+00\n",
            "Epoch 545/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 40.1357 - accuracy: 1.1834e-04 - val_loss: 420.8881 - val_accuracy: 0.0000e+00\n",
            "Epoch 546/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 43.3412 - accuracy: 1.1834e-04 - val_loss: 396.6104 - val_accuracy: 0.0000e+00\n",
            "Epoch 547/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 40.4290 - accuracy: 1.1834e-04 - val_loss: 381.9291 - val_accuracy: 0.0000e+00\n",
            "Epoch 548/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 39.0643 - accuracy: 1.1834e-04 - val_loss: 441.9280 - val_accuracy: 0.0000e+00\n",
            "Epoch 549/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 40.7915 - accuracy: 1.1834e-04 - val_loss: 441.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 550/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 41.1776 - accuracy: 1.1834e-04 - val_loss: 422.3216 - val_accuracy: 0.0000e+00\n",
            "Epoch 551/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 42.9926 - accuracy: 1.1834e-04 - val_loss: 433.9710 - val_accuracy: 0.0000e+00\n",
            "Epoch 552/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 41.1559 - accuracy: 1.1834e-04 - val_loss: 344.1616 - val_accuracy: 0.0000e+00\n",
            "Epoch 553/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 40.9184 - accuracy: 1.1834e-04 - val_loss: 418.8651 - val_accuracy: 0.0000e+00\n",
            "Epoch 554/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 42.1027 - accuracy: 1.1834e-04 - val_loss: 370.4838 - val_accuracy: 0.0000e+00\n",
            "Epoch 555/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 46.7144 - accuracy: 1.1834e-04 - val_loss: 449.2447 - val_accuracy: 0.0000e+00\n",
            "Epoch 556/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 41.1339 - accuracy: 1.1834e-04 - val_loss: 396.9566 - val_accuracy: 0.0000e+00\n",
            "Epoch 557/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 38.5120 - accuracy: 1.1834e-04 - val_loss: 438.6620 - val_accuracy: 0.0000e+00\n",
            "Epoch 558/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 42.1545 - accuracy: 1.1834e-04 - val_loss: 419.6723 - val_accuracy: 0.0000e+00\n",
            "Epoch 559/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 37.9671 - accuracy: 1.1834e-04 - val_loss: 381.9086 - val_accuracy: 0.0000e+00\n",
            "Epoch 560/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 40.6025 - accuracy: 1.1834e-04 - val_loss: 376.6644 - val_accuracy: 0.0000e+00\n",
            "Epoch 561/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 45.9462 - accuracy: 1.1834e-04 - val_loss: 384.7749 - val_accuracy: 0.0000e+00\n",
            "Epoch 562/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 36.4286 - accuracy: 1.1834e-04 - val_loss: 368.5143 - val_accuracy: 0.0000e+00\n",
            "Epoch 563/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 40.1205 - accuracy: 1.1834e-04 - val_loss: 386.7267 - val_accuracy: 0.0000e+00\n",
            "Epoch 564/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 39.6146 - accuracy: 1.1834e-04 - val_loss: 391.0525 - val_accuracy: 0.0000e+00\n",
            "Epoch 565/1000\n",
            "29/29 [==============================] - 1s 31ms/step - loss: 39.6252 - accuracy: 1.1834e-04 - val_loss: 401.4747 - val_accuracy: 0.0000e+00\n",
            "Epoch 566/1000\n",
            "29/29 [==============================] - 1s 31ms/step - loss: 41.5458 - accuracy: 1.1834e-04 - val_loss: 530.2379 - val_accuracy: 0.0000e+00\n",
            "Epoch 567/1000\n",
            "29/29 [==============================] - 1s 33ms/step - loss: 40.9690 - accuracy: 1.1834e-04 - val_loss: 346.5921 - val_accuracy: 0.0000e+00\n",
            "Epoch 568/1000\n",
            "29/29 [==============================] - 1s 40ms/step - loss: 39.5317 - accuracy: 1.1834e-04 - val_loss: 414.1231 - val_accuracy: 0.0000e+00\n",
            "Epoch 569/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 42.1501 - accuracy: 1.1834e-04 - val_loss: 345.5653 - val_accuracy: 0.0000e+00\n",
            "Epoch 570/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 41.2294 - accuracy: 1.1834e-04 - val_loss: 431.3618 - val_accuracy: 0.0000e+00\n",
            "Epoch 571/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 38.1167 - accuracy: 1.1834e-04 - val_loss: 458.1314 - val_accuracy: 0.0000e+00\n",
            "Epoch 572/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 40.6894 - accuracy: 1.1834e-04 - val_loss: 406.6731 - val_accuracy: 0.0000e+00\n",
            "Epoch 573/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 38.2255 - accuracy: 1.1834e-04 - val_loss: 421.9722 - val_accuracy: 0.0000e+00\n",
            "Epoch 574/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 40.7109 - accuracy: 1.1834e-04 - val_loss: 426.4733 - val_accuracy: 0.0000e+00\n",
            "Epoch 575/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 42.4841 - accuracy: 1.1834e-04 - val_loss: 430.6086 - val_accuracy: 0.0000e+00\n",
            "Epoch 576/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 42.3476 - accuracy: 1.1834e-04 - val_loss: 387.9120 - val_accuracy: 0.0000e+00\n",
            "Epoch 577/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 42.3429 - accuracy: 1.1834e-04 - val_loss: 433.7849 - val_accuracy: 0.0000e+00\n",
            "Epoch 578/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 47.9854 - accuracy: 1.1834e-04 - val_loss: 472.1542 - val_accuracy: 0.0000e+00\n",
            "Epoch 579/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 39.0105 - accuracy: 1.1834e-04 - val_loss: 414.9460 - val_accuracy: 0.0000e+00\n",
            "Epoch 580/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 38.5049 - accuracy: 1.1834e-04 - val_loss: 398.3348 - val_accuracy: 0.0000e+00\n",
            "Epoch 581/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 44.8394 - accuracy: 1.1834e-04 - val_loss: 463.7366 - val_accuracy: 0.0000e+00\n",
            "Epoch 582/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 40.4794 - accuracy: 1.1834e-04 - val_loss: 444.3429 - val_accuracy: 0.0000e+00\n",
            "Epoch 583/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 37.2392 - accuracy: 1.1834e-04 - val_loss: 426.8250 - val_accuracy: 0.0000e+00\n",
            "Epoch 584/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 38.0135 - accuracy: 1.1834e-04 - val_loss: 366.3340 - val_accuracy: 0.0000e+00\n",
            "Epoch 585/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 38.9388 - accuracy: 1.1834e-04 - val_loss: 416.9013 - val_accuracy: 0.0000e+00\n",
            "Epoch 586/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 39.8726 - accuracy: 1.1834e-04 - val_loss: 409.1196 - val_accuracy: 0.0000e+00\n",
            "Epoch 587/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 36.2026 - accuracy: 1.1834e-04 - val_loss: 410.2372 - val_accuracy: 0.0000e+00\n",
            "Epoch 588/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 42.2648 - accuracy: 1.1834e-04 - val_loss: 463.4199 - val_accuracy: 0.0000e+00\n",
            "Epoch 589/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 42.8326 - accuracy: 1.1834e-04 - val_loss: 487.7738 - val_accuracy: 0.0000e+00\n",
            "Epoch 590/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 41.0219 - accuracy: 1.1834e-04 - val_loss: 412.4236 - val_accuracy: 0.0000e+00\n",
            "Epoch 591/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 36.4640 - accuracy: 1.1834e-04 - val_loss: 436.6237 - val_accuracy: 0.0000e+00\n",
            "Epoch 592/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 36.0103 - accuracy: 1.1834e-04 - val_loss: 400.2611 - val_accuracy: 0.0000e+00\n",
            "Epoch 593/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 36.7520 - accuracy: 1.1834e-04 - val_loss: 406.4773 - val_accuracy: 0.0000e+00\n",
            "Epoch 594/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 35.8120 - accuracy: 1.1834e-04 - val_loss: 412.6291 - val_accuracy: 0.0000e+00\n",
            "Epoch 595/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 35.9747 - accuracy: 1.1834e-04 - val_loss: 443.6678 - val_accuracy: 0.0000e+00\n",
            "Epoch 596/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 39.8145 - accuracy: 1.1834e-04 - val_loss: 435.7207 - val_accuracy: 0.0000e+00\n",
            "Epoch 597/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 36.6191 - accuracy: 1.1834e-04 - val_loss: 418.3055 - val_accuracy: 0.0000e+00\n",
            "Epoch 598/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 39.7317 - accuracy: 1.1834e-04 - val_loss: 419.3813 - val_accuracy: 0.0000e+00\n",
            "Epoch 599/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 44.6635 - accuracy: 1.1834e-04 - val_loss: 417.0208 - val_accuracy: 0.0000e+00\n",
            "Epoch 600/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 36.8365 - accuracy: 1.1834e-04 - val_loss: 412.4193 - val_accuracy: 0.0000e+00\n",
            "Epoch 601/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 37.6962 - accuracy: 1.1834e-04 - val_loss: 447.3203 - val_accuracy: 0.0000e+00\n",
            "Epoch 602/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 39.7066 - accuracy: 1.1834e-04 - val_loss: 434.4650 - val_accuracy: 0.0000e+00\n",
            "Epoch 603/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 42.9430 - accuracy: 1.1834e-04 - val_loss: 412.2079 - val_accuracy: 0.0000e+00\n",
            "Epoch 604/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 35.8822 - accuracy: 1.1834e-04 - val_loss: 399.2662 - val_accuracy: 0.0000e+00\n",
            "Epoch 605/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 37.9532 - accuracy: 1.1834e-04 - val_loss: 459.1473 - val_accuracy: 0.0000e+00\n",
            "Epoch 606/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 42.8057 - accuracy: 1.1834e-04 - val_loss: 371.8653 - val_accuracy: 0.0000e+00\n",
            "Epoch 607/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 36.4983 - accuracy: 1.1834e-04 - val_loss: 424.6502 - val_accuracy: 0.0000e+00\n",
            "Epoch 608/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 38.0715 - accuracy: 1.1834e-04 - val_loss: 444.4981 - val_accuracy: 0.0000e+00\n",
            "Epoch 609/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 37.1503 - accuracy: 1.1834e-04 - val_loss: 407.1198 - val_accuracy: 0.0000e+00\n",
            "Epoch 610/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 40.7555 - accuracy: 1.1834e-04 - val_loss: 448.6201 - val_accuracy: 0.0000e+00\n",
            "Epoch 611/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 41.8058 - accuracy: 1.1834e-04 - val_loss: 402.6753 - val_accuracy: 0.0000e+00\n",
            "Epoch 612/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 38.7522 - accuracy: 1.1834e-04 - val_loss: 415.3782 - val_accuracy: 0.0000e+00\n",
            "Epoch 613/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 36.7680 - accuracy: 1.1834e-04 - val_loss: 421.9309 - val_accuracy: 0.0000e+00\n",
            "Epoch 614/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 35.6034 - accuracy: 1.1834e-04 - val_loss: 403.4255 - val_accuracy: 0.0000e+00\n",
            "Epoch 615/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 35.6269 - accuracy: 1.1834e-04 - val_loss: 433.2107 - val_accuracy: 0.0000e+00\n",
            "Epoch 616/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 40.4791 - accuracy: 1.1834e-04 - val_loss: 366.7155 - val_accuracy: 0.0000e+00\n",
            "Epoch 617/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 35.0113 - accuracy: 1.1834e-04 - val_loss: 427.4064 - val_accuracy: 0.0000e+00\n",
            "Epoch 618/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 37.9247 - accuracy: 1.1834e-04 - val_loss: 461.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 619/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 37.7819 - accuracy: 1.1834e-04 - val_loss: 441.1504 - val_accuracy: 0.0000e+00\n",
            "Epoch 620/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 37.4897 - accuracy: 1.1834e-04 - val_loss: 464.6091 - val_accuracy: 0.0000e+00\n",
            "Epoch 621/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 38.2161 - accuracy: 1.1834e-04 - val_loss: 401.4262 - val_accuracy: 0.0000e+00\n",
            "Epoch 622/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 40.5358 - accuracy: 1.1834e-04 - val_loss: 419.1466 - val_accuracy: 0.0000e+00\n",
            "Epoch 623/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 38.5587 - accuracy: 1.1834e-04 - val_loss: 406.4531 - val_accuracy: 0.0000e+00\n",
            "Epoch 624/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 43.9044 - accuracy: 1.1834e-04 - val_loss: 398.1583 - val_accuracy: 0.0000e+00\n",
            "Epoch 625/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 38.9875 - accuracy: 1.1834e-04 - val_loss: 523.7507 - val_accuracy: 0.0000e+00\n",
            "Epoch 626/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 35.0794 - accuracy: 1.1834e-04 - val_loss: 467.4140 - val_accuracy: 0.0000e+00\n",
            "Epoch 627/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 34.1958 - accuracy: 1.1834e-04 - val_loss: 447.5348 - val_accuracy: 0.0000e+00\n",
            "Epoch 628/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 35.8123 - accuracy: 1.1834e-04 - val_loss: 408.9874 - val_accuracy: 0.0000e+00\n",
            "Epoch 629/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 38.8182 - accuracy: 1.1834e-04 - val_loss: 385.8784 - val_accuracy: 0.0000e+00\n",
            "Epoch 630/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 38.8439 - accuracy: 1.1834e-04 - val_loss: 483.2550 - val_accuracy: 0.0000e+00\n",
            "Epoch 631/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 39.1844 - accuracy: 1.1834e-04 - val_loss: 401.1239 - val_accuracy: 0.0000e+00\n",
            "Epoch 632/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 37.7626 - accuracy: 1.1834e-04 - val_loss: 447.4123 - val_accuracy: 0.0000e+00\n",
            "Epoch 633/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 41.0788 - accuracy: 1.1834e-04 - val_loss: 457.4745 - val_accuracy: 0.0000e+00\n",
            "Epoch 634/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 35.2170 - accuracy: 1.1834e-04 - val_loss: 429.2833 - val_accuracy: 0.0000e+00\n",
            "Epoch 635/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 34.0456 - accuracy: 1.1834e-04 - val_loss: 399.1356 - val_accuracy: 0.0000e+00\n",
            "Epoch 636/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 38.9311 - accuracy: 1.1834e-04 - val_loss: 428.1931 - val_accuracy: 0.0000e+00\n",
            "Epoch 637/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 37.7228 - accuracy: 1.1834e-04 - val_loss: 384.1944 - val_accuracy: 0.0000e+00\n",
            "Epoch 638/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 39.1891 - accuracy: 1.1834e-04 - val_loss: 396.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 639/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 36.2518 - accuracy: 1.1834e-04 - val_loss: 434.9734 - val_accuracy: 0.0000e+00\n",
            "Epoch 640/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 39.1344 - accuracy: 1.1834e-04 - val_loss: 463.5608 - val_accuracy: 0.0000e+00\n",
            "Epoch 641/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 35.5207 - accuracy: 1.1834e-04 - val_loss: 466.4266 - val_accuracy: 0.0000e+00\n",
            "Epoch 642/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 40.8826 - accuracy: 1.1834e-04 - val_loss: 434.6056 - val_accuracy: 0.0000e+00\n",
            "Epoch 643/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 36.2600 - accuracy: 1.1834e-04 - val_loss: 408.5317 - val_accuracy: 0.0000e+00\n",
            "Epoch 644/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 34.6782 - accuracy: 1.1834e-04 - val_loss: 442.2326 - val_accuracy: 0.0000e+00\n",
            "Epoch 645/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 34.3644 - accuracy: 1.1834e-04 - val_loss: 449.2172 - val_accuracy: 0.0000e+00\n",
            "Epoch 646/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 40.3376 - accuracy: 1.1834e-04 - val_loss: 435.2561 - val_accuracy: 0.0000e+00\n",
            "Epoch 647/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 40.3156 - accuracy: 1.1834e-04 - val_loss: 434.9490 - val_accuracy: 0.0000e+00\n",
            "Epoch 648/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 34.1656 - accuracy: 1.1834e-04 - val_loss: 453.8756 - val_accuracy: 0.0000e+00\n",
            "Epoch 649/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 34.3447 - accuracy: 1.1834e-04 - val_loss: 412.5273 - val_accuracy: 0.0000e+00\n",
            "Epoch 650/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 40.8342 - accuracy: 1.1834e-04 - val_loss: 429.1507 - val_accuracy: 0.0000e+00\n",
            "Epoch 651/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 35.5030 - accuracy: 1.1834e-04 - val_loss: 427.2582 - val_accuracy: 0.0000e+00\n",
            "Epoch 652/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 33.9332 - accuracy: 1.1834e-04 - val_loss: 414.5493 - val_accuracy: 0.0000e+00\n",
            "Epoch 653/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 34.9137 - accuracy: 1.1834e-04 - val_loss: 446.0855 - val_accuracy: 0.0000e+00\n",
            "Epoch 654/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 37.9870 - accuracy: 1.1834e-04 - val_loss: 438.6822 - val_accuracy: 0.0000e+00\n",
            "Epoch 655/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 38.6323 - accuracy: 1.1834e-04 - val_loss: 396.3801 - val_accuracy: 0.0000e+00\n",
            "Epoch 656/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 36.0992 - accuracy: 1.1834e-04 - val_loss: 398.3253 - val_accuracy: 0.0000e+00\n",
            "Epoch 657/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 37.1127 - accuracy: 1.1834e-04 - val_loss: 375.9973 - val_accuracy: 0.0000e+00\n",
            "Epoch 658/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 41.5219 - accuracy: 1.1834e-04 - val_loss: 414.5609 - val_accuracy: 0.0000e+00\n",
            "Epoch 659/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 40.1742 - accuracy: 1.1834e-04 - val_loss: 390.2398 - val_accuracy: 0.0000e+00\n",
            "Epoch 660/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 31.6039 - accuracy: 1.1834e-04 - val_loss: 412.2723 - val_accuracy: 0.0000e+00\n",
            "Epoch 661/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 33.9988 - accuracy: 1.1834e-04 - val_loss: 412.3021 - val_accuracy: 0.0000e+00\n",
            "Epoch 662/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 33.2290 - accuracy: 1.1834e-04 - val_loss: 405.3288 - val_accuracy: 0.0000e+00\n",
            "Epoch 663/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 34.5888 - accuracy: 1.1834e-04 - val_loss: 376.0147 - val_accuracy: 0.0000e+00\n",
            "Epoch 664/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 41.0512 - accuracy: 1.1834e-04 - val_loss: 474.6136 - val_accuracy: 0.0000e+00\n",
            "Epoch 665/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 36.5892 - accuracy: 1.1834e-04 - val_loss: 453.6404 - val_accuracy: 0.0000e+00\n",
            "Epoch 666/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 33.1941 - accuracy: 1.1834e-04 - val_loss: 417.9901 - val_accuracy: 0.0000e+00\n",
            "Epoch 667/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 37.4010 - accuracy: 1.1834e-04 - val_loss: 409.7837 - val_accuracy: 0.0000e+00\n",
            "Epoch 668/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 32.8961 - accuracy: 1.1834e-04 - val_loss: 405.1750 - val_accuracy: 0.0000e+00\n",
            "Epoch 669/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 34.1067 - accuracy: 1.1834e-04 - val_loss: 432.5635 - val_accuracy: 0.0000e+00\n",
            "Epoch 670/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 32.9810 - accuracy: 1.1834e-04 - val_loss: 429.8172 - val_accuracy: 0.0000e+00\n",
            "Epoch 671/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 32.5337 - accuracy: 1.1834e-04 - val_loss: 398.6271 - val_accuracy: 0.0000e+00\n",
            "Epoch 672/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 34.5887 - accuracy: 1.1834e-04 - val_loss: 400.1889 - val_accuracy: 0.0000e+00\n",
            "Epoch 673/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 32.3259 - accuracy: 1.1834e-04 - val_loss: 430.9213 - val_accuracy: 0.0000e+00\n",
            "Epoch 674/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 38.0962 - accuracy: 1.1834e-04 - val_loss: 425.8931 - val_accuracy: 0.0000e+00\n",
            "Epoch 675/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 33.3194 - accuracy: 1.1834e-04 - val_loss: 435.6867 - val_accuracy: 0.0000e+00\n",
            "Epoch 676/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 34.7486 - accuracy: 1.1834e-04 - val_loss: 410.6416 - val_accuracy: 0.0000e+00\n",
            "Epoch 677/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 31.4100 - accuracy: 1.1834e-04 - val_loss: 429.7439 - val_accuracy: 0.0000e+00\n",
            "Epoch 678/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 30.7361 - accuracy: 1.1834e-04 - val_loss: 391.9874 - val_accuracy: 0.0000e+00\n",
            "Epoch 679/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 32.8765 - accuracy: 1.1834e-04 - val_loss: 399.3827 - val_accuracy: 0.0000e+00\n",
            "Epoch 680/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 32.1456 - accuracy: 1.1834e-04 - val_loss: 389.4762 - val_accuracy: 0.0000e+00\n",
            "Epoch 681/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 31.4726 - accuracy: 1.1834e-04 - val_loss: 412.2940 - val_accuracy: 0.0000e+00\n",
            "Epoch 682/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 32.0636 - accuracy: 1.1834e-04 - val_loss: 420.3839 - val_accuracy: 0.0000e+00\n",
            "Epoch 683/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 30.7780 - accuracy: 1.1834e-04 - val_loss: 417.0290 - val_accuracy: 0.0000e+00\n",
            "Epoch 684/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 36.2032 - accuracy: 1.1834e-04 - val_loss: 413.2729 - val_accuracy: 0.0000e+00\n",
            "Epoch 685/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 36.7389 - accuracy: 1.1834e-04 - val_loss: 381.5535 - val_accuracy: 0.0000e+00\n",
            "Epoch 686/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 36.2149 - accuracy: 1.1834e-04 - val_loss: 415.4488 - val_accuracy: 0.0000e+00\n",
            "Epoch 687/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 33.4797 - accuracy: 1.1834e-04 - val_loss: 397.2243 - val_accuracy: 0.0000e+00\n",
            "Epoch 688/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 40.4876 - accuracy: 1.1834e-04 - val_loss: 478.5330 - val_accuracy: 0.0000e+00\n",
            "Epoch 689/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 37.6282 - accuracy: 1.1834e-04 - val_loss: 435.9236 - val_accuracy: 0.0000e+00\n",
            "Epoch 690/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 37.0754 - accuracy: 1.1834e-04 - val_loss: 404.9789 - val_accuracy: 0.0000e+00\n",
            "Epoch 691/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 34.8887 - accuracy: 1.1834e-04 - val_loss: 448.1080 - val_accuracy: 0.0000e+00\n",
            "Epoch 692/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 33.8056 - accuracy: 1.1834e-04 - val_loss: 430.1159 - val_accuracy: 0.0000e+00\n",
            "Epoch 693/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 30.4433 - accuracy: 1.1834e-04 - val_loss: 453.9859 - val_accuracy: 0.0000e+00\n",
            "Epoch 694/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 30.3182 - accuracy: 1.1834e-04 - val_loss: 410.5598 - val_accuracy: 0.0000e+00\n",
            "Epoch 695/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 31.9716 - accuracy: 1.1834e-04 - val_loss: 442.5401 - val_accuracy: 0.0000e+00\n",
            "Epoch 696/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 34.8225 - accuracy: 1.1834e-04 - val_loss: 406.3756 - val_accuracy: 0.0000e+00\n",
            "Epoch 697/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 35.1527 - accuracy: 1.1834e-04 - val_loss: 429.3253 - val_accuracy: 0.0000e+00\n",
            "Epoch 698/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 33.8118 - accuracy: 1.1834e-04 - val_loss: 406.0888 - val_accuracy: 0.0000e+00\n",
            "Epoch 699/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 33.5097 - accuracy: 1.1834e-04 - val_loss: 390.1115 - val_accuracy: 0.0000e+00\n",
            "Epoch 700/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 33.4931 - accuracy: 1.1834e-04 - val_loss: 480.3680 - val_accuracy: 0.0000e+00\n",
            "Epoch 701/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 34.1587 - accuracy: 1.1834e-04 - val_loss: 439.9215 - val_accuracy: 0.0000e+00\n",
            "Epoch 702/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 33.0245 - accuracy: 1.1834e-04 - val_loss: 386.9476 - val_accuracy: 0.0000e+00\n",
            "Epoch 703/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 35.5115 - accuracy: 1.1834e-04 - val_loss: 438.4672 - val_accuracy: 0.0000e+00\n",
            "Epoch 704/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 35.9859 - accuracy: 1.1834e-04 - val_loss: 413.2323 - val_accuracy: 0.0000e+00\n",
            "Epoch 705/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 39.0879 - accuracy: 1.1834e-04 - val_loss: 359.1048 - val_accuracy: 0.0000e+00\n",
            "Epoch 706/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 33.7829 - accuracy: 1.1834e-04 - val_loss: 409.5975 - val_accuracy: 0.0000e+00\n",
            "Epoch 707/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 33.0423 - accuracy: 1.1834e-04 - val_loss: 461.0685 - val_accuracy: 0.0000e+00\n",
            "Epoch 708/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 31.9949 - accuracy: 1.1834e-04 - val_loss: 412.5059 - val_accuracy: 0.0000e+00\n",
            "Epoch 709/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 31.1654 - accuracy: 1.1834e-04 - val_loss: 425.3281 - val_accuracy: 0.0000e+00\n",
            "Epoch 710/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 38.6827 - accuracy: 1.1834e-04 - val_loss: 392.8432 - val_accuracy: 0.0000e+00\n",
            "Epoch 711/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 35.3711 - accuracy: 1.1834e-04 - val_loss: 406.1496 - val_accuracy: 0.0000e+00\n",
            "Epoch 712/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 35.2264 - accuracy: 1.1834e-04 - val_loss: 422.9088 - val_accuracy: 0.0000e+00\n",
            "Epoch 713/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 34.5858 - accuracy: 1.1834e-04 - val_loss: 448.2302 - val_accuracy: 0.0000e+00\n",
            "Epoch 714/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 31.6168 - accuracy: 1.1834e-04 - val_loss: 438.5499 - val_accuracy: 0.0000e+00\n",
            "Epoch 715/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 35.1539 - accuracy: 1.1834e-04 - val_loss: 421.1955 - val_accuracy: 0.0000e+00\n",
            "Epoch 716/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 32.3779 - accuracy: 1.1834e-04 - val_loss: 481.2408 - val_accuracy: 0.0000e+00\n",
            "Epoch 717/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 32.3751 - accuracy: 1.1834e-04 - val_loss: 395.9795 - val_accuracy: 0.0000e+00\n",
            "Epoch 718/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 32.5022 - accuracy: 1.1834e-04 - val_loss: 417.9991 - val_accuracy: 0.0000e+00\n",
            "Epoch 719/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 32.5019 - accuracy: 1.1834e-04 - val_loss: 450.1135 - val_accuracy: 0.0000e+00\n",
            "Epoch 720/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 31.2407 - accuracy: 1.1834e-04 - val_loss: 420.5898 - val_accuracy: 0.0000e+00\n",
            "Epoch 721/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 31.8350 - accuracy: 1.1834e-04 - val_loss: 443.1576 - val_accuracy: 0.0000e+00\n",
            "Epoch 722/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 31.7712 - accuracy: 1.1834e-04 - val_loss: 432.3382 - val_accuracy: 0.0000e+00\n",
            "Epoch 723/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 31.5007 - accuracy: 1.1834e-04 - val_loss: 429.6739 - val_accuracy: 0.0000e+00\n",
            "Epoch 724/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 36.3303 - accuracy: 1.1834e-04 - val_loss: 457.7083 - val_accuracy: 0.0000e+00\n",
            "Epoch 725/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 33.0884 - accuracy: 1.1834e-04 - val_loss: 491.4957 - val_accuracy: 0.0000e+00\n",
            "Epoch 726/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 34.3919 - accuracy: 1.1834e-04 - val_loss: 442.3264 - val_accuracy: 0.0000e+00\n",
            "Epoch 727/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 34.8849 - accuracy: 1.1834e-04 - val_loss: 457.5070 - val_accuracy: 0.0000e+00\n",
            "Epoch 728/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 33.8713 - accuracy: 1.1834e-04 - val_loss: 416.7435 - val_accuracy: 0.0000e+00\n",
            "Epoch 729/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 33.6756 - accuracy: 1.1834e-04 - val_loss: 448.4231 - val_accuracy: 0.0000e+00\n",
            "Epoch 730/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 35.8341 - accuracy: 1.1834e-04 - val_loss: 449.9227 - val_accuracy: 0.0000e+00\n",
            "Epoch 731/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 34.9602 - accuracy: 1.1834e-04 - val_loss: 402.3425 - val_accuracy: 0.0000e+00\n",
            "Epoch 732/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 37.2294 - accuracy: 1.1834e-04 - val_loss: 466.0853 - val_accuracy: 0.0000e+00\n",
            "Epoch 733/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 35.2281 - accuracy: 1.1834e-04 - val_loss: 453.3055 - val_accuracy: 0.0000e+00\n",
            "Epoch 734/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 32.1855 - accuracy: 1.1834e-04 - val_loss: 430.7729 - val_accuracy: 0.0000e+00\n",
            "Epoch 735/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 31.3966 - accuracy: 1.1834e-04 - val_loss: 455.6118 - val_accuracy: 0.0000e+00\n",
            "Epoch 736/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 32.9313 - accuracy: 1.1834e-04 - val_loss: 423.1146 - val_accuracy: 0.0000e+00\n",
            "Epoch 737/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 34.7798 - accuracy: 1.1834e-04 - val_loss: 446.3093 - val_accuracy: 0.0000e+00\n",
            "Epoch 738/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 31.3065 - accuracy: 1.1834e-04 - val_loss: 480.3612 - val_accuracy: 0.0000e+00\n",
            "Epoch 739/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 43.1679 - accuracy: 1.1834e-04 - val_loss: 422.8138 - val_accuracy: 0.0000e+00\n",
            "Epoch 740/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 32.0755 - accuracy: 1.1834e-04 - val_loss: 463.2192 - val_accuracy: 0.0000e+00\n",
            "Epoch 741/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 32.1028 - accuracy: 1.1834e-04 - val_loss: 412.7705 - val_accuracy: 0.0000e+00\n",
            "Epoch 742/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 33.8583 - accuracy: 1.1834e-04 - val_loss: 425.5041 - val_accuracy: 0.0000e+00\n",
            "Epoch 743/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 33.6321 - accuracy: 1.1834e-04 - val_loss: 425.3297 - val_accuracy: 0.0000e+00\n",
            "Epoch 744/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 29.5421 - accuracy: 1.1834e-04 - val_loss: 435.4504 - val_accuracy: 0.0000e+00\n",
            "Epoch 745/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 31.2744 - accuracy: 1.1834e-04 - val_loss: 400.4803 - val_accuracy: 0.0000e+00\n",
            "Epoch 746/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 30.2436 - accuracy: 1.1834e-04 - val_loss: 453.1461 - val_accuracy: 0.0000e+00\n",
            "Epoch 747/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 31.5116 - accuracy: 1.1834e-04 - val_loss: 413.4606 - val_accuracy: 0.0000e+00\n",
            "Epoch 748/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 31.3983 - accuracy: 1.1834e-04 - val_loss: 479.5238 - val_accuracy: 0.0000e+00\n",
            "Epoch 749/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 31.1060 - accuracy: 1.1834e-04 - val_loss: 424.4828 - val_accuracy: 0.0000e+00\n",
            "Epoch 750/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 35.7398 - accuracy: 1.1834e-04 - val_loss: 386.1421 - val_accuracy: 0.0000e+00\n",
            "Epoch 751/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 33.1552 - accuracy: 1.1834e-04 - val_loss: 403.2170 - val_accuracy: 0.0000e+00\n",
            "Epoch 752/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 37.4608 - accuracy: 1.1834e-04 - val_loss: 465.9289 - val_accuracy: 0.0000e+00\n",
            "Epoch 753/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 38.8384 - accuracy: 1.1834e-04 - val_loss: 412.4915 - val_accuracy: 0.0000e+00\n",
            "Epoch 754/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 30.1565 - accuracy: 1.1834e-04 - val_loss: 434.4521 - val_accuracy: 0.0000e+00\n",
            "Epoch 755/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 29.7762 - accuracy: 1.1834e-04 - val_loss: 412.5547 - val_accuracy: 0.0000e+00\n",
            "Epoch 756/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 28.1350 - accuracy: 1.1834e-04 - val_loss: 456.1356 - val_accuracy: 0.0000e+00\n",
            "Epoch 757/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 30.6042 - accuracy: 1.1834e-04 - val_loss: 463.1045 - val_accuracy: 0.0000e+00\n",
            "Epoch 758/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 33.0026 - accuracy: 1.1834e-04 - val_loss: 444.4746 - val_accuracy: 0.0000e+00\n",
            "Epoch 759/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 30.0572 - accuracy: 1.1834e-04 - val_loss: 412.3394 - val_accuracy: 0.0000e+00\n",
            "Epoch 760/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 32.5335 - accuracy: 1.1834e-04 - val_loss: 419.7808 - val_accuracy: 0.0000e+00\n",
            "Epoch 761/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 32.6867 - accuracy: 1.1834e-04 - val_loss: 418.3194 - val_accuracy: 0.0000e+00\n",
            "Epoch 762/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 29.1044 - accuracy: 1.1834e-04 - val_loss: 451.8499 - val_accuracy: 0.0000e+00\n",
            "Epoch 763/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 31.1050 - accuracy: 1.1834e-04 - val_loss: 446.4461 - val_accuracy: 0.0000e+00\n",
            "Epoch 764/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 31.6574 - accuracy: 1.1834e-04 - val_loss: 434.6757 - val_accuracy: 0.0000e+00\n",
            "Epoch 765/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 34.7730 - accuracy: 1.1834e-04 - val_loss: 462.9730 - val_accuracy: 0.0000e+00\n",
            "Epoch 766/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 30.8585 - accuracy: 1.1834e-04 - val_loss: 440.9200 - val_accuracy: 0.0000e+00\n",
            "Epoch 767/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 30.4800 - accuracy: 1.1834e-04 - val_loss: 439.0971 - val_accuracy: 0.0000e+00\n",
            "Epoch 768/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 30.2874 - accuracy: 1.1834e-04 - val_loss: 417.3333 - val_accuracy: 0.0000e+00\n",
            "Epoch 769/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 28.6775 - accuracy: 1.1834e-04 - val_loss: 406.3306 - val_accuracy: 0.0000e+00\n",
            "Epoch 770/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 31.3160 - accuracy: 1.1834e-04 - val_loss: 437.1511 - val_accuracy: 0.0000e+00\n",
            "Epoch 771/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 35.9375 - accuracy: 1.1834e-04 - val_loss: 408.1510 - val_accuracy: 0.0000e+00\n",
            "Epoch 772/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 30.9292 - accuracy: 1.1834e-04 - val_loss: 411.7731 - val_accuracy: 0.0000e+00\n",
            "Epoch 773/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 33.5584 - accuracy: 1.1834e-04 - val_loss: 444.2481 - val_accuracy: 0.0000e+00\n",
            "Epoch 774/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 33.9019 - accuracy: 1.1834e-04 - val_loss: 420.7765 - val_accuracy: 0.0000e+00\n",
            "Epoch 775/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 31.4576 - accuracy: 1.1834e-04 - val_loss: 494.1651 - val_accuracy: 0.0000e+00\n",
            "Epoch 776/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 28.9579 - accuracy: 1.1834e-04 - val_loss: 420.4893 - val_accuracy: 0.0000e+00\n",
            "Epoch 777/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 30.8789 - accuracy: 1.1834e-04 - val_loss: 419.0963 - val_accuracy: 0.0000e+00\n",
            "Epoch 778/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 31.5844 - accuracy: 1.1834e-04 - val_loss: 420.7904 - val_accuracy: 0.0000e+00\n",
            "Epoch 779/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 28.5398 - accuracy: 1.1834e-04 - val_loss: 451.0650 - val_accuracy: 0.0000e+00\n",
            "Epoch 780/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 27.9294 - accuracy: 1.1834e-04 - val_loss: 384.4670 - val_accuracy: 0.0000e+00\n",
            "Epoch 781/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 27.8538 - accuracy: 1.1834e-04 - val_loss: 427.2143 - val_accuracy: 0.0000e+00\n",
            "Epoch 782/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 29.6699 - accuracy: 1.1834e-04 - val_loss: 426.9234 - val_accuracy: 0.0000e+00\n",
            "Epoch 783/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 27.5861 - accuracy: 1.1834e-04 - val_loss: 433.5703 - val_accuracy: 0.0000e+00\n",
            "Epoch 784/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 31.6963 - accuracy: 1.1834e-04 - val_loss: 422.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 785/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 35.9443 - accuracy: 1.1834e-04 - val_loss: 464.9506 - val_accuracy: 0.0000e+00\n",
            "Epoch 786/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 39.8319 - accuracy: 1.1834e-04 - val_loss: 411.2339 - val_accuracy: 0.0000e+00\n",
            "Epoch 787/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 32.3819 - accuracy: 1.1834e-04 - val_loss: 405.2923 - val_accuracy: 0.0000e+00\n",
            "Epoch 788/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 29.7860 - accuracy: 1.1834e-04 - val_loss: 446.9162 - val_accuracy: 0.0000e+00\n",
            "Epoch 789/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 30.4174 - accuracy: 1.1834e-04 - val_loss: 434.8259 - val_accuracy: 0.0000e+00\n",
            "Epoch 790/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 30.2625 - accuracy: 1.1834e-04 - val_loss: 466.3646 - val_accuracy: 0.0000e+00\n",
            "Epoch 791/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 30.2969 - accuracy: 1.1834e-04 - val_loss: 402.4200 - val_accuracy: 0.0000e+00\n",
            "Epoch 792/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 28.3643 - accuracy: 1.1834e-04 - val_loss: 429.4924 - val_accuracy: 0.0000e+00\n",
            "Epoch 793/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 29.7784 - accuracy: 1.1834e-04 - val_loss: 398.8996 - val_accuracy: 0.0000e+00\n",
            "Epoch 794/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 29.8089 - accuracy: 1.1834e-04 - val_loss: 440.3357 - val_accuracy: 0.0000e+00\n",
            "Epoch 795/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 37.4892 - accuracy: 1.1834e-04 - val_loss: 417.5486 - val_accuracy: 0.0000e+00\n",
            "Epoch 796/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 29.8072 - accuracy: 1.1834e-04 - val_loss: 441.6298 - val_accuracy: 0.0000e+00\n",
            "Epoch 797/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 35.0004 - accuracy: 1.1834e-04 - val_loss: 396.6095 - val_accuracy: 0.0000e+00\n",
            "Epoch 798/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 28.7192 - accuracy: 1.1834e-04 - val_loss: 430.3240 - val_accuracy: 0.0000e+00\n",
            "Epoch 799/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 31.0625 - accuracy: 1.1834e-04 - val_loss: 395.4125 - val_accuracy: 0.0000e+00\n",
            "Epoch 800/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 33.6544 - accuracy: 1.1834e-04 - val_loss: 417.8672 - val_accuracy: 0.0000e+00\n",
            "Epoch 801/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 27.9846 - accuracy: 1.1834e-04 - val_loss: 434.7552 - val_accuracy: 0.0000e+00\n",
            "Epoch 802/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 31.6556 - accuracy: 1.1834e-04 - val_loss: 359.8702 - val_accuracy: 0.0000e+00\n",
            "Epoch 803/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 29.7480 - accuracy: 1.1834e-04 - val_loss: 440.6028 - val_accuracy: 0.0000e+00\n",
            "Epoch 804/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 29.5215 - accuracy: 1.1834e-04 - val_loss: 441.9338 - val_accuracy: 0.0000e+00\n",
            "Epoch 805/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 29.1223 - accuracy: 1.1834e-04 - val_loss: 437.4822 - val_accuracy: 0.0000e+00\n",
            "Epoch 806/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 29.5604 - accuracy: 1.1834e-04 - val_loss: 386.7425 - val_accuracy: 0.0000e+00\n",
            "Epoch 807/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 27.7850 - accuracy: 1.1834e-04 - val_loss: 438.3223 - val_accuracy: 0.0000e+00\n",
            "Epoch 808/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 28.5728 - accuracy: 1.1834e-04 - val_loss: 428.4991 - val_accuracy: 0.0000e+00\n",
            "Epoch 809/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 29.3961 - accuracy: 1.1834e-04 - val_loss: 460.7960 - val_accuracy: 0.0000e+00\n",
            "Epoch 810/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 28.5045 - accuracy: 1.1834e-04 - val_loss: 447.7376 - val_accuracy: 0.0000e+00\n",
            "Epoch 811/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 31.2332 - accuracy: 1.1834e-04 - val_loss: 409.4717 - val_accuracy: 0.0000e+00\n",
            "Epoch 812/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 30.9699 - accuracy: 1.1834e-04 - val_loss: 483.9703 - val_accuracy: 0.0000e+00\n",
            "Epoch 813/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 32.6367 - accuracy: 1.1834e-04 - val_loss: 375.9697 - val_accuracy: 0.0000e+00\n",
            "Epoch 814/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 30.1570 - accuracy: 1.1834e-04 - val_loss: 433.7493 - val_accuracy: 0.0000e+00\n",
            "Epoch 815/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 29.9455 - accuracy: 1.1834e-04 - val_loss: 483.4308 - val_accuracy: 0.0000e+00\n",
            "Epoch 816/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 33.0713 - accuracy: 1.1834e-04 - val_loss: 413.2352 - val_accuracy: 0.0000e+00\n",
            "Epoch 817/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 26.6487 - accuracy: 1.1834e-04 - val_loss: 452.8331 - val_accuracy: 0.0000e+00\n",
            "Epoch 818/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 25.2560 - accuracy: 1.1834e-04 - val_loss: 449.8872 - val_accuracy: 0.0000e+00\n",
            "Epoch 819/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 26.2253 - accuracy: 1.1834e-04 - val_loss: 413.6254 - val_accuracy: 0.0000e+00\n",
            "Epoch 820/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 26.0729 - accuracy: 1.1834e-04 - val_loss: 431.6983 - val_accuracy: 0.0000e+00\n",
            "Epoch 821/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 26.5553 - accuracy: 1.1834e-04 - val_loss: 398.1959 - val_accuracy: 0.0000e+00\n",
            "Epoch 822/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 28.4578 - accuracy: 1.1834e-04 - val_loss: 440.9646 - val_accuracy: 0.0000e+00\n",
            "Epoch 823/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 30.5767 - accuracy: 1.1834e-04 - val_loss: 404.4438 - val_accuracy: 0.0000e+00\n",
            "Epoch 824/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 33.1225 - accuracy: 1.1834e-04 - val_loss: 412.8367 - val_accuracy: 0.0000e+00\n",
            "Epoch 825/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 30.6035 - accuracy: 1.1834e-04 - val_loss: 456.0199 - val_accuracy: 0.0000e+00\n",
            "Epoch 826/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 33.3351 - accuracy: 1.1834e-04 - val_loss: 428.1771 - val_accuracy: 0.0000e+00\n",
            "Epoch 827/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 39.7597 - accuracy: 1.1834e-04 - val_loss: 434.3361 - val_accuracy: 0.0000e+00\n",
            "Epoch 828/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 29.3313 - accuracy: 1.1834e-04 - val_loss: 431.6587 - val_accuracy: 0.0000e+00\n",
            "Epoch 829/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 28.5644 - accuracy: 1.1834e-04 - val_loss: 426.5736 - val_accuracy: 0.0000e+00\n",
            "Epoch 830/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 37.8094 - accuracy: 1.1834e-04 - val_loss: 432.3723 - val_accuracy: 0.0000e+00\n",
            "Epoch 831/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 41.2057 - accuracy: 1.1834e-04 - val_loss: 411.2379 - val_accuracy: 0.0000e+00\n",
            "Epoch 832/1000\n",
            "29/29 [==============================] - 1s 20ms/step - loss: 31.3016 - accuracy: 1.1834e-04 - val_loss: 440.8314 - val_accuracy: 0.0000e+00\n",
            "Epoch 833/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 29.3837 - accuracy: 1.1834e-04 - val_loss: 440.6140 - val_accuracy: 0.0000e+00\n",
            "Epoch 834/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 26.7134 - accuracy: 1.1834e-04 - val_loss: 389.8084 - val_accuracy: 0.0000e+00\n",
            "Epoch 835/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 26.3819 - accuracy: 1.1834e-04 - val_loss: 428.6143 - val_accuracy: 0.0000e+00\n",
            "Epoch 836/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 27.3472 - accuracy: 1.1834e-04 - val_loss: 412.0387 - val_accuracy: 0.0000e+00\n",
            "Epoch 837/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 27.1420 - accuracy: 1.1834e-04 - val_loss: 403.5626 - val_accuracy: 0.0000e+00\n",
            "Epoch 838/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 27.7146 - accuracy: 1.1834e-04 - val_loss: 446.4276 - val_accuracy: 0.0000e+00\n",
            "Epoch 839/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 31.2754 - accuracy: 1.1834e-04 - val_loss: 443.6374 - val_accuracy: 0.0000e+00\n",
            "Epoch 840/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 29.0150 - accuracy: 1.1834e-04 - val_loss: 434.9279 - val_accuracy: 0.0000e+00\n",
            "Epoch 841/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 27.5790 - accuracy: 1.1834e-04 - val_loss: 428.4796 - val_accuracy: 0.0000e+00\n",
            "Epoch 842/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 28.0592 - accuracy: 1.1834e-04 - val_loss: 436.4036 - val_accuracy: 0.0000e+00\n",
            "Epoch 843/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 29.0301 - accuracy: 1.1834e-04 - val_loss: 395.2754 - val_accuracy: 0.0000e+00\n",
            "Epoch 844/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 31.0269 - accuracy: 1.1834e-04 - val_loss: 490.9809 - val_accuracy: 0.0000e+00\n",
            "Epoch 845/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 28.2434 - accuracy: 1.1834e-04 - val_loss: 419.2126 - val_accuracy: 0.0000e+00\n",
            "Epoch 846/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 26.5526 - accuracy: 1.1834e-04 - val_loss: 432.6607 - val_accuracy: 0.0000e+00\n",
            "Epoch 847/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 28.7194 - accuracy: 1.1834e-04 - val_loss: 398.2860 - val_accuracy: 0.0000e+00\n",
            "Epoch 848/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 25.4242 - accuracy: 1.1834e-04 - val_loss: 423.4003 - val_accuracy: 0.0000e+00\n",
            "Epoch 849/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 26.3885 - accuracy: 1.1834e-04 - val_loss: 431.8849 - val_accuracy: 0.0000e+00\n",
            "Epoch 850/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 29.5138 - accuracy: 1.1834e-04 - val_loss: 424.2635 - val_accuracy: 0.0000e+00\n",
            "Epoch 851/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 28.3461 - accuracy: 1.1834e-04 - val_loss: 448.7541 - val_accuracy: 0.0000e+00\n",
            "Epoch 852/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 30.6852 - accuracy: 1.1834e-04 - val_loss: 375.3876 - val_accuracy: 0.0000e+00\n",
            "Epoch 853/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 47.5847 - accuracy: 1.1834e-04 - val_loss: 424.1743 - val_accuracy: 0.0000e+00\n",
            "Epoch 854/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 28.7598 - accuracy: 1.1834e-04 - val_loss: 372.6083 - val_accuracy: 0.0000e+00\n",
            "Epoch 855/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 26.6407 - accuracy: 1.1834e-04 - val_loss: 408.8943 - val_accuracy: 0.0000e+00\n",
            "Epoch 856/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 29.1822 - accuracy: 1.1834e-04 - val_loss: 396.0856 - val_accuracy: 0.0000e+00\n",
            "Epoch 857/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 34.4082 - accuracy: 1.1834e-04 - val_loss: 449.1320 - val_accuracy: 0.0000e+00\n",
            "Epoch 858/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 32.9446 - accuracy: 1.1834e-04 - val_loss: 402.0720 - val_accuracy: 0.0000e+00\n",
            "Epoch 859/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 29.0675 - accuracy: 1.1834e-04 - val_loss: 417.7265 - val_accuracy: 0.0000e+00\n",
            "Epoch 860/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 28.0947 - accuracy: 1.1834e-04 - val_loss: 396.7302 - val_accuracy: 0.0000e+00\n",
            "Epoch 861/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 26.0313 - accuracy: 1.1834e-04 - val_loss: 430.6185 - val_accuracy: 0.0000e+00\n",
            "Epoch 862/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 25.1617 - accuracy: 1.1834e-04 - val_loss: 464.1571 - val_accuracy: 0.0000e+00\n",
            "Epoch 863/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 27.5391 - accuracy: 1.1834e-04 - val_loss: 381.0785 - val_accuracy: 0.0000e+00\n",
            "Epoch 864/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 27.5305 - accuracy: 1.1834e-04 - val_loss: 399.4852 - val_accuracy: 0.0000e+00\n",
            "Epoch 865/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 26.9835 - accuracy: 1.1834e-04 - val_loss: 418.4970 - val_accuracy: 0.0000e+00\n",
            "Epoch 866/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 26.3192 - accuracy: 1.1834e-04 - val_loss: 398.7833 - val_accuracy: 0.0000e+00\n",
            "Epoch 867/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 27.4407 - accuracy: 1.1834e-04 - val_loss: 430.6273 - val_accuracy: 0.0000e+00\n",
            "Epoch 868/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 29.9198 - accuracy: 1.1834e-04 - val_loss: 422.3228 - val_accuracy: 0.0000e+00\n",
            "Epoch 869/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 28.4368 - accuracy: 1.1834e-04 - val_loss: 455.7371 - val_accuracy: 0.0000e+00\n",
            "Epoch 870/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 29.9116 - accuracy: 1.1834e-04 - val_loss: 405.3235 - val_accuracy: 0.0000e+00\n",
            "Epoch 871/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 27.6822 - accuracy: 1.1834e-04 - val_loss: 432.3168 - val_accuracy: 0.0000e+00\n",
            "Epoch 872/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 25.8067 - accuracy: 1.1834e-04 - val_loss: 442.4482 - val_accuracy: 0.0000e+00\n",
            "Epoch 873/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 27.4459 - accuracy: 1.1834e-04 - val_loss: 433.7890 - val_accuracy: 0.0000e+00\n",
            "Epoch 874/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 28.1077 - accuracy: 1.1834e-04 - val_loss: 453.5193 - val_accuracy: 0.0000e+00\n",
            "Epoch 875/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 27.1981 - accuracy: 1.1834e-04 - val_loss: 402.6979 - val_accuracy: 0.0000e+00\n",
            "Epoch 876/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 26.2095 - accuracy: 1.1834e-04 - val_loss: 461.7221 - val_accuracy: 0.0000e+00\n",
            "Epoch 877/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 26.9536 - accuracy: 1.1834e-04 - val_loss: 371.1955 - val_accuracy: 0.0000e+00\n",
            "Epoch 878/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 28.4178 - accuracy: 1.1834e-04 - val_loss: 420.1665 - val_accuracy: 0.0000e+00\n",
            "Epoch 879/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 27.6857 - accuracy: 1.1834e-04 - val_loss: 386.3329 - val_accuracy: 0.0000e+00\n",
            "Epoch 880/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 28.1188 - accuracy: 1.1834e-04 - val_loss: 415.7812 - val_accuracy: 0.0000e+00\n",
            "Epoch 881/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 29.0279 - accuracy: 1.1834e-04 - val_loss: 416.6616 - val_accuracy: 0.0000e+00\n",
            "Epoch 882/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 26.9665 - accuracy: 1.1834e-04 - val_loss: 425.7437 - val_accuracy: 0.0000e+00\n",
            "Epoch 883/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 26.2858 - accuracy: 1.1834e-04 - val_loss: 414.9993 - val_accuracy: 0.0000e+00\n",
            "Epoch 884/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 26.8877 - accuracy: 1.1834e-04 - val_loss: 414.0847 - val_accuracy: 0.0000e+00\n",
            "Epoch 885/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 30.2713 - accuracy: 1.1834e-04 - val_loss: 367.9507 - val_accuracy: 0.0000e+00\n",
            "Epoch 886/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 27.9147 - accuracy: 1.1834e-04 - val_loss: 372.8465 - val_accuracy: 0.0000e+00\n",
            "Epoch 887/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 26.1048 - accuracy: 1.1834e-04 - val_loss: 396.8683 - val_accuracy: 0.0000e+00\n",
            "Epoch 888/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 23.8442 - accuracy: 1.1834e-04 - val_loss: 390.8683 - val_accuracy: 0.0000e+00\n",
            "Epoch 889/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 26.6336 - accuracy: 1.1834e-04 - val_loss: 384.7845 - val_accuracy: 0.0000e+00\n",
            "Epoch 890/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 26.4700 - accuracy: 1.1834e-04 - val_loss: 408.0650 - val_accuracy: 0.0000e+00\n",
            "Epoch 891/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 25.4281 - accuracy: 1.1834e-04 - val_loss: 433.1977 - val_accuracy: 0.0000e+00\n",
            "Epoch 892/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 27.0862 - accuracy: 1.1834e-04 - val_loss: 412.7069 - val_accuracy: 0.0000e+00\n",
            "Epoch 893/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 33.7789 - accuracy: 1.1834e-04 - val_loss: 409.9500 - val_accuracy: 0.0000e+00\n",
            "Epoch 894/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 31.0921 - accuracy: 1.1834e-04 - val_loss: 370.1782 - val_accuracy: 0.0000e+00\n",
            "Epoch 895/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 29.0963 - accuracy: 1.1834e-04 - val_loss: 404.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 896/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 25.7513 - accuracy: 1.1834e-04 - val_loss: 362.2047 - val_accuracy: 0.0000e+00\n",
            "Epoch 897/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 26.4820 - accuracy: 1.1834e-04 - val_loss: 374.0963 - val_accuracy: 0.0000e+00\n",
            "Epoch 898/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 26.8759 - accuracy: 1.1834e-04 - val_loss: 429.1204 - val_accuracy: 0.0000e+00\n",
            "Epoch 899/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 23.7652 - accuracy: 1.1834e-04 - val_loss: 392.5555 - val_accuracy: 0.0000e+00\n",
            "Epoch 900/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 24.4856 - accuracy: 1.1834e-04 - val_loss: 410.1242 - val_accuracy: 0.0000e+00\n",
            "Epoch 901/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 24.2355 - accuracy: 1.1834e-04 - val_loss: 404.1995 - val_accuracy: 0.0000e+00\n",
            "Epoch 902/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 28.7522 - accuracy: 1.1834e-04 - val_loss: 385.0599 - val_accuracy: 0.0000e+00\n",
            "Epoch 903/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 25.6057 - accuracy: 1.1834e-04 - val_loss: 374.5235 - val_accuracy: 0.0000e+00\n",
            "Epoch 904/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 25.6734 - accuracy: 1.1834e-04 - val_loss: 395.7573 - val_accuracy: 0.0000e+00\n",
            "Epoch 905/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 26.0422 - accuracy: 1.1834e-04 - val_loss: 397.0449 - val_accuracy: 0.0000e+00\n",
            "Epoch 906/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 33.3041 - accuracy: 1.1834e-04 - val_loss: 385.4521 - val_accuracy: 0.0000e+00\n",
            "Epoch 907/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 28.2642 - accuracy: 1.1834e-04 - val_loss: 446.8607 - val_accuracy: 0.0000e+00\n",
            "Epoch 908/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 26.1636 - accuracy: 1.1834e-04 - val_loss: 390.0327 - val_accuracy: 0.0000e+00\n",
            "Epoch 909/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 24.8607 - accuracy: 1.1834e-04 - val_loss: 415.4354 - val_accuracy: 0.0000e+00\n",
            "Epoch 910/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 31.6946 - accuracy: 1.1834e-04 - val_loss: 396.4030 - val_accuracy: 0.0000e+00\n",
            "Epoch 911/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 31.2006 - accuracy: 1.1834e-04 - val_loss: 398.6488 - val_accuracy: 0.0000e+00\n",
            "Epoch 912/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 28.8786 - accuracy: 1.1834e-04 - val_loss: 379.6798 - val_accuracy: 0.0000e+00\n",
            "Epoch 913/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 28.3741 - accuracy: 1.1834e-04 - val_loss: 397.1657 - val_accuracy: 0.0000e+00\n",
            "Epoch 914/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 26.9370 - accuracy: 1.1834e-04 - val_loss: 410.6207 - val_accuracy: 0.0000e+00\n",
            "Epoch 915/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 26.5059 - accuracy: 1.1834e-04 - val_loss: 384.3626 - val_accuracy: 0.0000e+00\n",
            "Epoch 916/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 28.6555 - accuracy: 1.1834e-04 - val_loss: 408.7762 - val_accuracy: 0.0000e+00\n",
            "Epoch 917/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 25.8888 - accuracy: 1.1834e-04 - val_loss: 400.3342 - val_accuracy: 0.0000e+00\n",
            "Epoch 918/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 23.8020 - accuracy: 1.1834e-04 - val_loss: 368.4402 - val_accuracy: 0.0000e+00\n",
            "Epoch 919/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 23.9584 - accuracy: 1.1834e-04 - val_loss: 390.0495 - val_accuracy: 0.0000e+00\n",
            "Epoch 920/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 27.1904 - accuracy: 1.1834e-04 - val_loss: 358.1119 - val_accuracy: 0.0000e+00\n",
            "Epoch 921/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 27.3700 - accuracy: 1.1834e-04 - val_loss: 364.5892 - val_accuracy: 0.0000e+00\n",
            "Epoch 922/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 29.1763 - accuracy: 1.1834e-04 - val_loss: 352.8792 - val_accuracy: 0.0000e+00\n",
            "Epoch 923/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 24.4550 - accuracy: 1.1834e-04 - val_loss: 431.6983 - val_accuracy: 0.0000e+00\n",
            "Epoch 924/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 25.5734 - accuracy: 1.1834e-04 - val_loss: 390.4617 - val_accuracy: 0.0000e+00\n",
            "Epoch 925/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 26.2002 - accuracy: 1.1834e-04 - val_loss: 382.2571 - val_accuracy: 0.0000e+00\n",
            "Epoch 926/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 32.2470 - accuracy: 1.1834e-04 - val_loss: 371.4619 - val_accuracy: 0.0000e+00\n",
            "Epoch 927/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 36.5994 - accuracy: 1.1834e-04 - val_loss: 363.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 928/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 35.1843 - accuracy: 1.1834e-04 - val_loss: 362.0199 - val_accuracy: 0.0000e+00\n",
            "Epoch 929/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 29.9784 - accuracy: 1.1834e-04 - val_loss: 365.8747 - val_accuracy: 0.0000e+00\n",
            "Epoch 930/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 31.7697 - accuracy: 1.1834e-04 - val_loss: 407.1707 - val_accuracy: 0.0000e+00\n",
            "Epoch 931/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 27.9944 - accuracy: 1.1834e-04 - val_loss: 376.4139 - val_accuracy: 0.0000e+00\n",
            "Epoch 932/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 25.9213 - accuracy: 1.1834e-04 - val_loss: 386.4839 - val_accuracy: 0.0000e+00\n",
            "Epoch 933/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 24.9029 - accuracy: 1.1834e-04 - val_loss: 370.3989 - val_accuracy: 0.0000e+00\n",
            "Epoch 934/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 24.6585 - accuracy: 1.1834e-04 - val_loss: 361.8946 - val_accuracy: 0.0000e+00\n",
            "Epoch 935/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 27.1757 - accuracy: 1.1834e-04 - val_loss: 376.1090 - val_accuracy: 0.0000e+00\n",
            "Epoch 936/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 35.0239 - accuracy: 1.1834e-04 - val_loss: 353.6259 - val_accuracy: 0.0000e+00\n",
            "Epoch 937/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 34.3448 - accuracy: 1.1834e-04 - val_loss: 346.1709 - val_accuracy: 0.0000e+00\n",
            "Epoch 938/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 23.3786 - accuracy: 1.1834e-04 - val_loss: 386.9452 - val_accuracy: 0.0000e+00\n",
            "Epoch 939/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 23.9536 - accuracy: 1.1834e-04 - val_loss: 385.4719 - val_accuracy: 0.0000e+00\n",
            "Epoch 940/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 26.4857 - accuracy: 1.1834e-04 - val_loss: 364.3138 - val_accuracy: 0.0000e+00\n",
            "Epoch 941/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 28.0673 - accuracy: 1.1834e-04 - val_loss: 432.2587 - val_accuracy: 0.0000e+00\n",
            "Epoch 942/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 23.9732 - accuracy: 1.1834e-04 - val_loss: 411.6566 - val_accuracy: 0.0000e+00\n",
            "Epoch 943/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 25.3362 - accuracy: 1.1834e-04 - val_loss: 372.7885 - val_accuracy: 0.0000e+00\n",
            "Epoch 944/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 24.8649 - accuracy: 1.1834e-04 - val_loss: 399.5897 - val_accuracy: 0.0000e+00\n",
            "Epoch 945/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 25.3644 - accuracy: 1.1834e-04 - val_loss: 365.6312 - val_accuracy: 0.0000e+00\n",
            "Epoch 946/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 27.4120 - accuracy: 1.1834e-04 - val_loss: 379.3919 - val_accuracy: 0.0000e+00\n",
            "Epoch 947/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 26.5864 - accuracy: 1.1834e-04 - val_loss: 366.9295 - val_accuracy: 0.0000e+00\n",
            "Epoch 948/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 24.2674 - accuracy: 1.1834e-04 - val_loss: 398.9146 - val_accuracy: 0.0000e+00\n",
            "Epoch 949/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 23.1494 - accuracy: 1.1834e-04 - val_loss: 373.5132 - val_accuracy: 0.0000e+00\n",
            "Epoch 950/1000\n",
            "29/29 [==============================] - 1s 21ms/step - loss: 26.5505 - accuracy: 1.1834e-04 - val_loss: 394.5480 - val_accuracy: 0.0000e+00\n",
            "Epoch 951/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 25.6842 - accuracy: 1.1834e-04 - val_loss: 365.2209 - val_accuracy: 0.0000e+00\n",
            "Epoch 952/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 29.9373 - accuracy: 1.1834e-04 - val_loss: 385.0884 - val_accuracy: 0.0000e+00\n",
            "Epoch 953/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 25.3579 - accuracy: 1.1834e-04 - val_loss: 385.4577 - val_accuracy: 0.0000e+00\n",
            "Epoch 954/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 24.2741 - accuracy: 1.1834e-04 - val_loss: 414.5055 - val_accuracy: 0.0000e+00\n",
            "Epoch 955/1000\n",
            "29/29 [==============================] - 1s 28ms/step - loss: 26.4426 - accuracy: 1.1834e-04 - val_loss: 363.0190 - val_accuracy: 0.0000e+00\n",
            "Epoch 956/1000\n",
            "29/29 [==============================] - 1s 30ms/step - loss: 25.9681 - accuracy: 1.1834e-04 - val_loss: 423.6816 - val_accuracy: 0.0000e+00\n",
            "Epoch 957/1000\n",
            "29/29 [==============================] - 1s 31ms/step - loss: 25.0642 - accuracy: 1.1834e-04 - val_loss: 373.3069 - val_accuracy: 0.0000e+00\n",
            "Epoch 958/1000\n",
            "29/29 [==============================] - 1s 30ms/step - loss: 24.3512 - accuracy: 1.1834e-04 - val_loss: 377.8528 - val_accuracy: 0.0000e+00\n",
            "Epoch 959/1000\n",
            "29/29 [==============================] - 1s 31ms/step - loss: 27.8836 - accuracy: 1.1834e-04 - val_loss: 414.9641 - val_accuracy: 0.0000e+00\n",
            "Epoch 960/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 27.2622 - accuracy: 1.1834e-04 - val_loss: 379.5193 - val_accuracy: 0.0000e+00\n",
            "Epoch 961/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 29.5313 - accuracy: 1.1834e-04 - val_loss: 381.5272 - val_accuracy: 0.0000e+00\n",
            "Epoch 962/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 27.4384 - accuracy: 1.1834e-04 - val_loss: 374.8478 - val_accuracy: 0.0000e+00\n",
            "Epoch 963/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 24.8732 - accuracy: 1.1834e-04 - val_loss: 372.4297 - val_accuracy: 0.0000e+00\n",
            "Epoch 964/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 25.2565 - accuracy: 1.1834e-04 - val_loss: 379.1053 - val_accuracy: 0.0000e+00\n",
            "Epoch 965/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 26.9108 - accuracy: 1.1834e-04 - val_loss: 372.3539 - val_accuracy: 0.0000e+00\n",
            "Epoch 966/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 26.0462 - accuracy: 1.1834e-04 - val_loss: 399.6073 - val_accuracy: 0.0000e+00\n",
            "Epoch 967/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 24.8206 - accuracy: 1.1834e-04 - val_loss: 373.9390 - val_accuracy: 0.0000e+00\n",
            "Epoch 968/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 23.6088 - accuracy: 1.1834e-04 - val_loss: 376.7501 - val_accuracy: 0.0000e+00\n",
            "Epoch 969/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 25.1019 - accuracy: 1.1834e-04 - val_loss: 376.6010 - val_accuracy: 0.0000e+00\n",
            "Epoch 970/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 25.3604 - accuracy: 1.1834e-04 - val_loss: 365.1262 - val_accuracy: 0.0000e+00\n",
            "Epoch 971/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 26.3751 - accuracy: 1.1834e-04 - val_loss: 381.8173 - val_accuracy: 0.0000e+00\n",
            "Epoch 972/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 25.4729 - accuracy: 1.1834e-04 - val_loss: 370.4784 - val_accuracy: 0.0000e+00\n",
            "Epoch 973/1000\n",
            "29/29 [==============================] - 1s 29ms/step - loss: 25.2897 - accuracy: 1.1834e-04 - val_loss: 370.6310 - val_accuracy: 0.0000e+00\n",
            "Epoch 974/1000\n",
            "29/29 [==============================] - 1s 32ms/step - loss: 29.5742 - accuracy: 1.1834e-04 - val_loss: 353.5024 - val_accuracy: 0.0000e+00\n",
            "Epoch 975/1000\n",
            "29/29 [==============================] - 1s 30ms/step - loss: 25.1479 - accuracy: 1.1834e-04 - val_loss: 398.3117 - val_accuracy: 0.0000e+00\n",
            "Epoch 976/1000\n",
            "29/29 [==============================] - 1s 31ms/step - loss: 26.5152 - accuracy: 1.1834e-04 - val_loss: 398.0604 - val_accuracy: 0.0000e+00\n",
            "Epoch 977/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 26.2466 - accuracy: 1.1834e-04 - val_loss: 375.4839 - val_accuracy: 0.0000e+00\n",
            "Epoch 978/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 25.7204 - accuracy: 1.1834e-04 - val_loss: 406.5595 - val_accuracy: 0.0000e+00\n",
            "Epoch 979/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 30.2833 - accuracy: 1.1834e-04 - val_loss: 420.6076 - val_accuracy: 0.0000e+00\n",
            "Epoch 980/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 23.4227 - accuracy: 1.1834e-04 - val_loss: 373.9354 - val_accuracy: 0.0000e+00\n",
            "Epoch 981/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 30.2082 - accuracy: 1.1834e-04 - val_loss: 425.8558 - val_accuracy: 0.0000e+00\n",
            "Epoch 982/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 33.9984 - accuracy: 1.1834e-04 - val_loss: 377.8520 - val_accuracy: 0.0000e+00\n",
            "Epoch 983/1000\n",
            "29/29 [==============================] - 1s 26ms/step - loss: 25.3023 - accuracy: 1.1834e-04 - val_loss: 376.9611 - val_accuracy: 0.0000e+00\n",
            "Epoch 984/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 26.6056 - accuracy: 1.1834e-04 - val_loss: 387.7281 - val_accuracy: 0.0000e+00\n",
            "Epoch 985/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 23.3819 - accuracy: 1.1834e-04 - val_loss: 372.8975 - val_accuracy: 0.0000e+00\n",
            "Epoch 986/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 23.6986 - accuracy: 1.1834e-04 - val_loss: 362.6753 - val_accuracy: 0.0000e+00\n",
            "Epoch 987/1000\n",
            "29/29 [==============================] - 1s 25ms/step - loss: 25.5982 - accuracy: 1.1834e-04 - val_loss: 382.3261 - val_accuracy: 0.0000e+00\n",
            "Epoch 988/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 25.4571 - accuracy: 1.1834e-04 - val_loss: 395.0313 - val_accuracy: 0.0000e+00\n",
            "Epoch 989/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 27.3584 - accuracy: 1.1834e-04 - val_loss: 374.8279 - val_accuracy: 0.0000e+00\n",
            "Epoch 990/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 26.2093 - accuracy: 1.1834e-04 - val_loss: 370.6213 - val_accuracy: 0.0000e+00\n",
            "Epoch 991/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 27.5603 - accuracy: 1.1834e-04 - val_loss: 364.5053 - val_accuracy: 0.0000e+00\n",
            "Epoch 992/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 24.4168 - accuracy: 1.1834e-04 - val_loss: 370.4510 - val_accuracy: 0.0000e+00\n",
            "Epoch 993/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 24.6270 - accuracy: 1.1834e-04 - val_loss: 376.0756 - val_accuracy: 0.0000e+00\n",
            "Epoch 994/1000\n",
            "29/29 [==============================] - 1s 27ms/step - loss: 23.0322 - accuracy: 1.1834e-04 - val_loss: 387.9727 - val_accuracy: 0.0000e+00\n",
            "Epoch 995/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 28.8655 - accuracy: 1.1834e-04 - val_loss: 335.6978 - val_accuracy: 0.0000e+00\n",
            "Epoch 996/1000\n",
            "29/29 [==============================] - 1s 24ms/step - loss: 22.9886 - accuracy: 1.1834e-04 - val_loss: 375.4376 - val_accuracy: 0.0000e+00\n",
            "Epoch 997/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 22.9656 - accuracy: 1.1834e-04 - val_loss: 355.4298 - val_accuracy: 0.0000e+00\n",
            "Epoch 998/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 22.7454 - accuracy: 1.1834e-04 - val_loss: 384.6094 - val_accuracy: 0.0000e+00\n",
            "Epoch 999/1000\n",
            "29/29 [==============================] - 1s 23ms/step - loss: 27.8450 - accuracy: 1.1834e-04 - val_loss: 390.2302 - val_accuracy: 0.0000e+00\n",
            "Epoch 1000/1000\n",
            "29/29 [==============================] - 1s 22ms/step - loss: 25.4081 - accuracy: 1.1834e-04 - val_loss: 409.3683 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "\n",
        "history = model.fit(\n",
        "    x_fit,\n",
        "    y_fit,\n",
        "    batch_size=bs,\n",
        "    epochs=num_epochs,\n",
        "    validation_split=val_split,\n",
        ")"
      ],
      "id": "pzIPqYMQ4oW0"
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPjWeEf5QEHf",
        "outputId": "63161619-5ec2-4294-af5a-cdee2ccd10fe"
      },
      "id": "qPjWeEf5QEHf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = (history.history['loss'])\n",
        "val_loss = (history.history['val_loss'])"
      ],
      "metadata": {
        "id": "eTzw2y_FQFTG"
      },
      "id": "eTzw2y_FQFTG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plt.title(\"Loss Graph\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid()\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "\n",
        "plt.legend(['Train_Loss','Val_Loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "nHGfpkZP3Ipg",
        "outputId": "3d7c7d2d-ec9a-46c3-c931-8380e9bb546f"
      },
      "id": "nHGfpkZP3Ipg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1248f0f1c0>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('train_loss_march23_2300.npy', train_loss) # save\n",
        "np.save('val_loss_march23_2300.npy', val_loss) # save\n",
        "\n",
        "# new_arr = np.load('train_loss_march23_2300.npy') # load"
      ],
      "metadata": {
        "id": "Cr-VQDiT8bRB"
      },
      "id": "Cr-VQDiT8bRB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MSw-7bebv-x"
      },
      "source": [
        "# Evaluation"
      ],
      "id": "-MSw-7bebv-x"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SKK24Ffl51LD"
      },
      "id": "SKK24Ffl51LD"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "# del model  # deletes the existing model\n",
        "\n",
        "# returns a compiled model\n",
        "# identical to the previous one"
      ],
      "metadata": {
        "id": "IKPOvGjw69KU"
      },
      "id": "IKPOvGjw69KU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "new_model = load_model('my_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "oO8eZqUL7C77",
        "outputId": "1b476e38-db0c-48a2-c018-2f09b1abe530"
      },
      "id": "oO8eZqUL7C77",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-9ade49769c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/saving/legacy/serialization.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    383\u001b[0m     )\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0;34mf\"Unknown {printable_module_name}: '{class_name}'. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;34m\"Please ensure you are using a `keras.utils.custom_object_scope` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown layer: 'AnalysisBranch1D'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t=x_test\n",
        "t=np.reshape(t, (len(t),len(t[0]), 1))\n",
        "y_pred = model.predict(t)\n",
        "y_pred.shape\n",
        "\n",
        "\n",
        "plt.plot(y_test[:600,2])\n",
        "plt.plot(y_pred[:600,0])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "43FtslEEdWsL",
        "outputId": "bb17c7ea-bcda-488e-c4da-58ac7f238802"
      },
      "id": "43FtslEEdWsL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134/134 [==============================] - 1s 7ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "0cQSzrv08CoY",
        "outputId": "54ee6a58-4693-451b-cbb0-85ccedae553e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134/134 [==============================] - 1s 4ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "[43.255096 43.92727  44.621647 ... 32.552036 32.57365  32.569893]\n",
            "[33.5  34.85 36.17 ... 35.8  35.51 35.12]\n",
            "0.48463441616378\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAHFCAYAAACkWR6dAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAADbnklEQVR4nOydd3xb5b3/348kS7K8t5PYjjNJgAAJgTBLmKWLtpRCC6Wl7S1ddNx7aW/X717o3i3dA1paKKVllZZdRtgQMggJCVnO9N6yZUuypOf3x3OOLG/JPpIs+Xm/Xn4d6+ic5zw6ko4+5zuFlBKNRqPRaDQaTWZgS/cENBqNRqPRaDTxo8WbRqPRaDQaTQahxZtGo9FoNBpNBqHFm0aj0Wg0Gk0GocWbRqPRaDQaTQahxZtGo9FoNBpNBqHFm0ajmbMIIW4VQhyc5r43CCGkEKLagnmsFUKEhBDLrJhbshBCvCKE+H4C29uEEN8WQhwWQkSEEP9I4vSShvE+35DueWg0Jlq8aTQxCCGuMS7U5l9ICHFUCPFHIcSCdM9vLhLznpw2wfMPzDaRMxohxFeEEO+aZJNvA/dIKfemaErT5TvApxMQrFcCXwb+CXwI+EmyJqbRzCUc6Z6ARjNLuQHYD7iBM4EPAucIIY6XUg6kc2IaS/kYqbmJ/QpwN/CP0U8IIU4ELgTOG/VUquaWCP8AvMCngf8Xx/brgW4p5XVJnJNGM+eYbRcGjWa28KiU8nYp5c1Syg8DPwUWAe+caAchRF6qJmcVQghPuueQTqSUQ1LKQJqn8RGgFXg6duUsmdsIpJQRlAj9kBAint+PSpTYswShyLVqPI0mU9HiTaOJjyeN5SKIxiP5hRD1Qoh/CiG8wIPmxkKIK434oEEhRLcQ4i4hxKLYAYUQS4UQfxdCNAshAkKIJiHEPUKIeTHbnC+EeMYYY0AIsV8I8YuY502XYv2osdcb69fHrNsghHhDCHGSEOIpIYQP+JXxnBBCfEYIsd14XW1CiFuEEOWTnRQhxGXGcc4f57kPxM5BCFElhLhZCHHEeL2tQoiHhRDHTXaM6RLnezAmrkwIkSuE+JkQokMI0We8vzWTxD0VGeP0CCF6DRe7J2Y8CeShBI/pjt8Qs/+7gCcNYTTV3KQQ4jdCiHcJIXYY5/F1IcTFcZyPemP/LwkhPiWEaDA+U48LIRYan4GvGO/PoPG6x3v//w3UAidPdSzgHcDCmNe93njeI4T4gVCxcAEhxF5jXrZR45iv9wohxHYgAFwxyXFPMM7/fuNz3CGEuFMIUTfV+TH2dwkhfiKEaI9978fZbqEQ4pdCiF3GOewRyn2/KmabQuO5n42zf5kQIiiE+F4889JoRqPdphpNfCwxlp0x62zAY8BG4AtACEAI8SVUDNPdwB+BEuA64HkhxIlSynYhRA7wKJAL/BJoBuYBFwPzgWYhxLEoQbgd5cYdMObx5hm8jmLjuPcAfwV6jPW/Bj4K/An4BerH+TPAqUKIU6SU/gnGexDoQ/2gPjHquSuAJuAZ4/HdwCpj/ANABXAOsBx4PY65F00gJnJGr4jnPZjkOLcClwO3Ay8ac3xwku3vBBpQsV1rgP8A2oD/MZ6/GrgZ9Tn5nbGu1ZjnAqAOuGmS8UdzOkoU/Rp17j8L3COEqJNSdk66p+J9gAv1PpQAXwTuAh5BuW+/j/qcfRb4MSpkIJbNxvJM4JUJjtGOet3/DdQA/2ms3yWEECj364XAH4zxzkfF09UDnxg11puAy4z5tgBvTPLaLgSOAf6M+uwtMcY7VcQX8nAz8AHgDuAFlNt3vPf+FGNedwOHUd/ZjwNPCyGOk1I2Sym9QiVoXCGE+C8pZShm/ytQn9s/TzEfjWZ8pJT6T//pP+MPuAaQKIFUjvrhuQLoQImnBcZ2txrb/XjU/nXAEPC/o9YvAfzAt43HJxr7XzbJXD5nbFMex3zrR61fb6xfH7Nug7Hus6O2PcNY/8FR688y1l87xTm73Tg/jph1xSgryU9jHkvg+hm8J5P9HUz0PYh5H2P3XWOM9/NR+/7RWH9DzLobjHV/GLXtvUDHqHX9wK3jvLbzjTHeNc5zI+ZmrJNAEFgas+4EY/11U5zHemO7DqA4Zv23jfU7gJyY9XcYx8odZ6wA8Ls43rsHxnkNlxjH+78JzvHxo15vBDgpzs+KZ5x15uf7A1Psa34nfzVq/Z/Hee/HOyeLjc/X12LWXWzs+9ZR274AbEn0u6D/9J/5p92mGs34PIKyHhxBWVZagXdIKRtHbferUY8vRVm0/yaEKDf/gF6UBe1cYzszDujNYuJYuV5j+a7R7qQZEGLY+mNyOUpcPDJqzm+gXve5TM6dQBlwQcy6dwNO4zmAQZQQWC+EKJ3m3D+LsqyM/nt51HbxvgfjYbofR7+vP59kn9+PevwsUCaEKJxkH5MyY9kdx7YmT0kp95kPpJSvoT5Pi+Pc/x4pZU/MY/P83S6lHBq1PgdlhR1NN+rmZjq8DSXIRlsbfxTzfCwvSClfjWdgGWNZE0LkCyHKgD0oC/OEbl6DtxrLX4xaP8btKaUcjDmOxziOF9g96jj/RlnVr47ZfjHKenrbFPPRaCZEu001mvH5LLALdSd9GDgipZSjtokAB0etW24sJ3LtNABIKQ8IIX4M/BfwASHE88C/UD+gpuvrbyhX5u+B7wohnkS5m/4uR7pgEqFJjnWBLgfyMVx541A5xZiPon7M34cSvRj/H5RSvgQgpQwIIf4H+CHQKoR4GXgIuE1KeSTOub9ijheLEOLzQGzpirjegwlYiLKU7B+1ft8425ocHvXYFGIlxB+sL+Lcbrzjmccsmeb+5k3C6PfBXD/euAJ1nqbDQqB1lIAEJXwiKAthLKPfiwkRQpQA30W5WUffJBTFMS/J2Pd6zzjHcQNfR7lY5416Ouq6llKGhRC3o8qrFEgp+4x9wqiwBY1mWmjxptGMz7hCYRRD44go00L2FowYuFFE79illP8thPgDyo10Ecry8DUhxDlSyp1SykEhxDmo2Jq3oly5fwH+SwhxtnH3P9EPqH2C9YPjrLOhfnDeN8E+k1qFpJRDQoh7gcuEEE6gEFX24kejtvupEOJ+VMbuhahSE18RQrxdSrlhsmMkSNzvgUWEJ1gfjyDrMJbxCq+ZHm+y/RMZt5jhuSebRN6vv6Ni8X4EbEXFBEqUBdhKT9PPUVnCP0e5QHtQwvOn4xznz6iY2EtRMaVXAf+WUrZYOB/NHEOLN43GWkwrwWEp5c6pNpZSvo4K1v+OEOIEVPD2f6JqfCFVBuIG4++LQohPolx6l6KEnCmsikcNvTDBOV8IvCSl7E9gv1juRFkJL0ZZIhwMu0yjSCkPoH7gfmpk8b0KfBX1+qwiofdgFIdQYmUJyvJqsnSGc5pIZJvHWDTB87MOI8nCycjzkwiHgAuFEEVSyt6Y9ctRwufgNOdVgnLd3yClvDFmvZv4xLH53i8FYj83y8fZ9r3An6WUnx9nDiNErZRyhxBiC3C1EGKXMd6NaDQzQMe8aTTWcg/KgvG/RlbdCMxsSaOMwOibp10oK0OxsU0ZY9liLIuNpSlU3hRzDDtwbQJz/hvqWvC/48zXbvwgTcVTKLfrFcbfG7FxSkZc0Ij6XFLKo6iszOIE5hoPcb0HE/CosfzUqPWfmeGcfIwjIKSUzajM27UzHD+VmDFdL0xz/wdQn7fPjlr/X8ZysszeyTAth6Pf8/8kvt+6h43l6ILC47334dHHEUK8H5V1Oh5/QsVafhFlDbwvjvloNBOiLW8ajYVIKRuMMhU/QNW3+gfKpWIW+P0bKkvxPOCXQoi7UbE+AiV6CoxtAP6fURfrQZQ1ogRV9sCH+gFESvm6EOIllOWuFOhCuT/j/m5LKZ8RQvwS+IJh/XsUlU24FBU79L+ozMfJxggbr+XDqK4U3xi1yXLgSSHEXShLYwDlCl4JXB/vXOMhgfdgvH03CyHuAa4TQhQBLzFczgSmH+e1CbhACHE9cBRok1KatQPvB94vhLDJUbXeZikXol7Dpmnu/wAqkP9GIcRC1A3JecB7gN9KKXdMZ1CpSnNsQFmonShL2lmo92/KEipSyleFEH8FPmm898+jBNd4lrd/Ah8Uqr7jDuAk1Pd3onjKv6LiPd+Dyjq22nWvmWNo8abRWIyU8odCiL0oS8LXUHf9R1GFfu8yNtuGutN/K8pF6keJmndJKe83trkfVfbiQ6iaaJ2oumNfl1IeijnkVcBvgS+hRMotKEvYvxOY83WGa+cTwLdQsWKHUTFET062bwx3otommf/HcgTl5j0f1e9SogLBPyql/EO884yXON+Difggqp7Y+1FZs4+jfph3o96n6fCfqPfoBlTB3qcZPq9/AD6PEhlPTXP8lGBkPV+GKo8yLaEppZRCiHejXIfvQ53vw6gWYnE3vZ+AK1FZrB9HZco+gxKGj8e5/0dQWeZXoYT+k6js19HJHJ9DlaO5AhUusAkVMvCD8QaVqrbjw6j4Vp1lqpkxYmwCnUaj0WhiEUKchAqA/4CU8i9JGP9RoEdKOWH3gNmAEOJSVF2/JYbLVxMnhtX5NGBhhlhYNbMYHfOm0Wg0MYyOzTP4PCqb8JlxnrOCrwLvEUIsS9L4VvFl4BdauCWGEKISw+qmhZvGCrTlTaPRaGIQQvwfKij/KZT7+C3G3++klB9P59w0mYVQvXTPRLljTweWGYk6Gs2M0DFvGo1GM5IXGK5Dl4+Kx7oBFQuo0STCOai2X0eAa7Rw01iFtrxpNBqNRqPRZBBzyvJWXl4u6+vrk3oMn89HXt5ErSo100GfU+vR59Ra9Pm0Hn1OrUefU+tJ9jndvHlzh5SyYvT6OSXe6uvr2bRpuqWJ4mPDhg2sX78+qceYa+hzaj36nFqLPp/Wo8+p9ehzaj3JPqdCiEPjrdfZphqNRqPRaDQZhBZvGo1Go9FoNBmEFm8ajUaj0Wg0GYQWbxqNRqPRaDQZhBZvGo1Go9FoNBnEnMo21Wg0Go0m0/B6vbS1tTE0NDSjcYqKiti1a5dFs9LAzM5pTk4OlZWVFBYWJryvFm8ajUaj0cxSvF4vra2tLFiwgNzcXIQQ0x6rr6+PgoICC2enme45lVIyODhIY2MjQMICTrtNNRqNRqOZpbS1tbFgwQI8Hs+MhJtmdiGEwOPxsGDBAtra2hLeX4s3jUaj0WhmKUNDQ+Tm5qZ7GpokkZubOy13uBZvGo1Go9HMYrTFLXuZ7nurxZtGo9FoNBpNBqHFm0aj0Wg0Gk0GocWbRqPRaDSaOcMNN9zA8ccfn+5pzAgt3jQajUaj0SSFLVu2YLfbOfPMMxPab/369Vx33XVJmlXmo8WbBvxeCIfSPQuNRqPRZBk333wzn/rUp9ixY4cuEGwhWrzNZQa74aEvwPfq4VfrYPfD6Z6RRqPRaLKEwcFB7rjjDq699louu+wybrnllhHPv/TSS5x33nnk5eVRVFTEeeedR1NTE9dccw1PP/00v/zlLxFCIITg4MGDbNiwASEEHR0d0TEOHjyIEIJNmzYBEA6H+ehHP8qiRYvIzc1l2bJlfP/73ycSiaT0tScb3WFhrhIKwp8ugdYdcOL74egr8Nf3wYcfhoVnpHt2Go1Go5mAG//1OjubvAnvFw6Hsdvt0zrmsfML+b93HJfQPnfffTcLFy5k1apVXH311Vx++eV85zvfIScnh23btnHuuedy9dVX8+Mf/xiXy8UzzzxDKBTipptuYs+ePaxYsYJvf/vbAFRUVHDw4MEpjxmJRFiwYAF///vfqaioYOPGjVx77bWUlZXx0Y9+dDovfVaixdtc5alvQctrcMVfYOXbITgAPzkWXvq1Fm8ajUajmTG33HILV199NQDnnHMOHo+H+++/n8suu4zvf//7nHTSSfzud7+Lbr9y5cro/06nE4/HQ3V1dULHzMnJ4etf/3r0cX19PVu2bOGvf/2rFm/TRQjxJuB64GRgPvBhKeWtMc8L4P+Aa4ES4GXg01LK12O2KQF+BlxirPon8BkpZU8KXkJ2cGQjPH8TrPmQEm4ATg+s+SC88AvoPQpFNemdo0aj0WjGJVELmEkqe5vu27eP5557jjvuuANQxWivuuoqbrnlFi677DK2bt3Ku9/97qQc+ze/+Q0333wzhw4dYnBwkKGhIRYuXJiUY6WLVMe85QM7gM8Bg+M8/0Xgv4HPAKcAbcC/hRCxn7Y7gDXAxcbfGuC2JM45+9jwHcirgDd/e+T6tR8FJGz6Q1qmpdFoNJrs4OabbyYcDlNXV4fD4cDhcPDd736Xxx57jCNHjkxrTJtNSRYpZXTd6NZSf/vb3/j85z/PNddcw6OPPsqrr77Kpz71KYLB4PRfzCwkpZY3KeVDwEMAQohbY58zrG6fB74rpbzHWPchlIC7EvitEGIlSrCdJaV80djm48CzQohjpJS7U/RSMpemrbD/SbjgRnDlj3yuZCEsezNsuxPO/9/0zE+j0Wg0GU0oFOJPf/oT3/nOd3j7298+4rmrr76aP/7xj6xevZonn3xywjGcTifhcHjEuoqKCgCam5uj/7/66qsjtnnuuedYt27diDIj+/fvn8nLmZXMppi3RUA18Ji5Qko5KIR4BjgD+C1wOtAPvBCz3/OAz9hGi7epeO6n4CqCtR8Z//mFp8Oeh2GgCzylKZ2aRqNJL2+0ePn+I7sJRZRlw2ETfPjMes5eVsHfXzlCz2CQa9+0hJ6BIF++dzu+4PCP61Xr6njzcdXsbPJy39ajfOWtK3VPzjnKgw8+SEdHBx/72McoKysb8dz73vc+fvOb33Dvvfdy+umnc+211/LpT38at9vNs88+y0UXXURdXR319fVs3LiRgwcPkp+fT2lpKUuXLqW2tpYbbriB7373uxw8eJBvfvObI8Zfvnw5t956Kw8//DBLly7lzjvv5Omnn6akpCSVpyDpzCbxZkYlto5a3wosiNmmXcbYTKWUUgjRFrP/CIQQ16Ji6KiqqmLDhg1WznkM/f39ST/GdHH52zlt5/0crnsPB17aMu42pZ1hTgC2PnYHvcWzowL1bD6nmYo+p9aSLefznj1BnmoYYlGRck/1BCTX7G7j1Hl2XmwKU+YWLI8cYXt7iId3BFiQL3DZBU39Ebo6u3C1u/nrGwEePRhiuWihwjP9yJxsOaczpaioiL6+PkvGCofDlo01Gb/97W85++yzcTqdY473lre8hS996UscOnSIf/7zn9x4442cdtppuFwuVq9ezTnnnENfXx+f+MQn+MQnPsGxxx7L4OAg27dvZ+HChfzhD3/gv/7rvzjxxBNZtWoVX/va17j88svx+Xz09fVx5ZVX8sorr3DllVcipeSSSy7huuuu4/bbb4/OJRAIEIlELDkXVpxTv9+f+GddSpmWP5QF7ZqYx2cAEqgbtd0fgEeN/78CNIwzVgPw5amOefLJJ8tk89RTTyX9GNPm6R9I+X+FUnYdnHib3ka1zUu/Td28pmBWn9MMRZ9Ta8mW8/nJ2zfJc77/ZPRxz0BQvvuXz8mF//OAXPn/HpYn3fiolFLKh7c3yYX/84Dc0dgjpZTyc3/dIs/4zhNSSimv+cPLcuH/PCCf2NUyo7lkyzmdKTt37rRsLK/Xa9lYGoUV53Sy9xjYJMfRM7OpSG+Lsawatb4q5rkWoELE2OKN/ytjttGMh5Tw2t+g7gwV2zYRBfPAXQxtO1M2NY1GMztoaPexuGI4FrYoN4fb/2Mdf7zmFK5aV8eA4SY1l3lO5bxZUpFPY88gg8EwDR0+APa29qd49hrN3GE2ibcDKAF2oblCCOEGzmY4xu1FVMbq6TH7nQ7kMTIOTjOapq3QsQdOvGLy7YSAymO1eNNo5hiRiORAh4/F5Xkj1nucDs5dUUmey0EgFCEckVHx5nGqgq+m4HujxcuRrgEA9mjxptEkjVTXecsHlhoPbUCdEOIkoEtKeVgI8VPgK0KIN4A9wNdQ7tU7AKSUu4QQj6AyT681xvkt8IDUmaaTs+1OsLvg2HdNvW3VsfDa35W1TgccazRzgsaeQQKhyAjLWyymlW0gGGLQEG+5hnhbUqkE35NvtBExLht725IfW6XRzFVSbXlbC2w1/nKBG43/zXLI3wd+AvwS2ATMAy6SUsZeBa4EtgGPGn/bgKtTMfmMRUrY9U9YdiHkFk+9feWxEPCqYr0ajWZOcMBwdy6uyBv3eVOoDQbD+IIhQFnlAOrL8hACHntd5ZutXVjCvrZ+IhE57lgajWZmpLrO2wZgQlOOEZx3g/E30TbdwAcsnlp20/wq9DXDirfFt32VUb27bScU1yZtWhqNZvbQ0K7cnBOJN9NFOhAMMxgM43LYsNvU5dydY6emJJfdreo++83HVfPKwW4aewapLfWkYPYazdxiNsW8aZLFnkcBAUsvnHJTACpWqGXr65Nvp9FosoaGDh8FLgcV+a5xnzfFmy8YYiAYjj42WWK4W+cVuTmpthjQrlONJllo8TYX2PMI1JwC+RXxbZ9bDPlV0NWQ1GlpNJrZg8o0zZuwsK7pIh0Mhg3xNtJxY4q3JRX5LKtUHQ11xqlGkxy0eMt2vM0q03T5mxPbL78SfB3JmZNGo5l1NLT3T5isACPdpgPBUDQGzsR0ty6uyKPIk0NlgYsn3mjjxf2dOvZNo7EYLd6ynb1Gt7HlFye2X14F+Nqtn49Go5l1DARDNPX6x5QJiSV3hHgLkzeB29Rcnr+yio0Hunj/71/imw/uStLMNZq5iRZv2c6BpyG/ejgJIV60eNNo5gwPbVc1zk80YtXGwzOqVMhoy9tJtcVcafQ3BfjOpavY+v8u5P2n1vGH5w+wYXdbciavmfPcfffdI9z9t956K/n5E1uR42HDhg0IIejomJ0eKC3eshkp4cCzsOjsxOu1afGm0cwJwhHJr57ax7HzCjl7WfmE2+XFWt6GQmNi3tw5dr797lVUF7mj60rynPzfO47lmKoCrr/rNfxDYTRzh2uuuQYhBEIIcnJyWLx4Mddffz0+ny+px73iiitoaIg/Zru+vp4f/vCHI9adccYZNDc3U1ZWZvX0LEGLt2ymYw/42qD+rMT3zSuHoQEIJvdLptFoUk+r1x+NQ3vgtSYaOnx85rylEyYrwMg6bwOBsdmmE+HOsfPRsxbR0R+gvS8w88lrMooLLriA5uZmGhoa+OY3v8mvfvUrrr/++jHbhUIhs1f5jMnNzaWysnJGYzidTqqrqyf9TqQTLd6ymYPPqmX92Ynvm2dkpmrrm0aTVext7WPdt5/gLTc9y5fvfY2v3reDZZX5UXfnRJiWtolKhUxGjkP9AIZ14sKcw+VyUV1dTW1tLVdeeSVXXXUV//jHP7jhhhs4/vjjufXWW1myZAkulwufz0dvby/XXnstlZWVFBQUcM4557Bp06YRY/75z39m4cKFeDwe3v72t9Pa2jri+fHcpg899BDr1q0jNzeXsrIy3vGOd+D3+1m/fj2HDh3iC1/4QtRKCOO7Te+9915WrVqFy+WitraWb33rWyMEZ319Pd/85jf5+Mc/TmFhITU1NfzgBz+w+pQCKS7Sq0kxB56FwgVQujjxffOMuxZfB5TUWzotjUaTPg52qt6jPYNB7tncyNtOmMdnzluKzTa5hcFuE7gcNqNUyFi36WTYjB/EiEWWlTnPw1+Clu0J75YbDoF9mj/71avgLd+d3r6xc8jNZWhoCIADBw5wxx13cNddd+F0OnG5XJx77rkUFRXxwAMPUFpayp/+9CfOO+88du/ezbx583j55Ze55ppr+MY3vsF73/tennrqKb7yla9MesxHHnmESy65hC996Uv88Y9/JBQK8dhjjxGJRLj33ns58cQT+chHPsInP/nJCcfYvHkz733ve/na177GVVddxSuvvMLHP/5xnE4nX/jCF6Lb/eQnP+HGG2/kC1/4Ag8//DCf/exnOeusszj99NMnHHs6aPGWrUgJB5+DpRdMrz9pnhH7oi1vGk3G88iOFnY29fJfFx1DZ79yXd7zyTOoLHDjdMTvgPE47arDwtDYhIXJ0OJNA7Bx40buuOMOzj//fACCwSC33XYbVVVVADz55JO8+uqrtLe3k5ubC8A3vvEN/vWvf3HbbbfxxS9+kZtuuonzzz+fr371qwAsX76cV155hVtuuWXC437jG9/gsssu45vf/GZ03QknnACAx+PBbrdTUFBAdfXE1ucf//jHnHPOOdx4443R4+7du5ef/vSnI8TbRRddxHXXXQfAZz7zGX72s5/xxBNPaPGmiZP23TDQMb14N9BuU40mi7jzlcNsOtitxJsvCEB5vish4QbKddo7OMRQWI4pFTIZpngLRxI6nGYipmkBG+zro6CgwOLJTM4jjzxCfn4+oVCIoaEh3vnOd/Lzn/+cX/3qV9TU1ESFGyjr1sDAABUVIwvK+/1+9u/fD8CuXbt4xzveMeL5008/fVLxtnXrVq655poZvY5du3bxtreNbDF51llnceONN+L1eiksLASGRaHJ/PnzaWuzPtNai7ds5egrall32vT2Ny1v/Tq9X6PJdPa19dMfCOELhOjoD5DvcuDOiV98meQ67XT6Asb/8f982A2NqC1vc483velN/O53vyMnJ4f58+eTk5MTfS4vb2RdwUgkQlVVFc8+++yYcUxxNBuJTWqIfX3mc5GI9XctWrxlKf37XyQs89jbV8LaibP/JyYnF5wFusuCRpPhDAbDNPYMAtDWF6CzP0hZvnNaY+U57XT2K8tdIgkLQuiEhbmKx+Nh6dKlcW27Zs0aWltbsdlsLF48fqz2ypUreemll0asG/14NKtXr+aJJ57gYx/72LjPO51OwuHJy9isXLmS559/fsS65557jgULFqTcmgk62zRrCR95hVcjS3hqzwzEV76u9abRZDr72/sxDV5tXj+dvgBledMTb7lOOx1GzFwi4s1uiDdteNNMxgUXXMCZZ57JO9/5Th5++GEOHDjAiy++yP/93/9FrXGf/exnefzxx/nOd77D3r17+f3vf89999036bhf/epXueuuu/ja177Gzp07ef311/nJT37CwIBK3qmvr+fZZ5+lsbFxwqK8//3f/83TTz/NDTfcwJ49e/jLX/7Cj370Iz73uc9ZexLiRIu3bCTQT4F3H6/KpWw51DP9cXShXo0m49nfPtwcftjy5prWWB6nIxozl0i2qd3IZA1r9aaZBCEEDz30EOeddx4f+9jHOOaYY7j88svZvXs38+fPB+C0007jlltu4de//jUnnHAC9957LzfccMOk4771rW/lvvvu4+GHH2b16tWcc845PPXUU9hsSgJ9/etf58iRIyxZsmRMvJ3JmjVruOuuu7jnnns4/vjj+dKXvsSXvvQlPv7xj1t6DuJFu02zkaat2IiwNbKEbUd7CIUj2G0i8WKDeRXQdSA5c9RoNClhX9tI8dbRH2R1XfG0xsp12qPWs8TcpmqpY97mFrfeeuuEz91www3jiq6CggJuuukmbrrppgn3/fCHP8yHP/zhEevMDE9QnR1GJyhccsklXHLJJeOOd9ppp7Ft27YR69avXz+maPCll17KpZdeOmJdX19f9P+DBw+OGXvDhg0TvYwZoS1vWUjkiEpWOOw+loFgmN2tfXzwDxu56CdP88K+BNyoeeWqQ4NGo8lY9rX1U1/mwWm30er10+ULUJY3PctbbIZpIqVCTMtbRMe8aTSWoMVbFjJ48GUORKp4y7pjAfj1hv08u7eD5h4/V978cvwNovMqYKATIrofoUaTqexr62dpZQEVBS72tPYRkUw7YSHWVZo3rSK90zqsRqMZhRZvWYi9aQuvyqW85fh5lOc7eeC1ZsrzXTz9xXMB2HakN76B8ipARmCwO4mz1Wg0ySIUjnCw08fSynwqClzsavYCTDvmLdbalojb1KazTTUaS9HiLdvob8ftb2MXi1hWlc/quhIAPnJWPaV5TsrynLR4B+MbSxfq1WgymkNdAwyFJUsr86kqdNHqVZmi5dPMNvXkTM9tatMxbxqNpWjxlm20qn53fUUrcTnsnL+ikupCNx84bSEA1UVuWnr98Y1lijddqFejyUga2n0ALKnIo7LAHV0/7WxT1/TcptGYNy3epkUyirxqZgfTfW91tmm2YTQrts9fBcD7Tq3jilNqo5mm1YVumuIVb7nFaumP082q0WhmFU1Gcd6aEg+VBcOCbfoxb8raJgS4c+K/9zeb3mu3aeLk5eXR2NhIVVUVOTk5iVcN0MxKpJQMDQ3R2to6ptNEPGjxlmVEmrfTIkspKR9usBv7Za8qcrP1SE98g7mMdiQBr4Uz1Gg0qaKpZxCn3UZZnpPKQiXebAJKPDMTb7k59oREhE0X6Z02NTU1dHR0cOjQIUKh0IzG8vv9uN3uqTfUxM1MzqnD4aCoqIjy8sTbIGnxlmVEml9jZ2QhlYXjf5iqC910+YIEQmFcjiliVtyGePNr8abRZCJNvX6qi9zYbCLqNi3Nc0bdmIliZpsmkqwAwx0WtOUtcWw2G5WVlVRWVs54rA0bNrB69WoLZqUxSdc51TFv2cTQIPaufeyUC6kqGD+mpdoQdW1G4PKkOI1+bdryptFkJM09g8wrUt/5CuOaMN0abzAs2hLprgC6SK9GYzVavGUTbbsQMszOSD1VE1jeqowLeYs3jrg3uwNy8iDQN/W2Go1m1tHc62d+cS5A1G063Xg3GM4wTdjyphMWNBpL0eItmzCSFXbKhROKN9Py1hxv0oK7UCcsaDQZSDgiafH6o5a3sjwXNjH9TFOIiXlLULwN13mb9qE1Gk0MWrxlE607CNo8HKWC8gnurquNC3lrvOLNVaDdphpNBtLeFyAckVHLm90mOHNpOWsXlkx7TLM8SCJlQtSx1VJb3jQaa9AJC9lE+xu0uBZSZs/FYR9flxe6HeTm2ONzm4LKONUJCxpNxtHUq8qEzC8etsLf9tF1Mxozd4aWNy3eNBpr0Ja3bKJ9N4dstVQVTuwWEUKoQr3xijd34YiYt97BIU751uO81NA509lqNJok0tyjvuPzinItG9MzzZg3Ld40GmvR4i1bGOyG/lb2RuZTVTB5zZmqQlcCbtPCEW7T5t5B2vsCbDms+51qNLOZZtPyZqF4cztmlrCgY940GmvQ4i1baN8DwGuB6glrvJlUFyZgeXMVjHCb9vtVkUizcrtGo5mdNPX48TjtFOZaFx1jswlK85yUJtgbVZcK0WisRce8ZQsduwHYMljFpZO4TUGVC2nzBohEZLRtzYS4i0a4TfsCpniLU/xpNJq00NyrarxZ3U7pb9eeNuUN4miipUJ0kV6NxhK05S1baN+NtLs5KismLBNiMq/QTTAcoWsgOPW4rkIY8kFYiTZfQFveNJpMoKlnMJppaiXLqgooys1JaJ9oqRBtedNoLEGLt2yhfTeDRYuIYJs0YQGI3jXH1WXBPbK/qXabajSZQVOv39J4t5kwnLCQ5oloNFmCFm/ZQvtuevKWAER7GE5EpdEmp60vDtena2SLrH7D8ub1h+jzD01zshqNJpk8vL2Z9r4Aiyry0j0VQLtNNRqr0eItGwj6oPcwra46gCndpqa4a+uLw/LmMi1vKu7NFG+QQJcGjUaTMl5q6ORzd77KyQtL+NDp9emeDgA2nbCg0ViKFm/ZQIfKND1sq8VuE5RNkQlm9jhsj0e8mW5T/0i3KUCjdp1qNLOOXzy5j4oCF7d8aG3CxXSThS1aKkSLN43GCrR4ywY69wOwNzyPygLXlBmk7hw7BW4HbfGUCxnHbWq6QHTcm0Yz+9jX1s+6xaUUe6bfgN5qzJg3bXjTaKxBi7dsoKsBgJ3+srhT+CsLXHG6TYvU0rC89QVC1JTkYrcJLd40mjTzlfu284NH34g+9gVCtHj9LC6fHbFuJnadbarRWIoWb9lAVwMULqCxH6oKJs80NakqdMcn3kZlm/oCIYpyc6gudEfb72g0mtTTHwhx16Yj3L35KNIQRQc6fAAsrshP59TGoIv0ajTWosVbNtDVAKWLae3zT5msYKIsb/G4TceWCsl3OZhf7NYxbxpNGnl+XwdDYUmrN8DRbvVdHBZvs8zyprNNNRpL0eItG+hqIFRcT8/A0JQ13kwqC1WXBTnVnbDDBbac4YSFgCnecmnqtV68hSOSPa19U2+o0cxxnnqjLZrFufmQ6jXc0O5DCKgvm2XiTejephqNlWjxlun4veBrp9+jyoQkEvMWCEXwxmSPjosQynVqlArp8w+Lt5Zev+XZYw9tb+binz4Tn1VQo5mjSCl5ancbF6ysosDl4JWDXQA0dPQzvygXd87syDI10W5TjcZatHjLdLoPANDhXABMXePNpKLALBcSp+vUjHkLhsh3O6gqcDEUlvTE02IrAZp7B4lI6B3QBYA1monY1dxHqzfABSurWL2whE0HleXtQIdv1rlMAYQQ2IQWbxqNVWjxlukYZUKa7fMB4nebGoV6W+NtkeX3IqWMxrzlu1VvQ18gPI1JT0zvoBJt/iHtX9FoJuK5fe0ArD+mgrULS9jT1kfvwBAN7b5Zl2lqYhNCizeNxiK0eMt0jDIhByOVAFRN0RrLxCzUG3fSQsBLIBQhFJHkuRzkuxwA9AWstZD1GBa3wSFrRaFGk00c7BygxJNDZaGbtfUlSAn3bj1KfyDEotkq3mxCx7xpNBahxVum03UA8qtoHLDjtNso9uTEtVu0v2k8ljeXinkzW2MVuIfFW/9UMXMJMmx50+JNo5mIpp5BFpSopvNr6kqoL/Pw9Qd2ArOvTIiJTTB1gpRGo4kLLd4yHaNMSJvXT0WBCyEm765gku9ykJtjj7/Wm98bFWrKbarEmy+oxZtGk2qaegaZX6TEmzvHzl2fOIMTaoqx2wTLqmaneLMLodtjaTQW4Uj3BDQzpKsBll5Aa4c/7ng3UAHElYXxdlkogEBv1PKWH+s2TZLlTbtNNZrxkVLS2D3IGUvKo+sqClz87drTONI1wDxD1M02bDahOyxoNBahLW+ZzNAg9LdAyUJavYG4M01NKgtcHO0emHpDw23aZwirWPGWrISFgE5Y0GjGxTsYwhcMU1MyUqS5c+wsqypI06ymxiaE7m2q0ViEFm+ZTO9RtSxeSKs3/u4KJmctrWDr4R5uee7A5Bu6C0FG8PtUuZB897DbtF8nLGg0KcXsbDK/eHZa2CbCbtNuU43GKrTbNJPpOQSAP28+fX5vNIM0Xq47bym7mr1888GdtPcFuPr0hSwY7wfBaJEV8PUAyvLmMYqA9ltoeYtEJF6/jnnTaCajKUPFm67zptFYh7a8ZTI9RwBot1cB8ZcJMbHbBD9930m8bdU8fvvMfs75/lPc9uLBsRu6lCsmONADKPFmswnyXQ5Ls037/KGoW0XXedNoxsdsSzfujdYsRtd502isQ4u3TKbnMNgcNIWLgfi7K8TizrHziyvX8MwXzuVNyyv4f/e/zrcf2jVqoyIAQr5egKjLNN/lsNRtasa7gXabajQT0dg9iNNhoyzPme6pJIRNCCL6nkyjsQQt3jKZ3iNQuIBWn7J+JZJtOpraUg+//+BaLl9bw++fbeBAh2/4ScNtGvH3YhOQa7hM81z2GSUsSClHuEdjxZt2m2o049PYM8j8Ijc2W3xlgWYLdp1tqtFYhhZvmUzPYSiuo82ruiTE25R+Iuw2wfVvPoYcm40/Ph+TxOBW4k36veS7HNFacvnuHPoC03eb3vrCQU77zhNRodYzONwnVYs3jWZ8Ygv0ZhJCqLhWjUYzc7R4y2R6jkBxHa1eP+4cG4XumeefVBa4eceJ87lr09Hh5vBGzJsp3kzyXXZ80xRvUkpue/EQPQND7GntA7TlTaOJh6Yef7RAbyZht+mYN43GKrR4y1RCQehrNsSbqvEWb3eFqfjoWYsYHArz900qIcJ0m9qCfdF4N2BGCQtbDnfTYLhmdzWrEiRmmZCi3BydsKDRjEMwFKG1z59xmaZgdFjQ2k2jsQQt3jIV71FAQlGtqvGWYKbpZBw7v5D6Mg/bjvaoFc58QGAP9o2wvOW5HNGuC4ly16aj5ObYyc2xs6t5pOWtutCtExY0mnFo9fqRksx1m2rLm0ZjCbNKvAkh7EKIbwghDggh/Mbym0IIR8w2QghxgxCiSQgxKITYIIQ4Lp3zTgs9h9WyuI62vkDCNd6moqbEw9FuVZIAmw1cBThCfeTFiLeCUeItEpG83tRLU88gL+zr4It3b2Pjga4xYw8GwzzwWjNvXTWPFfMKopY37+AQLoeNIk+OdptqNOPQ3KviW+cVWXezFqVzP8lMB7XbhI5502gsYrYV6f0f4NPAh4DtwAnAn4AA8A1jmy8C/w1cA+wG/hf4txDiGCllX6onnDaMGm+yqIZW727OW1Fp6fA1Jbk8vqst+li6CqHPS0X+sEjMdyvxJqVECMETb7TxsT9vGjGOx+ng1EWlI9btae2jPxDiwmOreGavjQdfa0ZKSc/AEMWeHNw59hHxbxqNRtFiJCdVzzA5aQyv3wd3XQNrPwJv/4m1YxvoOm8ajXXMKssbcAbwLynlv6SUB6WU/wT+CawDZXUDPg98V0p5j5RyB0roFQBXpmnO6aHnMAgb/a4qBoLhGZUJGY+aklw6+gNRC1jAnkdOyMeZS4ebYee5HIQjkkBI3a0f6lQxbP/79mP52ftXU57vHNeC1t4XAJT1YGV1Ab2DQzT3+ukdHKIoNwe3w4Y/qC1vGs1oWg3LW5WVlreOfXD/Z8BVBJv+AK/+1bqxY7AJQViHsmo0ljDbLG/PAZ8SQqyQUr4hhDgWOA/4jvH8IqAaeMzcQUo5KIR4BiX8fjt6QCHEtcC1AFVVVWzYsCGpL6C/vz/pxwBYsfsVip2l/OuplwDoPHqADRuOWDa+t0W5Q+979Gnm5duo80EBAwQ79rJhwz4Amg8r69ijTz5DkUuweXcQhw0WDR1EdAtEeIhDR5vYsGGk6/S5I2q/fTu24PerO/G/P/Y8B5uHQIK3e5Duvkj0PKbqnM4l9Dm1llSdz01vBHDaYfOLz1mWoLR6yxfxRGDzyT/gmN0/p/Cfn+WFjiLCDo8l45v4fIO0h3xxnyf9GbUefU6tJ13ndLaJt++hrGg7hRBh1Py+JaX8lfF8tbFsHbVfK7BgvAGllL8Dfgewdu1auX79eqvnPIINGzaQ7GMAcPCH4FxK/YoT4LmXWb9uNacvKbNs+LyDXfzutReZv3wV5yyvYMsLBVS5ejjzzedGt+nacpTbdm7jxJNPpb48j/tbX6Wqu4tzz1XblG59hsJSD+vXrx0x9rbH98Lre3jHhesJhMJ86+XHyKmoRzQ3U1ecS1mek4b+tuh5TNk5nUPoc2otqTqfdzdtYUGJl3PPtehYza/Bht1w8fc47bQroD4P/nYVZ6+sggUnW3MMg+Idz1GS52T9+lPj2l5/Rq1Hn1PrSdc5nW1u0yuAD6JcoGuM/z8lhPhoWmc1G/E2QtECWvsMN0oS3KYAR7sH6PYFaRzMocwRHLGNmXlqJi20j0qccOfYxi350d7vp8STg9Nho8CdQ21pLq8e6cFruE1znXadsKDRjEOr109lgYXf9a23g90JJ1yuHpcvU8uOfdYdw8BmE4R1woJGYwmzTbz9APihlPJOKeV2KeVtwI+BLxvPtxjLqlH7VcU8l/1ICd4mKJxPq1fFj820u8JoKgvc5NgFR7sHeWZvO17pIZ+BEduYNd/6jFpvbX3+EQkN7hz7uCU/2vsCVMT8AL111Tz+vbOV5t5Bij05uHJs+EM6OEajGU2rN0C1VfFuQ3547W+w4u3gMZKKShaBsEPnXmuOEYNNCHS+gkZjDbNNvHmA0b/2YYbneQAl0i40nxRCuIGzgRdSMcFZwWA3hPyqr6nXT77LMaL+mhXYbYL5xbkc7R7kiV1tDOXk4xgamcxrHtM3oeXNTiAO8fafFyxneVU+EYmRsGAnGIrou3SNJgYpJS1ev3WZpm88AP4eWHP18DqHE0oWQof14s0ust/yJrU61aSI2Sbe/gV8SQjxNiFEvRDi3cB/AfcBSPXN+CnwP0KIS4UQxwO3Av3AHemZchroPaqWhfNp81pf481kQXEuBzt8PPVGG9UVlYhwAEKB6POxbtNgKEL3wBAV+cM/LLkTWN7a+gJUxhQVdufY+ekVq8nNsbOwzEOuUzW+D4S061SjMekZGCIYilhnZd96GxTVwaL1I9eXLYNO692mc6FI7xfufo1rR5VL0miSwWwTb58B7gZ+BewCfgT8HvhqzDbfB34C/BLYBMwDLppTNd68TWpZWGN5d4VYakpy2d7YS18gxKIaI1ckMHyaY8VbR7/pvp085k1KOcbyBqqrw5b/dyHvPGkBbof6WOoWWRrNMGZ8qyWWt+5D0LABVl+linDHUr4sKQV7s7236ZGuAe7dcpTXjvameyqaOcCsEm9Syj4p5eellAullLlSysVSyq9IKf0x20gp5Q1SynlSSreU8hyj3tvcwduoloXzae3zW56sYFJTokoFeJx2FtXMVyv9wxcmM+atPxCizajdFhvzlusca3nrC4QIhCIjtovdPnapW2RpNMO09FqYnPTqXwABJ1019rmypRAaNFrwWYcq0mvpkLOK2146RERCe38g693DmvQzq8SbJk68jWBzIPMqaPUGLE9WMDEzTtcfU4HTU6RWBrzR53Nz7NiEinkzC+/GWt5cjrFZo23esduNxp2jxJvOONVohmn1muJtht/3SBi2/gWWnAvFtWOfj2acWhv3ls3ZpgPBEHduPIzTYSMckXT6AlPvpNHMAC3eMhFvExTMo2swTDAUSU6fQ6C+PA+ANx9XDa5CtTLGbSqEIM/loM8fos1w6cS6Q1XCwkjXS/s4FrrRuByG5U13WdBoorTGceMTF5v/qKxqaz44/vNlhnizOO7NnsUxb//e2YrXH+JDpy8Ehm9SNZpkocVbJuJthML5yW1SDayuLeYv/7GOd5wwH9yGePN7R2xjNqc3RVl5rNs0x04wPDJrtN2IjRsd8xaLTljQaMbS4vVTmueM3txMb5Ad8MhXYMn5sPKd42+TX6lu1qy2vGVxb9Oj3YMAXLBSVbEyraQaTbKYbR0WNPHQ2wjzTogRb7lJOYwQYriXadTyNlK85bkc+IyYt9I8Jzn24fsBd46ZeBAmz0huaDMuapWTJFnohAWNZixtXv/0XabeZtW3dPOtkFsM7/7t2EQFEyFU3FvH7ulOdVyU29TSIWcN7X0B8l0OFpYpb0Wrtrxpkoy2vGUa0QK9C2jpVXd7ybK8jcA1vuUt3z1seRtd+X28xIP2/gBOh43C3InvG6L7abepRhNF1XgbZbGORJi08q2UsPH38ItT4JkfQPUquPJvkF8x+cGqV0HztokzTiMR2Pd4QhmpNpG9ddA6+gOU5zspz3cihLa8aZKPFm+ZxmC3ygQrXEBTrx+HTYxwVSYN99iYN4CFpR62Hu5hX1v/GFeo2zE28aC9L0BFvmvSptrRhAXtNtVoorT0BoYtb74OeOTL8IPFcNOJ8OpfxxdST38fHroeatbCZzbD1ffC/NVTH6xmrcos72oY//ndD8Lt74FNt8Q9f3sWJyx09KvyRw67jbI8VzQGWKNJFlq8ZRoxZUJaepUbxWabWAhZhj0HHLkQGFnD6LrzljE4FOZAh2+seHNOIN6m6M3o1gkLGs0IhsIROn2GeJMS7vkobPwdLHoTuIvgH5+Aez4CoZj+w/sehw3fgRPfD1ffB2VL4j+g2ZS+cYKCs7sfUctnfwRDg3ENKbI45q2jPxi9ia4qdGm3qSbpaPGWaUQL9C6gqWeQ+cUpcJmauAvHuE2XVubzgXV1wNgkhPFi1+ISb05jP93fVKMB1PdGSqNMyLa/qgK7F38XLv8zXPs0XHAjvH4f/PUKVWD3jQfhro9A5bHwth+rOLZEqFgBznxo3Dz2uUgE9j6m4uL6mmHTH+Ma0p7Fdd6U29QUb27tNtUkHS3eMo1Yy5vXT3WSkhXGxVUwJmEB4HMXLGdxeR6ra0tGrB8d8zYUjtDQ4WNhqWfSw5hu0/H6omo0c5EWQwzUuAeVu7T2NFj7UfWkzQZnfR7ecRMcfB5+fjLceSWU1sOVd4Jz8u/buNjsyr16dBzLW/NW8LXBm76gLH8v/CyuIbPVbRoMRegZGNKWN01K0dmmmYa3CYQdmV9Fc+9rXHxcCi1vuaUw0DVmdWmekyevXz9m/ehiu/va+gmGIqyqKZr8MDnabarRxGJmaS9tf1w1k7/4O2OzRU++Bpa/BV65WTWYP+Oz4JhBPOyCNfDir1Q/49hx9jwGCFh6IfS3wYFnVCxubsmEQ0H29jY1C/KWFzgBlUnf6QswFI6MyL7XaKxEi7dMo7cRCqrpTHKB3nHJK1c9EeMkNyrelPtzR6OKlzt+weTiLcduw24TOmFBozEwW2OVH3pIFdGdKOmgoArO++r4zyXKgrUQGYKW7SqBwWTvo1BzCuSVQUm9Wtd9aErxZheCSBZa3jr6VJxhrNtUSuVKTVYZJ41G3xZkGkaBXvNinlK3aV45DHTEvblZ5810m+5o7CXPaWeRUQtp0n0dY5vaa5KLlFJnyc1SWrwB5tl7yTn6Ahx/aeIxbNPBTFrY/dDwus790LQVVrxVPS5RHQXomfqmLlt7m3b0jyxQbvae1a5TTTLR4i3TMGq8NfWoDK+UJix4ymGgc/K6UjGMdptub+zluPlFcWXHjtfUXpNcfv30ftZ9+wme2dOe7qloRtHm9fPe3C0IGYHjLk3NQYsWqGM991M49IJat+1OEDY44Qr1OGp5OzjlcDabIJyFblOza4xZ59Is56KTFjTJRIu3TEJKw/K2IBrAXJ1qt2kkpGJu4iBWvIUjkp3NXo5bUBjXvuM1tdckj6PdA/zsib1ICV+8+zV6B4bSPSVNDC1ePxeLF1T2aOWK1B34HTcpgXb3R5RrdNudsHg9FM5Xz7uLlLs0HvGWpUV6R1vezN6zbVq8aZKIFm+ZhL8HhgagcD5NPX5y7ILyvBQU6DXxGK2yfJ1xbZ4bI972t/fjH4qwaop4t+i+Ti3eUsk3H9iFQPCbD5xMe3+Abzy4M/pcNsYpZRpdvb0cM/QGLH9zag/sLoQrboPgAPzuHOg9DCddNXKbkvq4YmGzNdu0oy9IntMeza4vy3NhE9DWp92mmuShxVsmEa3xNp/m3sHUFeg1yStTyzjj3tzRrNEI24/Gl6wwvK+OeUsVv96wn0deb+G685Zy8fHVXH3aQv6xtZGO/gAvN3Ry3P89yr62vqkH0iSN8r7d2AlDzampP3jVcfDB+1R9N1chrHjbyOdL6uO0vGWpeOsPUB5Tu9JuE5TmuaIWOY0mGWjxlkn0GjXeimo43DVA3RT10iwnanmLLybKbhM47Tb8oTBvtHhxOWwsqciPa1+3dpumhL9vOsL3HnmDd540n0+eoyrwX7mujlBE8o+tjfxqw34Gh8I8+UZbmmc6d+kPhDgm9IZ6EJv1mUoWnAzXPgUf/AfkjEqSKl4IPYchMvn31SZEvOGyGUVsgV6T8nwn7X3BCfbQaGaOFm+ZREyB3kOdAyyMI2vTUvKMZta++DNOXTk2BoNh2vpUax97nJZCnbCQGn69YT+r64r54XtPjFpxl1cVcGJNETc/e4CnjeSFF/bH5yrXWE9Lr5/Vtv0M5M6H/Mr0TaRsyXAGaiwl9aqkiOkZmAC7jYkTFrzNcPOF8PiNM59nijGb0sdSnu+K1n/TaJKBFm+ZhLcJhI1eRxldviD1ZSm2vOUZlreEyoXYCYTCdPYHKRt1gZsMlbCg3abJpNsX5ECHj4uOrR5TTPSytbW0eP24HDbedsI8XjnQxVBYvx/poM3r5yTbPgYq42gonw7MjNMpyoXYJupt2nMY/ngxHN0Iz/0Ydv3L+jkmkfa+8S1v2m2qSSZavGUS3kbIr+ZQt7oo1Jen2PLmcIGzIO6EBVBJC/6hyLiuhUkPZcvOgp6ziVeP9ACwuq54zHOXnDAfj9POe9fW8LZV8/AFw7xmxC1qUktP2xFqRAciXS7TqYizXIjNJoiMp/+f+ray5n/4EVV8+P5PT2nFmy0MhSN0DwyN6ddcnu+KFu/VaJKBFm+ZhFGg92DnAAD1qXabgkpaSLBQ72AwTEd/cIxrYTJstuxspTOb2Hq4G5uAE8ZpV1bkyeGx/3wTX3vbsZy2WCWqvNSgXafpQDSq/qKexaeleSYTUFSjar9NJd4mao91+EVVfmTh6fCeW8Dvhc1/SspUrabHKKlTmjfKbVrgYnAozEAwlI5paeYAWrxlEt4mFe/W4QNIfcICqKSFBGLecnPsDAyF6fIFKEugrIkQ2VnQczax9UgPK6oL8TjH75JXU+LBnWOnNM/JiuoCXtgf//uusY68jm0MSTu5dbPUbWrPgcKaKcuF2Mf7Tve1KtFXZwjTsiWq2f1rf4u7GHg6Mfsvj/4OlRliTlvfNMlCi7dMQUqVbVq4gIOdA1QXuqN1hVJKXmLizZVjp6V3kIgkMctblmamzRYiUvLq4R5OGsdlOh6nLS5jy6GeSUs9ZGMB1tlAQd9+Gu0LxmZ5ziYK50Nf86Sb2GzqOz3ic3LkZbWsXTe87oQroPsAhd49SZiotZhJVZ5R12KzdEi7jnvTJAkt3jIFfy8M+YxMUx/15WmwukHC/U1zc+wc7VatvMoSiHmzT+Ri0VhCs0/SFwixurY4ru1PqCli0Ci2PB47Gns5+ZuP85QuKWI55f5DdLrr0j2NySmohr6WSTexGf1YR+j/Iy+D3QXzThxet/Id4HBT1brB+nlajCnezILkJhXGtW5WJC14m2HTHyCsu6ZkE1q8ZQq9R9WyqIaDnb70xLvBsNs07v6mNgYM10Ii2aYTZqZpLGF/j3pPVteVxLW9GRc3XtJCZ3+Aj9+2mS5fkK1GEoTGIsIhqiMtDBTUp3smk1MwD/pbJ93ELBM0wnp7ZKNKUnDE3Ni5C+GYt1LZ9uyUtePSjek2dY8Sb+a1rrM/zW7T9t1w8wXwwH+qP31NzRq0eMsUjBpvvtx5dPQHU1/jzSSvXNV0Cnjj2jz2jrQiAcubEBNkpmksoW1AYrcJFsWZsbyoPB+P086OxpHibSgc4bo7ttLeHyDf5eBo90Aypjtn6WvZRw5hwqVL0z2VySmoVteEwPiWWQDD8DZ8Uzbkh+ZXoXacrhEr3kZOqE89P4sZHFIJCaNDWMz43rRa3gL98Me3QjgIq6+GrbdRd/ie9M1HYylavGUKvUcAOBIuBUh9jTeTaJeFxFpkQWJu02xtYj1b6A1IKvJdcRdNttsEx80vZPso8fatB3fxYkMn33n3KlbOK4i6yDXW0H1Y9Zh1Vi5P80ymoGCeWk5ifbNH3abG97rlNSUsYuPdTBado5YNT1s5S8sZDKo7zNExb06HjaLcnPSKt0MvqBCXd/0aLvk5rHg7dYfvUn1qNRmPFm+ZQu9RsOWwf1C1l0qr5Q1gIL6yEaZ4s9sExbk5cR9GuU0Tnp0mTroDksrC+MU0qL60O5u8UbfXg681c+sLB/nImYt4z8k11JR4aNTizVIGW3YDUFhzbJpnMgUFVWo5SdLCmJi3jr1qWTXOa8uvoD9vITRssG6OSWCimDdQrtO0uk0bNqh4wvozldlz3SdwhP2w+6H0zUljGVq8ZQq9R1WygvHjuDBtljejOX2c/U1N8Vaa54y2X4oHXectufQGJJUF7oT2WbVgOGkhEpH8+N+7WVFdwFfeugKAmpJcWrx+QroTg3V07KVL5lM9b366ZzI5puVtkqQF2+iYt94jgFBlRsahu+QEldAw5LdyppZiirfRMW+gCvWmNdu0YYMqwWJmKS88E7+rDF77e8JDSSnpHdAJD7MJLd4yhd6jUFTLka4ByvOd5LnGr82VdMyLdG9jXJubd6RlefEnK4AR86bFW9Lo8UcStrytWjCctPD4rlb2t/v45PolOIzWWjUluYQjkube2ftjm2m4ehs4xLyEvz8pp6BaLSexvNmNe7doOETPYXU9cYz/2nqKT4SQf7icyCzEbyQsjFe2qSLflT63aX8btL2uih+b2Gy0Vb4J9j+RUJccgHu2NHLSNx7jj88f4GCHjy/fu53tuuNKWtHiLVPobYSiGg53DVCbjuK8JgXVkFsCrdvj2tydoz5iibTGAhUfo92mySEYitA3BJUFib0niytU0sLNzzbwo8f2UFuay9tWzYs+X1OiPpc67s06igcP05pTixDxW63TgqsQcjyJWd56DkPxxCVQeoqPA2GHA7M37s3MpJ91btMDz6hlrHgDWqvOgUgIdt6X0HCP7GhGSrjxXzs5/8dP89eNh7l78xGLJquZDlq8ZQKRsMo2LVrA4a6B9HRWMBECqldBS3zizbwjTaRAL0zSSkczY0xrQFVhYm5Tu03wnUtX0Ts4xO7WPq49e3HU6gbK8gbojFOr8HspDnfizVuU7plMjRBGrbepY96iXRZ6Dk0q3sIODyxYAwefs3SqVjI4FMbpsI2b+FOe76J3cIhgKA1hBA1Pgbt4ZP08wJdXr855AokgwVCEF/Z3cuW6Oq47dymXralhaWU++9t91s5ZkxBp8r1pEqKvBWSYcMECmnr8vPukNIo3gOoTYOPvIRwC++QfIbfDcJsmaHlTpUK0eEsGrV7l1kzU8gbwzpMW8NZV89h2pIc1o2rEzSvKRQhtebOMzn0ADBUvTvNE4qRg3uSWN0O8SYm6dniboLh28jFr16lrTSgwshbcLME/FB7X6gbD3oZOX4B5RSnujtG4RZ0726i5CQG1pylrppTD9VsmYdOhLgaCYc49ppILj1WJKf/1t1d5Ufc6Tiva8pYJGAV6O+yVhCMyvW5TUOItHIDOvVNu6jLcpokU6AXdHiuZtPVNz/JmkmO3sba+dEwCitNho7rQrcWbRfjbDwDgqMgU8Ta55c000oYjUm0XCU1qeQNUwH04AE2vWjdPCxkMTize0laoNxKGzv1QMUF5mbp1qqRL98G4hnt6TzsOm+D0JWXRdUsq82nu9dMfCFkwYc100OItEzBqvB2NqBpvaXWbgnKbQlyuU/PClmjMm3abJo+2GVjepqKmJFe7TS2ir1WJt4LK+vROJF7yq1Wj+Qm+tyK2zlvPYbVyKvFm1oA78pJVs7SUgaHwhD2mC4ykMl+qBU7PYSV4yycQb7WnqWWciSDP7OlgbX0J+TFJcksqVKmqA9p1mja0eMsEDMvbvkAxAHXpKhNiUr5M1Q9qeW3KTd0504x5s+mEhWTR1hdAkLgrOx5qSjza8mYRgx2H6Zduqiqr0z2V+CioVv2XA33jPh0t0hthWLwVTSHe8iuhdDEcnp0Zp5NZ3jyG2DGTGlKG4W6nbNn4z1euBFcRHJ5aEDf2DLKr2cublleMWL+kQtUbnajXsSb5aPGWCXgbwV1Eg9eG02GjKsH6XJZjz1EXgDgsbyfVFXPF2lrW1pcmdAghYgKbNZbS6vVT5BJxd1dIBF3rzToiPUdokmUsNn4oZz1T1HqzGb82ESmj3gSKxq/xNoLa05SVaBZeD/yTWN7yjPW+YIotb2bx4/IJxJvNDrWnxGV5u3ezMhy844SRdQbryjzYbUKLtzSixVsmYNR4O9w1QG1JbkLFbpNG9Spofg3CRuHGCRpIF7pz+N5lJ1Dojr+7Apgxb7PvYp0NtPUFKHIl5zO0sCyPcERysFO7U2aKo7+Jdls5JbO9xpvJFLXeRmSb9hxSbtacOG5E69apNk+d+62aqWUMTpKwELW8BVJseevYo8o5ecom3qb2NGjbBYPdE24SiUju2nyU0xeXjYmzdjns1JV6tHhLI1q8ZQI9h6M13tIe72ay6BwY7IJfroM7roBvVcNjX7Ps7ljXeUsebd4AxUkSb6vrigHYfGjiHwVNfOQHWvC550294WxhCsubaemNRIyYt6kyTU2iMVqzL+5tIBget7sCpNHy1rlPuUwnyyStPQWQkyaCbDzYxeGuAS4/ZXzr6JKKPPa36Zu0dKHF22xHSug+iCyp53DnLBJvqy6D998JTg+07oS60+GFn8OzP7JkeJ2wkDza+vxJE2+Ly/Mo9uRo8TZThvwUR3qIFCxI90ziZ4r+piN6m05RoHcE5ctVzbI4YrRSjX8oPKYpvYnHmaaYt449EycrmFQdr5ZtO0esPtDh45Edzfx6w36+/dAuClwOLj5u/BuIJRX5HOj0DRdd1qQUXedttjPQCcF+BvNr6QuE0l8mxEQIOOYt6g9UFPJ9H4cnvwHLL4bq42c4vCoVol2n1jIUjtDpC1JclZgbO16EEJxcV8ImLd5mRH/HIfIBR2mc1qnZgKsAnAUTx7yZbtNwWHWMOfZd8Y1rs6ms01nYJmuyhAWnw0aOXaQ229TvVWVAypdOvl1eOeRVqhtvg31t/Vzw4+HiveX5Lv77ouUTxvQtqcgnGIpwoKOfpZUF6vBDYR54rZm3rqqOildNctCWt9mOUYunxabufmaN5W00Nhtc/F3VzmbHPTMfLragp8YyOvoDSEnSLG8AJ9eX0NDuo8uXptZAWUDbERXfVVhVn96JJMoktd7MUF0x0AGRIShMwKpYt05ZlAa6LJikdQxOkrAAyvqWUsubWXtzokzTWCpXjrC8bW/sAeDmD65l+w0XselrF3DNmRN39zhrWTlOu41bnjsQXffLp/Zx/V3b+NaDu6Y1fU38aPE22zHE26GIStVeWJaXxslMQV6Z6qX3+r0zVl3mhV67Tq2lo08JqsJkijej88LWw9r6Nl16WtQPYvmCJWmeSYIUVE8Z8+bwGeKuMIF4vgRrk6WKwaGJY95Axb2l1PIWzTSdwm0KUHUctL9h1G6BN1r6cNptnHNMBQVxJJjNL87l/afW8vdNRznY4WN/ez+/eXo/xZ4c/vLyYV7WHRiSihZvs51udRHfE1A/iLWlKW6zkijHvVsJzuZXZzSMmVGrwymspdOnuisUOpMn3k6oKcZhE9p1OgP8HYcAmF+XieJt8pg3u6/V2DYB8bZgDdhyZlXcWzgiCYYiE7pNQWWcptTy1rFXeT9K6gHYcribgYkSJipXwtAA9BwEYE9LH0sq88mxxy8LPn3eUnLsgk/cvpn/+NMmcnPs/PPTZ1FTkstX7tuuWxwmES3eZjvdByG/mgO9kvJ81+yPI1jxNrA5YMe9MxpGaMtbUjBdmQVJFG+5TjvHLShiixZv00b2NtJFEe7cWWxpH4+CahVzNc731rwhs/cblrlExFtOrmqyPossb4NDSpRNlLAAhuUtldmmHXuUcHM4eXZvO5f+6gVuf+nQ+NtWHqeWRtzbntZ+jqlKrKZgZYGb/7xgOb5giEK3gx++90Tqyjx8/oLl7G/3sb2xdwYvRjMZWrzNdroPQUm9USZkllvdADylynW6+6EZDWOLbaWjsYxUiDeAFVUFugbUDHAPNNHjrEr3NBKnYB6E/ODvGfOU2WEhZ6AFhA3yE3x9daephuuhgAUTnTmDhkXNPVXMWyrrvHXug/Ll+IfCfO0fOwDY3ugdf9uKY9SybSde/xCNPYMsry5I+JAfP2cJz37xPO6/7iwuOk7V+rtgZSV2m+DR18d3oWtmjhZvs53ug1BSz6HOgdkd7xZL3enqIuKf/l2XXWi3aTLo9AVx2ASeJBtwF1Xk0dEfxOsfSu6BshApJcXBVgK5GVTjzSRaqHfsj7YZx+rwtahMR3uCH8KaU1TPztbXZzhJa/AblrfJ3KZ5rhRa3syG9OVL+dVT+zjUOUBNSS67micQb658ZaVr28neVtXS7JiqxMXbeBR7nKxbVMpjO1stGU8zFi3eZjOhIPQeJVy0kObewdlTJmQq5p2kls1T9z6dCO02TQ5d/UFK85zRJuHJot640TjYoYt4Jkprr58qOqEog2q8mUQL9Y6NezPdpjkDLYklK5gsWKOWTVumOztLMWPZJo15S2W2aUxD+sd3tXHGkjIuXb2Ahvb+qNAcQ+Vx0LqT3S3KSn7MNCxvE/Hm46rZ19avLfBJQou32UzvEUDS5ZpPRM7iMiGjmXeiWs4gaSFaKkS3yLSUTp8Sb8lmcYUSbwe0eEuYQ80t5As/7rIMqvFmMqnlTX2nnQOtUDB/zPNTUlSrWj41bZ3JDC0jrpg3VwqzTWMa0rf1Bagr9bByXiERCXsMy9oYKpZD1372NneR57SzoNi60JwLj1Vuce06TQ5avM1mjEzTRtSXIGPEW36FquHUvG3aQ+hSIcmh0xegLD/54q2u1IMQWrxNh9ZGFWBeVLUwzTOZBvkT9zc1kxidA23DIi8RhID5qydt6ZRKojFvs8XyZpQJCZUsodMXoLLAxcp5hQATu05Ll0AkRGdTA8urCyy1yM8vzmVNXTF/3XiYYEjfhVuNFm+zmS4l3vaHVIPhjBFvoFynMxFvNp2wkAy6fEFK81xJP447x878olwt3qZBb6sSb8WVGWh5c3rAVTSu5U0IgYsgOcGe6blNQYm3tl0QHJjZPC0gGvMWR7ZpSjrFGA3pO2UBUkJFoZu6Ug95Tju7miewvJWpUjSh9n2WxbvF8pnzl3Gka5C/vXLY8rHnOlq8zWY690NOHrt9ebgcNioLkv+jaxnzTlR3goEJLhpTIOZgwsJfXj7EZ/6aXJdQV3+QshS4TUG5TnXMW+IMdh0FwFY4DdfibGCCWm92IagSRvmY6bhNAeavARmGlu0zmKA1xBXz5nIgJfiHUmB5MhrStxmFuCsLXNhsgmOqC9g5oeVtMQDlwaOWxruZrF9ewan1pfzsyX0T15vTTAst3mYznXuhfCmHu/zUlnqi1qiMYP5JgISWHdPafS66TTce6OK5ve1JGz8QCtMXCKUk5g1U0kJDh0/3p00Q6TWEz3Rci7OBCbos2G2Caoz2VjOxvMGsiHuLt84bkJqM0449UL6MVq8fIHqzv3JeIbuaveN/D/OrCDs81IvWpFjehBB84eJjaO8L8I0HdsZ1LQhHJM/v62AorF2tk6HF22ymYw+ULaOho5/6sgxymcKMkxbsc7DOmy8Qiv4gJINunyrbkSrxtqg8jz5/iE7d4zRugqEIrsE2AvY8VcohEymYN4HblJlb3grnqbi6WSTepop5A5Jf6y3akF4lKwBUFboBJd76/CGae/1j9xOCHncN9aJlWjXe4uGU+lI+tX4Jf914hFtfODjl9jc/28BVN7/MtX/epK11k6DF22xlaBB6jhAqXcr+dl9STNpJpaBaZYa1Ta9BsW0Ouk37AyH8Q5GkWarM1lipcpsuKtflQhLlcJePStFNIDcDC/SamJa3UZ9juy3WbToDq+K8E6Fl+mWIrMIfjCPmzZUiy1tMQ/q2PiXSyvOV5a2mRGWQNvcOjrtro20+S+yt0e2TwfUXHcNFx1bxjQd2TtrzuKXXz01P7GVJRR5P72nnQ3/YSCA0vvDd397PNX/cyOZDXcma9qxGi7fZSud+QNKSU0c4IjmmujDdM0qcknromaA1yxRE67zNIfXmM+7OA0nKzDK7K6TS8gbQoMVb3Oxv91EtuhDTdSvOBgoXQGRIWYJisAlBtegiZM8Fd9H0x69Yrq6PkRR2LhiHeOu8qW2HxdvGA13WX9diGtK39QUozXPidKifd9MC1+odvzPF7qFKFtAG4eQJTJtN8MPLT2ReUS7//fdt0Uzd0XzroV2EIpI/XnMqP33fal452M03HxhrAHhubwfv+uXzbNjdzg8f3ZO0ec9mtHibrXSoD+TusLoDX5lpljdQ4q17euItWudt7mi3aD2oiS5sM8UUb6koFQLqjt9uExzuTH9mYKZwoMNHpejBVZKBBXpNSheppZEtb6LEWzd+d+Xw3dl0KF+uitH2pDeDcXAojNNhwz5JLHLU8mbcmL3e1Mvlv32Rp62ObY1pSN/mDYxIbjPFW8s4btNIRLLNV4qDMPQm93wWunP4wWUn0NDh47sPjxVkT+xq5V/bmvjU+iXUlXm45MT5XPumxdz20iF+/sRe+o3r45GuAT5x+2bmF+VyzRn1vNjQOXEplCxGi7fZSsdeQLClrwyn3UZ9eYa0xoqleKEqNDyNO2Sb8cmcSzFv5sXJP4GbYKZ09hviLQWlQgAcdhvVhW6aesZ312jGcqDNS5XowZnJ4q3EEG/do8Ub1IlWfHkzLIFStkwtzaK0acI/FJ7U6gZjLW9thvXrSJfFNzQxDenb+/xUxIi3Ek8OTruN1r6x4u1o9yC7hyrVg84Ga+c0DmcsLeejZy3iTy8e4l/bmqLreweG+Mp921lRXcCn1i+Nrv/im4/hgpVV/Ojfezj920/w08f3cP1d25BScvOH1vL5C5bhzrFx6/MHkz732UaSOxxqpk3HHiiuZUf7EEsq88mxZ6DOLlkIkRB4G6G4LqFd52Jj+lRY3uw2QVFuTlLGH4/5xW4atXiLm7bWJnIIDbeZykSK6wAxxvJmF1AvWmj3nMaMIvrKDfHWsQeWXTiTkWbEYHBq8ZZniDfT8tY7qJKGxk0emAlGQ3qAtr4ASyuHPTVCCCoLXbT2+mFUA4XdrX0clMa70ZV88QbwPxevYNuRHv7nntc40OFDAPdva6KjP8jNHzwl6u4FdQN484fWsu1ID795ej8/fVy5h7//nhOi7SLfs6aGuzYf5YsXH0NZEuP2ZhuzThEIIeYJIf4khGgXQviFEDuFEOfEPC+EEDcIIZqEEINCiA1CiOPSOeek0LkXypaxu6WPFZnoMgV1JwjTcp2KOSbeIhGJzxBtyco47fQFKfHkpLTkzPziXJomCJTWjERKSV+7qvGWsWVCABxOKKqB7oMjV/u7KBSD9OXNsHOEpwxyS4bjvNLE4FB40mQFAI/hNjUtb6Z4G8+FOW1iGtJHIpL2vgCVhSNFTHWhe9yYtz2tfbRTjHTmQdd+6+Y0CU6HjV9etYb5xbn8+N97+NG/91DgdvDz969mVc34sZAn1hbz6w+czD8+fSbfe88q3ru2Jvrch8+sJxiK8NeNc6sQ8KyyvAkhioHngeeAtwHtwGKgLWazLwL/DVwD7Ab+F/i3EOIYKeX0KsLONiIR6NhL4IR1tLzuz7xMU5Ni4yLdcwg4O6Fdh+u8WTul2cpAjGCbsIn0DOnsD6QsWcFkfnEuD21vJhyRk8YGaVRAecFQOziZfimN2UJJ/Ri3qdN7EACvJzEr/BiEUK7TNLtNB4LhScuEwHANOPPGbNjyZuENjdmQvmwZXQNBQhE5pqB7VaF73LiwPa19LCj2IArrpx2fPB2qCt08/l/n4B8KMxgMUxLndemk2mJOqi0esW5pZQFnLyvntpcO8fFzlmSml2oazLZX+UWgWUr5QSnlRinlASnlE1LKXaCsbsDnge9KKe+RUu4APgQUAFembdZW09cEQwM0OdTdRcaKt6IaELYxd+DxMNfqvMU2r05WNfauFDWlj2V+cS5DYUlH//iZbpph9rT2WVNKYzZQumiM2zSnRz325lrQ9qt8eTSpK134h8KTFugFcDvsCAEDxve7ZyAJljdTxJYvj8bUVRa4R2xSWeiKFu+NZW9rP0sr86G4VsUnpxh3jj1u4TYZHzlzEa3eAA9tH9vZI1uZVZY34F3AI0KIvwHnAk3AzcAvpSp+tQioBh4zd5BSDgohngHOAH47ekAhxLXAtQBVVVVs2LAhqS+gv79/xsco7dzMCcDjhhW4+8AONjTPNp0dH+tc5Xjf2Mgu24aE9tvZqi52Gze+QqltMOnvW7pp7h8WbBu3vMrQUeu/mkfbB6gttLFhwwZLPqfx0Nmm3sd/Pfk8S4sn/6HLZKw4n48eHKIKJd6e3rIbaUuNGysZ1HVLFg908OzjDxF2qNikeXufIV/a2HzER34c52qyc1rrtbGkv5VnH3+QsCM9yVwtHYO47Ez5vrtssHv/QTZsaGb3ASWuGrsHeOqppyxpBF9z5GGWAs/vbmNzryrL07R/Jxu6dke38XUE8QXDtPcMn9OIlOxrHaDW6eBo2E51xwGey9DrrJSSao/gV4++RlFPat3pqbqWjibhXwghhBt4O7AE+K2UskcIsQTollLOtFreYuBTwE+A7wInAT83nvsFSrgBtI7arxUYNz1LSvk74HcAa9eulevXr5/hFCdnw4YNzPgYz22F7dBZsQ5PYw/vfvO5lnzJ08LBY8gN+6lK8JwEX2+BrZtZc/JaOvZunfk5neW8drQHnnsegKXHHMv6E613mw0+/Rgr6uezfv3x1nxO46C6xctPtzxL9eKVrD8hw12Bk2DF+XzkntdY6OwFTwXnnHeBNRNLF693w4HbOPv4WqheBUCg+Y8clRUsXr6S9afXTznEpOf0DR80/JmzV1RDzcnWzTsBvvziE5ywsIz160+adLuC5x+ntKqS9etP4PZDm6CplaEInHTqmZZYnfjXPyC3hDMvvITGzUdh82u8+U2nUxfTlaenqJG/736VIYcnek6PdA0QfPQp1p+8kpqh06DxQdavOwlyi2c+pzTwLv8b3PJcA6edefaU7mwrSdW1dDQJmXOEEEuBXcBvgG8BpcZTnwS+b9F8tkgpvyyl3Cql/CPwM+DTFoydObS+DkW17O61sbAsL3OFG6iM02m4TdNa5y0NB+2PcZsmI2FhKByhd3AoLW5TQJcLiYM9rX3UO3szO9PUxCwXEuM6tfc0cFBWWxPHGi0Xkp6kBf9QmBavn4WlU1v98pz2aLap14h5AwszTo2G9AihMkphTMKCWeutJzB88ve19QOwzHSbQlpcp1axpq6YobBkR2NvuqeSEhL1xf0U+DdQBcRejf+JcnPOlGZg56h1uwAzwtVsmDc607wq5rnMp/V1qDyWQ10DmdfTdDTF9arS+lBiP95pqfM2NAhPfx++Wwc/WgF3vM/odJFkpCTY204h/diIEEiCeOseSG2BXpNCdw4FLgdNPRaXRsgypJTsbe1ngeiEIgtiwtJNNNPcEG9SYu9u4KCsImyFeitdhCpHkpryFqM52j2AlFBfPvX12eN0RLNNewaD0WSCFq9FNzRdDVC2BIAj3QNUFLjGWJ6qDDHX7R8Oz9jbpvL7VMyb8ROb5sLHM2HNwhIANh+auP1WNpGoeDsD+KGUcvSvy2HACp/I88Axo9YtB8w0mAMokRYt7mO4cc8GXrDg+OknFISOPUQqj+NI1wALyzKwOG8s5kU8wYtCykuFDPnhlovgqW9B/dmw+Fw4/AL85mzYfndyjtmxD/71efjJ8az/52m85r6Wl1zXUX/wb5a3qkl1a6xY5hfn6lpvU9DqDdAXCFESalOJPplObrEq52Fa3nztiGC/YXmz4Dttz4H8SvA2Tb1tEjjYoYrs1pVOLd7yXPYRdd7MBLSWXguSeMIh1Ue2UEUNHe4aGHdOE1neyvOdFHucUGSKt8y1vJXnu6gv87Blkt6p2cR0oqLHq/BZB1hhq/wJ8IIQ4qvA34DVwGeBrwBIKaUQ4qfAV4QQbwB7gK8B/cAdFhw//XTsgUiIroJlDIVlFljeYszxFaN1+cSkvEjvEzeqZtfv/RMc9y61rvco3PMxuOc/QEbghMutOdZgDzz2NXj1L2B3wrIL2TzvfTy4o5WL7Rs5e/e34R/74D2/t+Z4QFeKuyvEMr9Yd1mYij2tfRQwgDPUnx3iDaB0CbQZjhTDQnZQVjPfqu90QbUSLmngkNEhIZ6ba4/TQY9h+e4dHGJpZT7P7+ugxYpyIb42kGEoVLaTI12DnLqodMxmeS4HBS4H3f6R4m1JRb6xQTk4cjPabQqwpq6EZ/Z2IKXM7HCjOEjU8vYY8F8xj6UQohC4EXhwppORUr6Cyji9HNiBiqv7f8CvYjb7Pkrk/RLYBMwDLsqaGm+trwNwyKFiRuoyXbzlGx7uvtE5JpOT0jpv+5+Cl34Fp147LNxA/YhefS/UnwX3fQJ23j/zY+19HH51Orx6B5z2Kfj8drjidjbNv5I/hN/C5cH/5fkFH4Htf4fX/zHz4xl0privaSzzi3O1eJuC/e39zBcd6kG2iLflF8ORl5XVvXEzAA1ynnXf6YL56RNvnT4KXA5KPFN3K8lz2fEFwwRCYfxDEcrzXVQUuKyJeTMtj4ULCIYiNPcOUluSO+6mlYWuqOVNSsm+tn6WVRniTQh1o92TulpvyWDNwhI6+gMc6cr+602i4u2/gbOEELsBN8o6dhCVBfolKyYkpXxQSnmilNItpVwupfyZUSbEfF5KKW+QUs4ztjnHqPeWHbTuALsz2m+uPtPdpqZ460/sIhut85YK9fbUt1VB4Qu/Pva5nFx4/51Qsxbu/ijseXR6x/B74Z+fgb+8B9yF8B//hjd/S7l+GK7zVuDK4YnKa2D+anjgP8HXMc0XNZJ0u027B4aicT+asTS0+1ji6lEPskW8nfBetdx2J7z8WyIL1nJYVloT8waG5S09btNDnQMsLPfEZd3xOB34AqFogd7C3Byqi3JpGafuWsJ4G9WyaAFNPYNEJNG2UaOpKnTTMajOfXtfAK8/xFLT8gYq1jKD3aagLG/AnHCdJiTepJSNqPId30PVVNuEKqy7RkrZbvns5iKtr0PFMRzsDuJ0qMbeGY3TA65C6G+betsYhmPekjGpGI5ugqMblRUsZ/w7Vlz5cNVdUHUc/O1qaNiQ2DEaNsCvz4Ctt8OZn4Nrn4YFI8sb9AfC5DnteFx2BkIC3vkrGOyCzbdO51WNodMXRAgo8UxTvEUiKi5wGizQGadTcqDDx6p8w3mQLeKtpB7qTodnfwQ9h5CnfxYQ1t2QFc6HgU4Ipb4A9OGugbgyTUG1pmrrC9DRp26ginJzmFfottzydrhr8ji8M5eWc9Ab4Y6XD/OXl1UM8vKqmALwxXUZ7zY9prqAApeDlw90pnsqSSdu8SaEyBFCtACLpZR/kFJeJ6X8lJTyZimlvipbgZTQsh2qjudgh4+FpZ6U9qFMGvlVCbs3zJctkx3z9tKvlbhcfdXk27mL4Or7oGwp/PX9cCiO/JhAPzz0BfjzO8Hhgo88pqx7OWMFuS8QIs/lwJ1jV6VCqo6FhWepuDgLzkFnf4Di3JzptahqeFqJz+/UwB1XQNPWhHY3LQFmkLdmLA3t/Sx19YDNMWytzgZOuBxCfihdgljxNsDCGzKzC0WKXaehcIQjXQNxh7TUl+cRjkheb1Jh4UW5OVQXuWm24mam9yg43JBbMizeJpjXJ85ZwvHldr76j+3c9MRe3nbCPNYtLhveoLhWieGgb+bzShN2m2Dd4jKe36fFWxQp5RAwBMyNfkXpoK9ZBaDOX63M8pke72ZSUK3KhSSAKVqTannzNsHOf8CaD4IrjhZknlL44D+UZeTP74KXfze+sAoPwda/wM9Pho2/g3WfhI8/C7WnTDh0fzBEvstBbo6dQaMPIquvUoHeh1+czqsbwbRbY238Pfz5EhjywdoPq9ilO68Cf/z5SUsqlIWioaM/8ePPAQaDYZp6/dTaupQ1yZZFnSiOfRfkV8P6L2FzqPy4sGUJC0aBgxSLt+ZeP6GIZGEcmaYAi4xyIq8dHRZvJR4nvmCYUHiGrfC8TeozIwRHugdw2m1UFYzvrbHbBJ880cUp9aVcd+5Sfv6+1SNv5qK9qDPb+nbW0jIOdw1wuDO7bxYTzTb9OfBlIcSHpZQ6gMVqDIuGnHcih7q6OWtZeZonZBH5ldC4JaFdhhMWkqjett8FkRCs/Uj8++RXwocfgX98Ah7+Amy9TYm/siXKrXh0I2z7m4rFWXAyXP5nqFs35bCm5c1uE/hDxgX92Hcqy93Wv8DCM6b5IhWdvmDimaav36eOf8zb4LJblFv5hPfBLRfAv/8X3nFTXMMUe5yU5jlpaM/cO/pkcrBTnZeKSFt21HiLxVMK1w+3abLbhHXW9KjlLbVxb4c64880jd1u29EeQIm3XKeymwwOhSkY1Uj9F0/upXtgiP/39mOnHtzbFC0TcqRrgJqS3Em9NXk5gr9//PTxnzQ/ez2HoXLF1MeepZi/m8/v76CurG6KrTOXRBMWzgbeCTQKIZ4QQvwz9i8J85tbNL0KwkZb3nL8Q5HMLxNikl89g5i3JIu3BWujBS7jJq8Mrvw7XPILiIThoevhtnfDne+H53+mSqK8/0746ONxCTcwxZud3Bw7ftPy5sxT2a+v3zfteDOThC1vB56Fe6+F2nXDwg1UK6LTr1OxeEdeiXu4xeV5WrxNgHleCgKt2RPvNgE2gYUJC0YnihRb3kyxHa9npCzPSYHLwa5mLwDFuTnkOpXdJGplj+Hfu9r44/MH4osRjRFvh7sGJkxWiItoWafMLdQLsKQin6pCF8/tsybZa7aSqHjrAO4BHkIV5u0c9aeZCU1boWIFDT3q4lZfnuGZpiYFVcrtFoi/mkvS67y1vaHiC1e9d3r7CwFrroZPPg/XbYYPPwwfeRS+fES5Vo95y3CbiDjoD4TJdzlw59hGtsda+U517g4+N715GnT5gpTGWyakZQfceSWULob3/3VsIsf6L4EzH7b8Ke7jL67I027TCTjQoTpr5Pia54B4E9aFQnhKVZ3EvmaLBoyPtj6VIFEVZzKZEIL68jyGwuqFF+bmkGt0QBivFV5nf4CIhDtfmcJ9GYkoq6NR4+1w5/gFeuMmvxpsORnvNhVCcObScl7Y15GaagVpItFs0w9P9pesSc4JpITmV2H+6uiP3OLYNO5MZhq13oZLhSRjQsCOu0HY4Lh3z2wcIaB8qXJr1p2mrGXTwHSb5jrtIy/oi85WxTP3PjbtKYYjku6BIGXxWN66D8Ht71ExgB+4R/1AjsaZBysvUXXv4mx7trgin47+YLRcgmaYhg4fxxcOIGQ4akXJVpR4s+gHVQjlOvWmVrz5AiE8TntCyT/mjXiBERrhcSrxNjCO5a3TKKh958bDDE0WE+drU2EfhfPpHRjC6w/NTLzZbOrmIYNbZJmctbSc7oEhdrV40z2VpJGo5U2TLLyN4GuHeSfR0O7DnWNjXqaXCTGZRq03kcyYNymVy3TxemUVnAXEZpv6Y8VbTi4sehPsfXTaWac9A0GkZGrxNtClhFtoUAm3yaxAJ14BAS/sfiiuOSw2frwa2rX1bTQN7T5WFxou5WyLeRuF3Sasc5uCUag3teJtIKi+q4lghsAU5qqivhNZ3gaCIQaHwpy8sIS2vgCP75zkhtes8Va4gCPdKg6vtnSCckfxkgXlQkCVRQF4PotdpwmJNyHEdiHEaxP9JWuSc4KmV9Vy/moOdPioL8vLjjIhMBxYnEDGqS2Zdd6at0H3wZlb3SykPxAy3KajxBvA8ovUfDv2TmvsaIHe/CkSFp78pmok/v6/QeXKybetP1tZibb9La45mFZkHfc2EiklDe39rPQY2btF2W15E8LiG7KC6pSLNzPEIRHMYutFpngzLG+jY95Mq9tlJ9dQU5LL759tmDjBw6zxVjRc421GMW9gdFnIfPFWVehmaWU+z2VxyZBELW93o2LezL9/omLfao3/NdOlaSsIO1QfT0N7TM+5bGAablMzXCwpdd52/VOd6xVvt37saRAKRwiEIuQ5R5UKMVn2ZrXcO73uDtHWWJNZ3jr3qxi2NR+ChRNko8Vis8Oqy2Df43GVDakr9WC3CR33NoqO/iBef4jl9mZAqDjDLMZus7BIL6ikhRQnLJjJRYlguk2LjXZanonEm/FdrSp08bGzF7PlcA+vHJygW0BMgd4jVom3ojrlIZlhgtRs4Kyl5Ww80EkgNNY1nQ0kGvN246i/r0kp3w58GyhOygznCkdfgarjCAoXR7oHWVyRJckKALklKrA4Abdp0ixvUqqeoYveNH48VxrwBdTFxcw2HRwKjxStxbVQeey0W3PF1RrrqW+p9+ic/4l/4KUXqqbYB5+fclOnw0ZdqUdb3kZhZiDWhY+ojgQTdfnIEuxWJiwAFM6DYL9qP5ci+gMhPM7ELG+LykdZ3gy36cDQaMubSoYozXNx+dpaSvOc/Obp/eMP6m1U31mPqmtW4smh0D11r9VJKa4bHjvDOXNpOf6hCFsO9aR7KknBqpi3e4EpStRrJiQSVsVPa0/lcJePcERGv+xZgRBGl4VE3KZqaXnMW9tO6NqvaqjNEvqNnp/5RsJCRBLNTIuy7EJVrHcaP1LmD8KElrf+NthxD5x6bWIxgLWnqmSKA0/Htfni8jz2tmnLWyymeCsZOAAVmVtbK16EENYV6YW0lAvxGSEOiVDiyaE0z0lFgQpdMN2m/gncpmV5TnKddj50ej1PvtEWtayNnEgH5FWAEDMvE2JilgvJ8Ab1AOsWl2K3iayNe7NKvL0JyO5yxsmkbZe6e6w5JWqZyJpMU5P8qoRi3pJW523n/SrLdJa4TGG4KX2ey4HLMVy8cwTL3qwyyxqeSnh80xVTMpF4a9yslssvTmxgh0tl2DbEJ95OX1LGvrZ+th+NvztDtrOr2UtNYQ72rn2qPmCWY7dZHAphWs8HU9eI3EwuSgQhBH/5j3V85rxlQIzlLTiy1n2Hz7jRMsr6nL+yEhgu8DuCgU7wqPZWR6wSb9FCvZkf91bozuHEmiIe29mC1599We6JJiz8c9Tfv4QQm4CbUY3qNdPhqFHstOYUGjpM8ZZFljdIWLwlrc7bzvth4ZmQX2HtuDOgPzDS8gaMTVqoXaf6q+4Zv2RIfyDErc8fGDee6HDXAOX5LnLsE3zdGzcrQTvvhMQnv/gcaN8Vl1X18lNqyXc5uOW5hsSPk6XsbPbypop+iAzNCcubTVicbeouVkt/j3VjToFKWEi8hdnKeYVRy5vpdh0cGlkKpLM/iMdpjz6/vKqAHLvg9aZxLO6+DvCUEY5IGnsGZ1YmxKRwgYoHzoKMU4APnLaQfW39vPknz7DlcOoEfipI1PI2uihvG/A48BYp5dctntvc4egr6g6qdDEN7f2U57tmHrsw2yhIrDl9Uuq8tb0B7W/MKpcpjLS8RUsIjE5asDtgyfmq3ts4J+XRHS3c8K+d7G4dWwh586Fu1tQVTzyBxi1QsXJ6NeoWnaOWB56ZctNCdw6Xr63lgdeaae61oCl3huMfCrO/3cepeUb3kTlgeVPizcIBo+ItddbcgWCIvARj3kYTtbCPsrx19geiVjdQsaLLKgvGF28DHZBXTovXz1BYWiPe7A5V9DcLar0BXLqmhns/dSY2IfjCXdusvXFIMzMt0vtRKeWXpJTTryCqgSMboeZUEIKGdl+0JlZWkVehXBuR+DJ/klLnbdc/ATGrXKYQK97suA3x5h8vQ2r5m1VhzuZXxzzV4lXZYd5RRXDb+wIc6hzg5IUl4x9cSmjaAgvWTG/y805UFsEDG+La/MNn1hORkl9vmCAIew6xt7WfcESy0mGUuihfnt4JpQCb1W5Td5Fapki8RSKSgWA4YbfpaGw2EU1OimW8HsTHzi9kZ1Pv2PM20AWe8mgD9toSi9opFtdlhdvU5KTaYr7y1pXsb/fxwGup7YObTBJ1m9qEELaYx9VCiP8QQpxp/dTmCANd0LkXatYipWRPax9LKrMs3g0gtxSQMNgT1+ZmjTtLvaY771cxWoXzLBx05vQb2ab5k1neQGV32hyq1+ko2gzx1ucfeSdvugrW1k8g3roPKFE9XfFms0Pd6eoGJA5qSz1ctW4hf37xEC/sz85A4ngxkxUWhA6pEg2uLPzej8JudcJCVLz1WDfmJPhikotmSq7TPqbDQmd/kPJRbeyOm19IR38w2pYLgFBAFcn2lEWTGSyxvIGKe8sSt6nJW46vZkV1ATc9sTdrrG+Juk0fBD4DIITIBzYBPwA2CCE+aPHc5gZmvFvtqTT1+vH6Qxw7ryC9c0oGRmAtA/EVTbQ827RzP7TuUG2dZhmxblP3JD0PyStTiQuv/Q3CI0WaeWEfHZi7+VA3TruN4+YXjX/wxi1qOX+a4g1gwVro2BO39ePLb13BovI8rv/7NvqyMJA4XnY2e/E47eR550ayAljc2xTA4YQcT9w3hTPFLOvjmUbM22jGt7wFxljezO/u600x36+BLrXMK+NI9wB2m2BesUUdeYprVamQcPZ8N202wefOX0ZDu4+Hd6S2qHOySFS8rQWeNP6/FPAClcDHgOstnNfc4dDzqhnwgrXsMuIaVs4rTPOkkoCZFRa3eLO4ztu2v6qg/FkW7wbjJywEhiYIDFp9lUr82Pf4iNWtE1jeNh/qZlVNUVQUjqFpK9hdUHXc9F+AabVr2hrX5h6ng+9cuoqmXj+P7EhtgdXZxM5mL8dWeRAde+eOeLO6SC8o61uK3Kax39WZkuscWZBbSklnf3BEzBvASuNmfmds3NuAYbU2arzNL3ZPnJCUKMV1ICPDRYCzhIuOq6amJJe/vJQd8XyJvtv5QI/x/0XAfVLKIZSgW2LhvOYOB5+HBSeD0xN1o6zISvFmWN4Gu+La3NKYt3AIttwGSy+Yle2HfIEQdpvA5bDhzpmgVIjJsotU/OCrt49YbVreYi1Z/qEw24/2ThzvFgqqwr/zTgT7DBJkTPF2dFPcu5xaX0ppnpMXG7K3fc1kSCnZ1ezlTSVdEPJD1fHpnlJKsFvZmN4kheItaiWfYcICqC4LsW5T72CIUESOKaZd4M5hYZlnZNKCzxRv5RzuGrDOZQrD5UKyzHVqtwnef2odLzZ0si8L6k0mKt4OA2cKIfKANwP/NtaXouu8JU6gXwWf16uQwV0tXhaWeSy5q5t1TNvyZsGFfu+jqrvDydfMfKwk4AuEyHPaEUJMHvMGSmSdcAXsfli5glFCoM1rirdhy9uuZi+VkVYu890Jd30Y/vlZ2PSHYZfL8zepeMuz/nNmLyC3BMqWDrtg48BmE5y+uIwX93cmpwXaLKexZ5A+f4h1DqNfbd269E4oRQiB9TFH7qLUxbzFhDjMFPcot6lZ4618nB7EK6sL2d0Sk0luXkc9ZTT1DLKg2MLOHGaXhSxKWjC5fG0tDpvgrxsz3/qWqHj7MXAbcBRoBMz6AG8Ctls4r7nB0Y2q8OrCMwBlFl9ZnYVWN5hGzJtZKsSCC/3mWyG/erhH6CwjttF17mQxbyanX6fKevzjUxAJ0zs4RNCov+D1h5Slcd8TzHvoGp5zfY7lr/9UZZS+8QA88J/ww+WctPWr8Mz34bh3w4q3zvxFLDgZGjcllGFy+pIymnv9HOiYey2zTBfY0sDrkFcJJYvSPKPUYLdZHPMGqlxIqixvweHkopniGeU2jXZXyB9bTLu8wEn3QHB4hXEdDblLae8LUF1oUbwbqFpvkDXlQmKpKHDx5uOruXvz0YxPXEi0VMhvgdOBjwBnSSnNwJz9wP+zeG7Zz6EXVEHE2nX4AiEOdQ1kZ7wbqKBihztu8Wa3KuZt77/V35oPqhpGs5DYiu0us1TIZOKtcB685ftw5CV44kbaOrtwEeQM2w7eduh78KNj4PZLKercxk9Dl9L3iS3wuW3whf1w7dNw2iexhwdUPae3fN+aF7FgrYrFS6An4plLywF4Yf/cc53uau5DCCjp3KKsbmacQJZjyxa3qQUJCx7nSMtbl9ldIW+s5a3AnUOfPzRspR7oBAQd4TwiEiqtFG85blVUvTf7xBvAhSur6B0cGmnJzEAS/jWTUm5CZZkCIITIkVI+aOms5goHn4f5J4GrgDcOdSPlcHBq1iGEsr4NxFfl2ixIM6MLffdBuOc/VDD+TF2DScQXHBZvufGIN1Cu072PwfM3seSl37HDFSRHhPF73XDsW+G4d/HjvXXcsbmVz1UtVvsIoT5v809is/N81q9fb92LWHCyWh7dBEU1ce1SX+ZhXpGbF/d38oHTFlo3lwxgZ3MvJ5cEsPUcglM/lu7ppAybzeIOC5CxCQvunJGWNzNudXSpEIACt4NQROIfiqikJl8H5JbQ2q9iXC21vIGKe8tCtykQjQHefLibY+dnrrEk0TpvnxVCvCfm8S3AoBBitxBibqRLWUXQp9xMC414t+YszjQ1yS1N2G06Le3m98ITX4ffnqMGuOI2cFoY0Gsx/TGNrnPsArtNTO42BSXE3nMLfOQxDtZcwm/Db+d/nF/mmvI74L1/hGPfSWN/hOoid7RPbFKpPl5ZkVvij54QQnD6kjKe399BYLyixFnMruY+Li40mn/XnpbeyaQQm0hCy7vcYiXeLG3HMj6m5c1jlds05nu+9XAP5fmuaAutWAqMjjvRhKSY7goAVVaLt+Lsq/VmUlOSS3m+i62HMrtdVqIxb58F2gGEEG8CLgeuBF4FfmTpzLKdg89DOAhLzgOUeCtwO6gpsTDwdLbhSUS8qWXCF/rBbvjzJfDsj2HRm+DDD0Lp4gQnmlqU21RZ3MykhcFgHD9EQkDdOh5d9EV+GLqClurz6AwM/6g09/qZV5Siz5PDpToEtO5IaLdLV9fQMzDE3ZuPJmlis48+/xCHuwZYa9+tQgnmnZjuKaWMpGWbyggEk59BGBVvE5XeSYDcHHu0Mb2UkpcbOlm3qHTcm61Ct/pee82EpIEu8JRFi3NXFY0VfDOiuA56j6ZEEKcaIQRr6orZnOG9ThMVbwuAA8b/7wDuklL+HbgBmDu3j1aw/0l14a47HVA1n1bOK0yNlSRdeMqSW+ctFIA/vxNaX4f336ksbtWrpjHR1OILjGy3oyqvhybZYyRt3gAFLgdVha4R2aYtvX6qiyy+I5+M6uPVuU+AM5eWcVJtMb/esJ8hS5tezl7eMGJtFg9uV8WRHWPdZNmKqvNm8aApbJHVHwiT57RHO8DMhFynA/9QhEhEcrR7kKZeP+sWl467bYEh3qKWN6MpfYvXj90mxo2TmxFFtcq44GuzdtxZwskLSzjUOUBHf2DqjWcpiYo3sygvwIXAE8b/Q0AKfyWygP1PKpdpjptIRLK7pY9js9llCgmJt2nVedt5PzRvg0t/B8dcPI0JpodYtylAqcdJly84yR4jaevzU1noMoKa1cU9FI7Q1hdgXirFW9VxytUyGP8drRCCz5y3lKPdg9z/anYVBZ2IXc1eCvFR0L0TFp2d7umkFJvA2vZYkNLm9LHJRTMlN6aP8UtGvcN1i8rG3XbYbWpa3jqV27Q3QGWBC7sFYnIE0XIh2Zm0sMaIe9t6uCe9E5kBiYq3x4DfCyFuBpYCDxvrj2PYIqeZit6j0LE76jI91DXAQDCcvckKJp5SdYENT21VmlapkE1/gNIlsHL2dVGYCCnlmB+EsnwnnQmIt1ZvgMoCNwVuB75gmFA4Qnt/gHBEps5tClBlWDkTtL6dt6KSxRV5/HPb3BBvOxp7Oc+zDyEjUD+3xJvdJqyv65fC/qa+YMiyOpwe53BNx5cPdFHiyWHZBH2thy1vIeXKHOhUbtM+v/XxbjBcqDdLxduqBUXk2AWbMzjuLVHx9mngeaACuExKaZbLXwP81cqJZTX7jQ5jMfFukOXJCmDUepNxXWQTLhXSuhMOvwhrPww2i9rEpIBgOEIoIkda3vKcdCZgzm/1+qkyLG+gLHnNvSoWJqWWt2qjS0CC4k0IweraEt5o9k69cRawvdHLW/L2qLCJmlPSPZ2UYhNJyjaFjLW8DQTDvHygk1MXlU7ojh2RsODvARkGTzktveq7bznF2dllwcSdY+ek2mL+vbMlY4uEJ1rnzSul/IyU8p1Sykdi1v+flPLb1k8vS9n7byiYB5UrASXebAKWV2W75S3+Qr0Ju003/xHsTjjxymlOLj2Yja7znMMB0OX5rrgtb1JK2voCVBa6R9ydtxjiLaUxb/lV6j1OIOPUZOW8Atr6AgmJ1kzEPxRmb2sfq8PboXadqqk1h7AJQdjyIr2pFG9hS2q8AdE+xoe7BjjSNcipE7hMYZTlzeyQ4imj1eu3vkwIgKtAuaOztFwIwPtPrWN/u4/n9nWkeyrTImEThRCiSghxvRDi10KIcmPdmUKIuVEifKYEB1RT8WPeGlUou5q9LKnIn7h5eLaQQIssIQRCEP9d0Z5HjL6fE18AZyPjtdspy3PS5w/FVT6jyxckGIpQVeiOyUgbSo/lTQjVozNByxvACqOzSKYXzpyK3S19FEZ6qRzYp7Kh5xi2RL7T8ZJbrJaDPdaOOw79gZAlfU1h2PL2epMSncurxneZAuQ7HQhhWN6MpvQBVwlef8jaAr2xFNdlrdsU4G0nzKM838mfXjiY7qlMi0TrvJ0M7AauAj4KmH6+C4FvWTu1LGX/kzA0ACvfEV21s8mb/S5TUHXeYPjOcQpUNfY4NhzsURcZs1BsBjFe0c8yo7dhPEkLh7tUS+GFpZ4RQc0tvYO4c2wU5c6g4fx0qF4FbbsgkljdthVGvOeuLBdv2xt7Oc22Uz2Yg+LNnowivS7j2pkKy1vQOrepGfNmZh8vLM2bcFubTZDvdKhSIcbNb0dEfWeSYnkDKKlXhc6zFJfDzpWn1vHEG200tGdeo/pELW8/BG6SUq4GYv0bjwJnWjarbGbXv5Q5uv4sAHoGgjT1+ueGeEu4v2mcblPT0lN9wjQnlj7Gs7yV5qnSEWavw8k40j0IQG2pZ4RrxazxlvLSM5XHQmgQuhLLXzKLk+7K8ri315t6Ocf5BtKZD/NXp3s6KSfuG7KEBrUrAZdhMW9uQ7ztbunDbhPML55chBW4Hcpt6lOWt9aQEntJC40oqYeeQwnfiGUSV522EE+Onatv2ci+tswScImKt5OBP42zvhmomvl0spxQEPY8rFymdmURed1oUJ3JbTriJkHxJuK90JsxVmbAfAbRP454M9vjxBP3dsSwvNWW5o4Iam7pTVIszFRUGI1WOvYkvOuK6gLeaMlu8ba9sZezHTsRC8+IXgPmEjl2G8FkdNNIUXN6XyBMvkUxb6blbW9bPwuKc3HYJ/85jpYCMtymTUHVNSYpCQsApYtUrbe+5uSMPwuoKnRz57WnEwiFufy3L0avx5lAouJtECgZZ/0KIDur+VnJgWfUBebYS6KrXmroxCZgTV1x+uaVKpwecORab3lr2Q55FSpgPsMwExbGc5vGE7x/uHOA8nwXHqcjGvM2bHlLg3grX6aW0xBvK+cVsqe1n1CWFusNhiJ0txxifujonCsRYpLrHNnP0zLcRUkvFRKOSAaHwta5TXPUOMFQhIVlU7fvi1reBrogx0PTgLKqJ6VUCECJEcaeoBU901hVU8SPLz+JLl+QjQfi+22aDSQq3u4H/k8IYUp9KYSoB74H3GPlxLKSrX9WcV9GiRCAF/d3smpBUdRqkvV4ShOLeYvH9Na6XQXKZ2B3imG36fDdfJlheYs35q2uVNVyMz9DjT2DNPUOUl8+cQxN0nAXQX71tC1vwVCEg52+JEws/exu6WOtNFz8czDeDVRW9cBUfXunQwqa0/uC1jWlB3A7h39+60rjFG+BIaO7QjlHugbJdzksm88YSurVMovj3kxOXVSK027jxf3ZK96uB0pR/U09wHPAPqAH+JqlM8s2+tvgjQfhpCtVH0hgIBhi29EeTluSWRmSM8JVCIH4XGP2eNym4SEVIJ8BbbDGY7yEhQKXgxy7oCOOmDcl3tSF3+mw4XLYeHxXK1LCukXjt9pJOhXLoX13wruZGae7mrMzaeHVoz2cYdtJ2FWcsZ/XmZLrdDCQDMub2Zw+iYwXnzoTPDFZq/GJtxzD8tYJnlJeO9rDcfOT2FKxqBaEHbqz2/IGRt23umJeaojPsDAbSFS8hYD1wLuA/wFuAi6WUp4jpczO22WrePUOiIRgzQejqzYd7GYoLDl98VwSb/kQjO+jIuJxm3bsVXEZGZisAOP/IAihehVO5TYdCkdo7h0cceEvcOfQ0O7D6bBxYm1xUuY8JeXL1fuSYEmIRYal0MygzTZePdzDWY6d2BadqYLs5yAep51gKGK9azwFCQvRpvROi+q8xZSGSsxt2kHEU8bOZi8nJTPcxu5QxXrngOUN4PTFZbze1Evv4FC6pxIXcYs3IYQd6AWWSymflFL+UEr5fSnl48mbXpYQicCWP0PdGcMB3cCLDZ04bIJT6tNkIUkHzjwIxpfVY4unlU4GJysA9AdDOB02ckYFK5flT93ftKlnkIhUmaYmZtzbmrri9NUNLD8GAr3Q35rQbrlOOxUFLg53Zqd4azm8mwW0IernpssUhoWP5a7TBK4r06WtT91MVeRbkyBgtwmcDvW9r5ukTIiJmbAgfR30iCKGwpKTaootmcuElCzK+pg3k9OXlBGRsPFAZljf4hZvUsowcAhwJm86Wcqu+6FrP5zy0RGrX9zfyQk1RZaZ4TMCZz4E4hRv8bhNO/cq037ZspnPLQ34AuP3SizLd9ExhXgzLVQjLW9qrIkaXKeEGSQt1JV6stLy5vUPUd29WT0wygTNRXJj+nlaijNPFUBPIk09qvD1/GLr+gWb1re6OC1vQ2EJA100G5mmSbeuZ3mtt1hW1xXjcmRO3FuibtNvAN81Oyto4iASgQ3fU9aI494dXe0fCrOjsZd1c8llCqrtSpxu07iyTX3tqgSJPTMF8ETtdsri6G8aFW9lI92mAKel83NlWpenEfeWreJt+9Fe1ordDOUUqlp4c5So5c1y8ZYP4YCKgU0STT2qpqKVddU8Tjtlec64kg4K3Q5cBBFDPg4M5lJZ4Ep+RnnpIhjsSkkZlnTjctg5saaYbUd70j2VuJhOwsJZQKMQYr8Q4rXYvyTML/PZ+Q9o3wXnfHFEnMvOZi+hiOTEZJu9ZxvOPAjGF5AeV503XwfkZe69xETtdsrypnabHu4awGm3UVUwfAEvcDtw2m2sTmfpmYJ54CyYluWtttRDc+8gwVB2lQt59UgPp9regLrTwJZwV8KswQzSHwhaXE/LadzAxHljOB2aewcpz3daGo6Qm2OPy+oG6sasFHXt3O11cmJtcfKLcM+hjFNQBdL7/JkR85aoueJuQAKZV5MhHQz54clvQMWKEVY3gNeO9ABwQk1RGiaWRhJymzJ1qZCBzuHivxnIZG7TgWCYgWBoRFZaLEe6BqgpycVmG/46vndtDWvqStLbJ1cI5TqdpuUtIpWVIy2lTpLE/gMNLLE1w6JPpHsqacWTTLcpKPFm9jq1mMYev6UuU4C3rKqmsiA+61mB20GpUJn6u/ucnJSKhKTYWm/zTkz+8dKMx2lPTjZ0EohLvAkhPMAPUFmmOcATwGeklB3Jm1oW8NyPoasBPnj/mOyy1472Up6fArP3bMOVD5Eh1W3CMXn4pIp5i0O8ZbAbyhcIUewZex7MWm+d/UE8peN/TXe39LG4YqTAOW9FFeetsH6eCVO2FA6/lPBuZvze4a4By8VbOCI50NGP3aZKqrgcNvLdDlyO5ApdKSWOoy+rBwvPSOqxZjumePMlw20Kqm90kmjqGWRpxcTN46fDF94c/5e1wJ1DmSHeumQBq1Mh3koN8da5L/nHmgV4XPGJt/tfbeTZvR18813pS5SL1/J2I3AN8BdUl4UrgV8D703OtLKAjr3w3E9g1eWweP2Yp7cd7eHEmqLU955MN+ZFNtgPjsmzbONKWMgCt2lNyVi3SZnR37SjPzAimzR2v4YOH+84cX7S5zgtShfBjrvjEumxxIo3q/APhfnlU/v4+6YjtHrHxhE6HTYK3TmsW1zKL96/2vLv5JGuQVYGtxNyunHMO8nSsTONXKOrwKDlblPT8pacjFMpJU09g7xpWUVSxo+HAreDEsNtGnSVckoq6ji6CqBwwbRCIDIRj9MRl0v/sZ2tbD3UnVYPR7zi7VLgo1LKOwGEEH8BnhdC2I0sVE0s4SG47+OQ44GLvjnm6T7/EA0dPi45cUEaJpdmTPEW6FPdFibBZmPyUiGRMAx2gydzxdtECQv15XkIAZ/6yxa+9JYVvPOkkZ+VXc1epIRVC2ap272kHmQEeg5D+dK4d6sscOF02KI9W2dKc+8gn7htM9uO9nL+ikr++6JqcuyCwFAE/1AYXzCMd3CIPa19PPhaMx85cxEnLxyvA+D02XSoi1NsuwlUr8GRgJDNRpKWsJCT3Jg372CIgWB4yubxyaTA7aBMKPG2ZsWyMeWFkkb58jkj3nJz7PiHIoQjErtt/Js4KSWvHOji9DQX149XvNUCz5oPpJQbhRAhYD5wJBkTy2ie/h40bob3/gkKxvbb3NGofnhPqJ2lP7zJxGVa3qa+yE7pNh3oAmTGx7yNVypmSUU+f/noOr7+wE6uv2sbb1s1b0Tj6u1HVfbX7BVvhrul+0BC4s1mE9SW5FpieQtHJB/+4ysc6Rrgt1efzJuPq55w2/5AiNO+/QS3vXjQcvG2veEI7xSHEEuvsHTcTMTjSmK2KSStXEijkWm6wOKYt0QocOdQIvoISRvnrU5haaTy5fDqX1TR7Sz3FJk30oND4QkzgA93DdDWF0h7fdZ4pbsdGJ36FiLxhIesp6hnJzz7IzjpKjjuXeNu85qRijznMk1hpNt0CqZ0m5oN7vMyU7yFwhF8wRAFE1wkzlhazvtPrWMoLOkZVfV7R2MvlQUuKpPVlHqmlMYEOidIrUXlQv61rYk3Wvr47ntOmFS4gWpP9p41C3hoewsdU5RoSZRgw4vYhcRWP7fj3WA42zR5CQvJcZuaZULmpVG85bsclOGlVxRw+tIUum8rlqvz6m1M3THTRG4c2dAbD3Thwc8pdYWpmta4xCveBHC7EOKf5h/gBn4/at3cxt/Lijd+AsV18JbvTbjZpkPd1JbmUpo3B10oCYi3KdtjDRj5MhnqNj3YOUBEwsKyiQPzzc/I6LIh2xt7OX62Wt0A8quUK2safRHrSj0c7hyYurvGJAyFI/zk8T2snFfI21bNi2ufq09fSDAc4c8vHpr2cUfTOzjEfO9WwsIONadYNm6mYhal9WVYqZCmXiXe0uk2tdsE83N8hN0lqXOZgqpRCnPCdZpnuvUDE99cbDrYzXXuR1h++8lJLww9GfF+Av4ENAGdMX+3o1ymsevmNg99Abe/Ay69WQV6joN/KMzz+zo4Z3n6Al/Tiuk2jaNciE2Iydtj+gzxlqEJC/vaVPzK8qrxPyswvngbCIbY394/u8WbECrubRqWt7pSD32BEN0D06+3dN/WRg51DnD9RctHlFKZjKWVBbxt1Tx+9dQ+XjVK+cyUrYe7OcW2m4GyVcPWoTmM3SZwOWxJsLzFH44xHZp6/DjtNsrzrGmNNV3OmC8or0xxrHS06Hb2i7d4YjJfOdjFW5zbEKWLh28a0kBcbk8p5YeTPZGMJxyCnFwO1l/BotqJ77BfPtDFQDDM+SvGxsLNCRJwb9iEiluakKjlLTPdpnta+xECllZOXH5gPPG2q9lLZDYnK5iULFJt4RLEPB/72vo5dZoZdXduPMyyynzOW1GZ0H7ffvcqXj3Sw3V3bOH+T59J2Qz7WL56oIVPiv2IJXO7vlssSamlZV5XhpIl3gaZV+yO+0YgWTgDXVC5MrUHzasAdxF0JF63MdOYqoh0e18Ab0cTi9y7YdnXUjm1MczdUt9WY3fAO27i0MLJg5Kf3NWKO8eW9kyVtOE0rExWJCz4DGNvxoq3PmpKcqP9HsfDLBnSGSPeth7uAeD4BemNuZiS0kWqMnsksW4JywxL5N62+DpxjGZ/ez9bDvdw2ck1CZf9KPLk8IsrV9PeF+Cdv3yeN1q805qDSe/el3GJEM7Fc7ef6WhUOQaLxZvdqXocJ83yNsj8ovTFu0VJR1FyIZTrVFve2Hq4mzfZtqkHyy5M1bTGRYs3q5nkx0JKyZO72zhzSXl6K+CnE1dMqZApiCthwV0E9hxr5pZi9rb2s7xyYpcpEC3g2x0j3v69s5VjqgqYNxt+TCajpB5CfuhvTWi3+UVu8px29rZOL/j83i1HsQl49+rpuZdW15Xw94+fTjAU4b2/fpEDHdMTBEPhCMXtG9WD2nXTGiMbUZY3i2PehFCu0ySJt+Zef/oLqodDKsM+Lw0hNxVzo1xI7hTibUdjL+faX0XmVUH1Camc2hi0eEsh+9r6OdI1yHkrE3PlZBUOt3GHHIfbdKo6bwMdGZusEApHaOjoZ2nV5BXbnQ4bBW5H1G3a5QvyysEuLjouA9zupTHlQhJACMHSyvxpWd4iEcl9Wxo5e1nFjDJxT6wt5p5PnoHdLvjk7ZvZ397PP7c14QvELzp2NXtZI3fiLVw+ZU3DuUTSWhA585Im3noGgpSkO8FsoAOQkJ+G34/yY8DXZpRnyl7ypnCb7jjaxXrHdsSyC9Peo1iLtxTy2E5lgUg0DierSOAOeWq3aUfGukwPdg4wFJZTWt5Axb2ZbtPHd7USkUxZ+mJWUDL9ciHLqgqmZXnbdrSHpl4/l66ZeVB3bamHn1xxErtb+zj/R0/z2b9u5aHtzXHvv+VAGyfb9mJbfPaM55JN5Drt1icsQNLEWzAUwRcMU5ybZgu/acHOS8PvR9VxatmyPfXHTiGTuU2llNgbN1IgfbDsglRPbQxavKWQR3a0cFJt8ex3dyUbV3zN6UU8btMMzTTd2zp1pqlJaZ4z6jZ97PVWFhTnctz8WR7vBqpkjrBPq1zIssp82voC9CaYcbrpYDeAZTGl5x5TyY8vP5HPX6CKonr98VveOva8jEcEyF9+jiVzyRY8TgcDQxa7TUFl/iVBvPUMqu9ecbotb/3tapkOy5vZlL55W+qPnUI8roktb829ftYFXiQscmDJ+ame2hi0eEsRR7sH2N7Yy8XHZ4DFJNk48yEYT8zbFHXeMtjytrdNidcllVOXjygzLG+DwTDP7m3nwmOrMqMnrj0HimqmaXkzMk7bE3OdbjrURV2ph8oC6+KT3r26hk+tV10i/EPxWYyklHiaXlQPFp5p2VyygdykuU2TE/Nm3kCk3fLma1PLdMS85ZVDYU3WizezDuF4n8/tR3u4yLaJ/gVngTv9N89avKWIR3a0AHBxJri7kk2c7o1J3aZSZrblra2f2tLcaGr6ZJR4lOXtjRYvgVCEM5dm0GsuXTRNy5uRcZqA61RKyeZD3aytt7a9FUCOXWC3ibgD7Rt7BjkuuJ2evMUZ+xlNFnn/v737jo+rOhP//znTZ9Sb5d6NsQEbG5teTAsJZEMSsoFAQpJNQnrbknz57m6W3353k920XVIJm8IuWSAJhLAJGyAU0wwG04wNxr1bltWlmdHU+/vj3BmNpJE0I93RvSM979dLL1lTj66vZp55znme43OP2gR13HwVJWkVktndpDZk97SpGbxV2rTeddbqKR+8uV2KgDd/H8KWnVuY7zpBaNXVNoxsOEcHb0qpm5VShlLqBzmXKaXULUqpo0qpqFJqo1LqFDvHWYiHt7dw8swqFjZKo85Cp01dapQuE7EeSCfKNvN2oD3MwlF2VshVX+mjIxzPBjInjVHk4Ch1i8aVeZtTGyTodbOziODtQHuEtr446xZYXxyglCLkLTxj9Pyu45zh2kl6gbQIGUq3CinBtKm3NNOmmSULdSG7p01b9e/ot+nvf9ZqaN9dUKeAchbyefLuAFK9/2HSKLwrr7JhVMM5NnhTSp0N3ARsHXLVV4C/Aj4PrAdagT8ppcZePGST7kiCLQc6y2OR+WTwVU0885bZXaFMq00PdUSYV19Yd+6GCh/xVJpXDnXh97iYW2dfV++i1S+CaAf0dxd1N5er+IrTF/frSrhSZN5AT/cVOm26f9tzVKp+aldcXJKxlLOgz020wONYlBJNm2YybzVOmDa1Y8o0Y/bpgAEt2+wbwyQI5vmQlkylWdnzFAdCp9mz5jAPRwZvSqka4L+BvwA6cy5XwJeAfzEM4z7DMLYBHwaqgOttGGpBXjnUiWHAWePsFj/l+CoKXPM2yvZY0S79PViaN+pS6u1P0BlJML/A4C3zif+Ffe0saarEbXOX96JMpOJ0RiW7WwvPvL10oJOaoJelTaXJTBS6ViudNvAeehYA10JZ7zZUyOsmkTJIpIpr3jymElWbdkXMggUnTJvaNWUK06ZoocI/fFr/1Ve3sJwD9C91RtYNCtweywa3A/cahvGEUuofci5fBMwEHslcYBhGVCn1FHAu8JOhD6SUugmdwaO5uZmNGzeWctz09fUNe477d8VRQPf+19l4uIzeeEtkWXsPTX2dbBrj/6K7O0oiBX19qWHHtLZzK6cDr7y5m+5joz+O0xzs0S8MPcf2sXHjoTFvf6RVp/D3nAhz9iy3JedwvvO0FCr62lkPbH/mQU7M6Crqvq5wnGPdCf746BMEPWP/3Tz9ZoQFlS6eeurJ8Q12DOl4PwePHs973HKP5/7uFKclt9EWnMO2l94E3izJeMrV0UM6k/XI409S4R35/7XYc3RRSxvzYn08ZfF5vXVnHLeCLc89Y2uh0LrW/USDM9k+gd9von/35/jq6HzlYXb0nzzux3C6ZH+Uw8ejg45T2+b/Zq2haA0s5fiQ4zdZr6VDOS54U0p9AlgKfDDP1Zl5x6Et248DeRs7GYZxOzoYZN26dcaGDRusGegINm7cyNDn+NmezSyfGeMdl11Y0ucuG/HHoPXJYcdpqJ/t2Uw4lqSyMjH8tm9F4TVYs/5cmLO2ZEMthYe3t8Cml3j7+etYNbd2zNvXHOzk31/eBMD5py1hw4ZlEx5DvvO0JGJnwJYvccqsIFxQ3PMlZhzn3p1bmHnS6ayZP3qGNZlKc/yRh7h63UI2bCjNG0vTG89S4fewYcPw3RJyj+ePHt/BOtdbeE/+88k5xmXm6OaD3L3jddaeefaobZOKPkddL8LB+9hw/rngsW592iOdr1PX2sLFF9s8Bf5CH5ULVk7onJrw3/2RM5nZuZ+ZU/i8vn3X8yRSaTZsOBeAWCLJ4Y2fYV/FKi668n3Dbj9pr6VDOGraVCm1HPg6cL1hGMU1eHKodNrg1UNdY775TCu+SkhG9XYvoxi1z1tmesRXfgUghzoiAMwrcO1aQ8XA5uhLC2jq6yj+Kr1OZ5y93qCwitPDnVGSaYNFJSwIKnTa9ND2zVSrKMFl0t8tnwr/6FsQjZvPnC4vYPeWYnRF4tlt6myT2RrL7vVWC87RG9Rnes5NQSGfm3DOtOnLL25iCUdIrXyPjaMazlHBG3AO0AhsV0ollVJJ4CLgM+a/zZ3IGTrx3wy0TN4wC7e3rY/e/iRr59faPRTn8Bf2IutSo2yPldABUDkGb4c7o1T5PQWvoamvHHjjWFZOlaYZdQvHteZtXn0Iv8dVUNFCZv/RxU0lDN68Y2+o3hdLUt26Wf8g/d3yyvTSsnyXBa/5YSjz2mCRrkjC/h5vdm6NlWuhOXu0/2l7x1FCIZ9nUEFN30u/IoVi0YXOWlbvtGnT3wFbhlz2C2AXOiO3Ex2kXQ68CKCUCgAXAH8zaaMswssHugAk85Yr+wk5DMHaEW/mUorUSMFbJvPmLaPKS9PBjghz60MFr5+p8LnxuV0YGCwosMjBUeoWwcHni76b26VY0lSZbWg8mr1m8LaosXTBbaiAatPn97SzjjeJVi0kWD2rZGMpZ6Hs/pFWZ97MwN3iooWuSILZtTZvSm/n1li5Zq3Wr9/7n4FT3zvxx0un4MhLcORl6D0KRlq3f6pbBHPX6Sbfk0xn3pLm8FKc2v4QOyvWsaLaWftJOyp4MwyjC+jKvUwpFQY6zMpSlFL/DvxfpdQOdDD3d0AfcNdkjrVQrxzSFXCLpb/bgOyL7NiZtxH7vJX5tGkx03tKKeorfNQEvXjcTkuWF6B+EWy7F5LxotciLWuuzG55NZp9bX3UBL3UlbAiULcQGH2q/9mdx/iyawe+JdeUbBzlLpjdP9LiXm8lnDZdafd2dHZujZXL7YH55+jgbSLSKdjyc3juhwNLKtx+UC69pCajbhGc8h449Rq9v+okFIyEfJ5sVvjgy4+wkDYOnPSVkj9vsRwVvBXom0AQ+CFQB2wG3mYYhiM7B758oIvT59XiKqf2DqXmN9dtjdGod9Q+b4kIuDzgtnktSpEMw+BwZ5SLTiquX9PK2dXMqyvTPXHrFulP1F0HoXFpUXddNqOSB149SjiWpMI/8svVvrYwixorSloNWMiG6q1vbaZaRWCp9HcbyWibf09IqTJvUQdMm2a2xrI7eANYeD48+g9m65JxjKfrENz/STjwLMw9Ey7+W/2YmUx1rBfadsGhzbDrEXj2Vnjmu9C4HM74CKy5AQI1lv5KuUI+N5FECsMwiL/0S3qMIAvPf3/Jnm+8HB+8GYaxYcjPBnCL+eVovf0Jdrb2cuVpMn0ySIGfkEft8xYPg7diUj6JWamtL040kSq4QW/Gzz+yfuT1f05Xv1h/79xXdPCWKdDYc6Jv1MrcfSfCnL24tLttjNVc9lBHhMU9L2B4FWrRhpKOpZyVLngz/6bi1q15iyVTROIpZ/R4A/unTQEWXqC/739aZ8SK0bYL7ninfu1/922w+rrhr+H+Kt1BYM5aOPvTuiH7Gw/A1l/BwzfD4/8Ep38AzvoUNE688n6ooM9NKm0Qi/Qw//ijPO67kCsbnLfsqQznYMrHa4e6MQxYI8UKgxU6beoaZWP6eHjgxbqMHMxUmtYXn0Uri83o86nPNOrdW/RdM1uBjbZNVjSe4mh3f0krTWHs5rJP72rjAvfrxJpWQUV5bts2GTJr3qJlMG2a3ZTe7mpTu7fGyjVrNQRq4a2Hirtf+x4duBkp+NifdABWyGtaRSOs/xh87BG46Uk45d3w8n/BD9bDbz5i+Y4PFeaHi9hrvyVg9NOy2FlVphkSvJXQKwf1Wp3V82rtHYjTZF9kR/+ErMaaNi3DYoXDncW1CZkSKpp0lnQcFafz60MEvW7eONoz4m32t5vFCiWsNIWBtVojZd8279jHWtdu/MsvLek4yl05TZs6ZlN6u7fGyuX2wMqrYceDhR/rWB/ccz2k4vDh30PzyvE99+zT4d0/gi+/Aed/GXY9CredB3ddB4eH1jqOT+bDRfKFn7ErPYeFp19iyeNaTYK3EnrlUBfLZlTavyee03jMvmWp2Kg3G3PatAyLFdr79FY7TVX+MW45hSilp07HkXnzuF2cOqea1w53jXibbJuQElaaQk7wlifoSKQNUnuexkMKtcSZL/ZOkWkVEi6DViGZTelrgw7IvNm5NdZQq94PiTC89cexb2sY8MBnoW0n/PkdMGPFxJ+/sgku+wf48uuw4f/Coefhp5fCf12tiykmsMQk5HdzitpPQ9fr3JW+hPWLnJlFl+CtRAzD4JWDnTJlmo/HLLtP9o96M5caa9q0/IK3nn79Sb4qMM0C+vqF42rUC7Bqbi3bjnSPOF2ZCd4WNpY2mzlaxmhnR5r16VdJuYMw78ySjqPcuVyKgNc1ZtuVopVg2tQxmbfxFgeUyvxzoWo2vH7v2Lfd9H1443dw2S2w2OLG1cE62PBV+NLrcPk/wvHtcMdV8PMr9LTuOIK4kM/N9e7H6MfH1vorHftaLcFbiexvj9AZSbBW+rsNl8m8JcfOvI3Y561Mp017okmq/J7y2lzeCvWLoXO/bhFQpNXzaokl0+w8nr+gfE9rH7NqAtnpjlIJejNrtYb/Dq+1JrjE/RosunDg/BYjKqTtStE8PnB5LZ02HVjzJtOmg7hccNo1sPtPo++2sPdJXZm68mo49wulG4+/Cs77og7i3vEt6DkKd18LPz4Ptv5mzN18clW6ElztfpYHU2dx0sLJ7zNXKAneSmTL/g5AmvPmVWDmTY3V561MM2/V03EavW6RXu/Sc7Tou55uVpm+dqg77/W7WvtY1lz6bcMG1rwNfyPoOXGQeaoV98nvKPk4pgLdS2ukP+4J8FVYGrx1RsxpUzsLFrJbYzlo2hRgzY06s7XxG/mv79gH934UGpbB1T+cnM4A3iCcdRN84RV4z090ccRvPw7fXwvP3wb9+V9DcjW3PEml6ufe1IWsmefc928J3krkwdePMac2mN2fUeRwewE1ZubNrdTI7THiEduCN8Mwxt22oyeaoCrg+A491stUnI5j6nRefZC6kJfXDnUNuy6dNtjd2jcpf2cjTZvuPdHH6vjL+oeTrij5OKaCkkybgp46HaN/ZDG6ogm8bpWtQLRFdmssB2XeAJpOgjNvgpd+Ace2Dr6uvxvuvk5n2j9w90Bvz8ni9uo2JJ9+Dq67Swe+D30VvrMCfv+lUStUGw48yAmjms3pFaxdUDtpQy6WBG8lcKI3xtO72rj69NnSnDcfpfTU0phr3kbbmL7PtmnTr//vm9z48xfGdd9pm3nL9HobR9GCUopVc2vzFi0c6YoSTaRYOgnB20h7cj67p51L3K8QbzwFqmeXfBxTQcjnsX7aFHQrjbh1/dpf2t/JwobSNn8ek1O2xspnw//R684e+Ax0H9aXdeyFX1wJ7bvh2juhYYl943O54OSr4ON/gps26t0aXrtbV6j++Hx49nuDZwNifYQOPM4fU2dRGfCVvAhqIiR4K4H/ee0oqbTBe9fOsXsozuXxj73mbbQ+bwn7Mm87j/ex98T4pma6o0mqHboAtqSq5+j1SONoFwKwem4NO4/3DnvD323uezoZmbeRWoW8tfcA69RbeFfIlGmhgt7RGx6Pm6/SsmnTg+0RXtjfwbvX2Pw67pStsfIJ1uop0fa98ONz4RdXwW0X6EDu+l/pNaBOMXsNvPuH8Jdv6nVxHj/86e/huyvhp5fBk9+CzT/GlYzyh9TZnD6/ztHJFwneSuD+Vw5z2pyabHd4kYcnUMCatxEyb+mUvq9NwVtPf4LwOLMGPdEE1cFpOG3qckPdgnFl3kAXLaQN2D6k39uuVp1lmYzM20jTpsEDj+FWBuqkt5d8DFNFIVuNjYvfumnT375yGKWwP3hz0tZY+Sx/B3z6GZh3NqSTuonuTRth6WV2jyy/UL1eF/eJx+DzL8OGm/V7yhP/BI//E0blTN7wruTsxfV2j3RU0/BdpLSO9KXZdiTM379znE0Ip4tCMm+K/GvLMp+sbZo27YkmiMTG98bT05+Ynpk3MHu9jb9dCMBrh7pYv3DgRXXX8T6aqvyTsqA8lKfatL0vxvrI03T56qmdc0bJxzBVBL1ujpUq85bZSmoCDMPgty8f4ZzFDcyptXlPYSdtjTWS+sVww6/tHkXxGpboViMbvqqP8+5HUXUL+WPV6TRXB+we3agk82ax544mcbsU71ota19GVUDmbcRWIZkmnLZl3pLEU2niyeKq5dJpg75YcnqueQOoXwIde0YpIR5ZU5WfObVBXh1StLBrkooVAAI+/XKZO923dc9hLnJt5VDdOXqeXxQk5HNbv8MCTKhg4a2WXp7b0w7Aq4e6ONgR4Zq1DmgV4aStsaayyhlw+vWw4Fzm1YfweZz99+zs0ZWZdNrguaNJLljWOL066I9HQZk3RTrfvGkm82ZX8GY27ix22qc3lsQwoHo6VpuCrk5LRKDn8LjuvnpeDVsPD5T6G8bkVZoC+Nwu3C416P+97/U/4FcJorPPm5QxTBUBn7s01aYTKFj414d28Nm7XsYwDLbs11sbXrTcARWeYYc16BWOIMGbhTbv66C93+A9dq+RKAcFZt7y1ivYOG3an0gRMzNuxa57ywR90zbz1rhcfz+xc1x3XzW3loMdETrMLYtaevrpiyVZOgk93kCvwQx5B2eMmg8/RLurnkidBVv+TCNBr/Myb7tb++gIx9nXFubVw13MrQvSWOmAD+F9rc6eMhW2kODNQve/cpiAG962cqbdQ3E+T6CgNW95q01tnDbt7R8I2IptdZDZGmvarnlrMoO3trfGdffVmXVvZsuQN4/p4oWTJrGXYsDnzjbpjYe7WBV9kd0Nl4CSl9JihHy62nS8/RJH5K+EdGLM15ah+hMpDnfq15WXDnTy6sEuVs+rtXZs4+W0rbGEI8grjkUMw2BXax9nNHuyLQXEKArp8+YaodrUxmnTTAAGEDaLFjKZoDHvG9Vv+tOy2hSgohGC9XBifMHbaXNrUAq2mjstPLOrHb/HNalvsqGcKsm9G/+LgErgWn3tpD3/VBHwujEMsllsy/jMLGyR2bcD7ZHsa83D249zpCvKGqcEb07bGks4ggRvFlFK8dtPn8uNp9i4jUo5KSDzpkbKvNk4bZqZ+gQ9bbrtSDdn/NOfslmg0XRHp3nmDaDpZGgb37Rppd/D0qbKbObtmd0nOHNRPQHv5H1Yyp3u82+7hz3MYfVZl07a808VmbYrlrcLySzqL3Jz+r0n9O1nVgd4bIduiuuIzJtTt8YStpPgzUJKKfxu5zb1c5QCd1jIO6ti47RpT+60aSzFwY4IhqEr1ca+rw7eaqbrmjfQRQsndpD/P3ZsZy2uZ9OeNt442sPO432ct7TR4gGOLmhO98WOvcmi6HbemvkufJMYPE4V2d0qrC5a8I0veNtjBm/vXTsHwwC3S3Hq7BprxzYeTt0aS9hOgjdhj4msebNz2nRI5i3zc2a9TCH3nbYFC6CLFqKdEG4b190/et4iYsk0n7tb7yV6/iQHb5lp08NP/Iyk4aLxvA9P6vNPFcERGh5PWCbzVuS06d4TYWbXBDh/mT6fljdXOWP5i5O3xhK2kuBN2KPAzFvePm92TpvmrHmLxFPZn490RQu4bxKloMo/Tde8gc68wbiLFpY0VXLlqbPYeyJMQ4WPlbOqLRzc2IJeD6lYmObdv+IZ1xmcccrJk/r8U0Um82Z5u5DMmrci24XsOdHH4qZKTp9Xi9etWDO/1tpxjZeTt8YStpLgTdijoDVvetp0WEWandOm0YFp03Asmf35cGcBwVs0QaXf4+j98kou2y5kfMEbwKc36I2uz13aOOnHMuhzsyH8EJXpHrYv+gju6fx/OQEhn/4A44TMm2EY7D0RZklTBSGfh19+7Cy+eNkya8c1Xr3mpulV0sFADDaNUwDCVgVk3txKvzEOy73Fwzr4c03+tEZPfwK3S5FKG0TiKXozmbdCgrfpvDVWRs1cvS7pxI5xP8Spc2r4zp+vZvW8yV+TVOkxuCb+O14wljNv9SWT/vxTRTDPbhWWyHygK2LN24neGL2xJEvMljNnLW6wdkwT0XVIt6Gplt6hYjDJvAl7eAKQio+6VVImqTFs5jQetnVf09qgF7/Hpde8mQUMh7ui+XeDGHTfabw1VoZSMPM0OPbahB7mmjPmsnTG5DTnzXV6ZBNzVRu3Jf+Mc5c46E2+zGQqhKNF9koc0zhahew2ixUWNzpw+6nuQ1A1C9zT/HVDDCPBm7CHx+xcnhp56jQzJTYsJEpEBqrKJllPvw7AKvweIrFUtgghnkzTFh59Glhn3iTZzew1cGyrboNQZppSegF594wzndF9v0xlpk0tz7xlW4UUvuYts+Rhfr09HwhH1XUIaubZPQrhQBK8CXt4Avr7KFOn5qzp8Ea98TD47Mu8VQc8hHxuM/OWyI5zrHVvPdGEZN5AB2/J6LiLFuwUQgfo65fNtnkk5S3bKiRucZNejx9c3qIyb51mk+2GSgf26Ow+CLXz7R6FcCAJ3oQ9Mpm3UYoWXKOtebNr2rRfB2Ahn9vMvCVZYH5iH2nd2+M7jvPkzhNm4CfBG7PX6O9HXrZ3HOMQVDFihofzTpIF5BMx0CqkBNlXf+VARXoBOiJxfB5XtnGwY6SS0HMUaiXzJoaT4E3Yo4DM24hr3hIRWypNgWwAFvJ5spm3FWa7ipEyb//4+zf49C9foi0cn75bY+WqXwL+ajj6it0jKdqcCoOkO8j6hfV2D6WslaxVCOh1b0UULHSG4zRU+FDKYZXDvccgnZRpU5GXvJMIexSRecs7bVptz7SVXvPmoSvqNqtNk8yuDVIb8nKka3ij3nAsyQFzFwaY5ltjZbhcMGt1WQZvjb4UVFaD7KowIT6PC49LWd8qBHTmLVb4mreOcJy6kBOnTA/p75J5E3lI5k3Yo6A1bw6cNs3JvPVEE/TFklQHvMypDebNvO083othwHlLdWWirHkzzV4Dx7dBMm73SIqTsO/cm2qCXrf1BQugi5mKyLx1hOPUVzgweOsyg7caWfMmhpPgTdijgMybe9Rp08l/A+1PpIgl07ra1OfmeI8OPKuDHubWBfOuedth7nn6z+8+jf975clcddqsSR2zY81eo1vFtG63eyTFidtz7k1FAXOrMcv5K4srWIgkqHNi8NZ9UH+vmWvvOIQjSfAm7FHImjdz0duwerRY30A/p0nUa/Z0qw54CPk92R5v1QEvCxsrONAeGfZmtONYDxU+N/PrQ9x04RJm1gQmfdyONO8s/X3f0/aOo1iJiGTeLBLylSrzVlF85i3kwIx41yEINcqHBZGXBG/CHtngbeTMW3baNDfzZhj6hdk/+X3eMvuYZjJvGVUBD+cvbSSeSvPc3sEbrr/Z0svymVXTe0usfGrmQNPJsOdxu0dSHAneLBP0ukuz5s1XVXDmLZlK0x11aubtkLQJESOS4E3YIzttWki1aU70Fg8Dhi1NejMNeTNr3jKqg17OXFRP0OvmiR0nSKcNntjRSjSeYsexHk6e5M3Ty8aSS+HAJkiMvbWYY8i0qWWCPndpqk39lQU36e2M6L9px655k2IFMQIJ3oQ9Csi85e3zlpkOsSXzZk6TBj1U+Acyb9UBL36Pm/OWNvLEW63c/eJBPnrHi9x05xZ6+pOsmDn5U7xlYckleoeNA5vsHknhEmHw2tOmZqopXebN7PM2bLHscJ0RXTDjuGpTw4Duw9ImRIxIgjdhjyIyb4NahWSmQ2xY85bJvFUNy7zpf29Y3sThzij//OCbVAU8PL1LT6FK5m0EC84Ft7+8pk4TUfAG7R7FlBAqZcFCOjnqB8OMDnN3Bcdl3jr26l1IGpfZPRLhUBK8CXsU0SpkUPCWmQ6xIfOWeaMJ+dyDM29m+48Ny5sAXZV69yfO5qxF9bgUnNQsmbe8fCFYcA7sfqzw+8QjemeG/c9Cf3fpxjba89vUIHqqCXhLNG2a+WBXQNFCZmssx2XeDj6vv2cKe4QYQpr0CnsU1Cokz7Rppvmmf/IDov6kfqMJeN3ZzJtSUGn+e25diItOauLkWVWcOqeG2z+0jh0tPdRIb7eRnfR2eOj/wPHt0HzK6Lfd/yzc/8mB5qWBGjjnc3DeFwfOp1IyDClYsFDIV6Jp08wHu1gvVDSOetOOiEP3NT30vD6/G5fbPRLhUJJ5E/YoqFWI/m7knTad/MxbJkvg97ioMAO2Kr9nUCXpf/7Fmdz8jhUA1IS8nLW4YdLHWVZWXaunTl+6Y/TbvX4v3HEVuDxwzc/g+l/DwgvgiX+GX14D0a7SjzURRRfLSPBmhZI26YWiMm+1TmsVcugFnXVzyVu0yE/ODGEPt/lJd9wFCzZk3hK641zA6yZkTpvKjgkTFKqHlVfDa7/SU5L5tLwOD3wO5p8Dn3oGTnsfnHQFXPff8J7b9RTTL66ESEdpx5qpipXMmyVK2qQXCmoX0h6OU+n34Pc4aLuzSAec2CFTpmJUErwJeyils2/FrnnLTJvalHlzuxRe90DmTfYqtcAZH4FYN2y/f/h1kQ645wYI1sL7/3P4WsfV18INv4b2XXDXtWYrmRJJmI8twZslQl4P8VSaZGpYG+6J8ZsFQrGeMW/aGY5TV+Gwv+HDL+rvEryJUUjwJuzj8Y+RedPfndIqpD+RJuDRfzIhXybzJstGJ2zBudC0Ajb+y+AihHQK7vs49ByF998JlTPy33/JJXoq9cgWuPcv9P1KIZMZlGlTSwR9+m/J8qnTUL3+XkAmtiOSoN5pxQqHNuvlAXPOsHskwsEkeBP2GSPz5sq3w0JmKsSGXlv9yRQBrw7aKvzmmjfJvE2cUvCu70HPEfjfv9GXpRK6kGHPY3Dlt2De+tEfY+W74B3fhJ0PwZ++VppxZjNvUm1qhaCZvbY8eAuawVt07OBNZ94cFLylU7DjQZh1unxIEKOStIGwT4GZt/SgHRb69JSpDQt5+xMDwVs28ybBmzXmnQkXfQU2fgO6Duqg/ugrcPZnYd1HC3uMMz8BbbvguR9Aw9LC71eozJo3eVO1RND8W7J83VugBpQbIu0AvHywk5qglyVNw7P1HeE4y2ZMfhZ/RNvv1+vdrvmZ3SMRDifBm7BPgWvehrUKsWG9G0Asmcbv1UGj3+PC7VJUBeRPyDIX/LV+033zAeg7Ae/7BZz63uIe44qvQ8ce+N+/hvpFsHiDdePLTJvKmjdLZD4AWZ55U0pPnZrB21fu3crSpkpu+9DwacjOiIMyb6kkPPF1aD4VTinyvBfTjrzzCPuMkXlz55s2tWlTeoBYIkXArEpTSvF3V63gzEX1toxlSnJ74KK/0V8TeYz3/Rx+dgX8+kb4+GPWdamXggVLBc3gLRwrwRrFYH12zVtXJMHx3uEfEqPxFJF4yjm7K2z5mf7gcd3d0iJEjEnOEGGfsda8mWfnoFq0WJ9tmbf+RJqAd+BP5qPnLeKU2TW2jEWMIlAD198DLi/c9X7rWohIwYKlas02O93RuPUPHmrI/r+HY0na+oZ/SNzbptfPLmhwwP/n8Tf0Ws0ll8Lyd9g9GlEGJHgT9vEERs28qREzb/ZsN5W75k04XN1CuO4uvbn3r2+EpAUBQiIzbSoFC1bIbEnVEU5Y/+Cheoh2kEyliSZStPUO///feVy3HVpu9/Z1yTjc9zH9uvae2/S0rxBjkOBN2MfjH1+1qV2Zt2QKv0f+ZMrG/LPg6h/C/qfhwS8POZHGIRu8ycb0VsisNeuKlCLzpte8hc1iiGgiRTiWHHSTt1r68LoVCxttDsZf/k9ofQP+7Hsjt8MRYgh5JxL2GSPzlr/PW292zdu+tjDGRN+Qi6CnTSXzVlZWvR8u/Aq88kt46tsTeywpWLBUdcCD26XoLEXwZq556+sfyOq19w1+np3He1nSVInXbePbYCIKT39H7x4i06WiCBK8CfsUmHlL58m87W7t4+Jvb2TTnvYSD3KATJuWqQ03w6rr4Il/gs0/Gf/jJMLgCcpicosopagNeumMlGLatAHSCSK9XdmLTgxZ9/ZWSy/LZ9o8ZbrlF9B7DC7+W5kuFUWRVyFhnzHXvOnv6TzVpke7dM+tvSfG3r/QKkMLFkSZcLn09OnJ74Q/fgVevWt8jxOPSLGCxWpD3uzm8JYyd1no72nLXpRbtNDbn+BIV5ST7Fzvlk7pnoQLL4BFF9g3DlGW5J1I2KfQNW+ZC1JJfXtfFV1R/Wn9WPfI97daLJFy1gbWonBuj258uugieOCz8MYDxT9GIirFCharr/CVZto01ABAovdE9qLc4G1Xq/7QZ2uxwr4n9a4i6/7CvjGIsiXBm7DPGJk3t2tIwULc3JTeX5ld5NwymcFbUta8lTVvQFegzlmn90B9/d7i7p8IS7GCxWpDPrpKMW1qbpGV7BtYVpFbcbqzxaw0tXPa9NW7dVub5VfaNwZRtiR4E/YZM/OmvxuZ3FtmX1NfZfYFf7Iyb6m0QTwl06Zlz18JH7wP5p2lN71/6Y7C7yvTpparC3lLmnlL9+WfNn3reC8hn5s5tTYF4/098Obv4dRr9IcKIYok70TCPp4ApOKQTue9Wg0tWIibwZt/IHg73jM5wVssqVsOSOZtCghUww33wtLL4PdfhE0/KOx+iYhMm1qsrsJHZzhhfdV4aPDm9I2Vftr6YvT0J/jaA9v4zZbDrJhVjctlU5HAG7+DZBRWX2/P84uyJ8GbsI/H/MSZ6Z81xLA1bzFz2tRXlZ02PdbdPyntQvoTOsAMSJ+3qcEX0lOoK98Nj/wtPHSzXlM5moRk3qxWF/IRT6WJlGRzehcuM3hb2BCirS/Gfzy1lzufP8ClK2bwr9essvY5i7H111C/GOaus28MoqzJO5GwT8DcWqq/O+/V2WnTTGwWy1nzZhYsRBMpeqJjvOlaoD8hmbcpx+PT+6Ce/Rl4/kdw97UjnouAnjaVNW+WqgvpLbIsnzp1uSFQiyfWid/jorkmQFtfnOf3trNqbi23XreGpTPsafZNbwvsfwZOfZ+0BxHjJsGbsE+wTn/v78p79bDMWzx3zdvAi/2xnmhpxpcjE7z5Zc3b1OJyw9u/AX92K+zdCD+9HNr35L+tTJtarjaU2WWhNL3evLFOqgIemir9tHT389qhbs5eVG/9cxVj+/2AAae9z95xiLIm70TCPsFa/T3amffqYX3eYoPXvM2u0dOuk1G0MDBtKpm3KemMj8CHfgfhVvjJRbDtvuG3iYdl2tRi9RWZ/U1L0+vNn+ii0u+hsdJHNJEinkpz1mKbg7fX74Xm06Bpub3jEGXNUcGbUupmpdSLSqkepdQJpdTvlVKnDrmNUkrdopQ6qpSKKqU2KqVOsWvMYgIymbdoV96rh+2wkM286T5vK2ZVA5PTLqRfChamvkUXwCefghkrdCuR//nCwJZYYPZ5k+DNSiWbNgUINRBMdFPh99BY6Qf0B8J1C20M3jr2wZEtcNo19o1BTAmOCt6ADcCPgHOBS4Ak8KhSKvev7SvAXwGfB9YDrcCflFI273Miihao1d9HyLxl+7xlLjDXvKXNadOlzZW41GRl3mTadFqonQ8f/V84/8t6w/D/uBiOvKwropNR8Mm0qZVKOm0arKci1W1m3nTwtnJWNdUBr/XPVahX/xtQer2bEBPgsXsAuQzDuCL3Z6XUh4Bu4Dzg90r3jvgS8C+GYdxn3ubD6ADuemACGxeKSZfNvOUP3oYVLMT7wOWhN+kmbUBTpZ/GSj8t3aVf8xbLTJtK5m3qc3vhslv0tkUPfA5+eimc+Ul9nRQsWKo2qAOpkkybVjRQle6myueisUoHb2ctarD+eQqVTumt2ZZeCrXz7BuHmBKcnkaoQo8x8+6+CJgJPJK5gWEYUeApdLZOlBN/FSj3iAULmT5vRu6aN18l3WZ1aW3Ix6yaAC09I+/SYJVsnzdZ8zZ9LL0UPvMcnH4DbP6xvkymTS3lcbuoDniyBUiGYfDEjlZSaQva/1TPxUuSmd5eFjdVsGxGJe9cPWvijzteex7X22GtvdG+MYgpw1GZtzxuBV4FnjN/nml+Pz7kdseBOfkeQCl1E3ATQHNzMxs3brR8kLn6+vpK/hxTybmeCk7s2c4u98Zh17WEdbYr2t/Pxo0bWXFgB9UEeOwZfToc2rMDTyLJnqPpkh/zl4/qgHHrK1to3en0zzxjk/O0CDXvo27VEhYcuJddrV7CeY6bHM/xC7hSvLX/MBs3tnGgJ8U/bOrnS2v9LA31T+iYNrR1chrga9vBy897+Nu10LP3NTbutWzoRTll23eo8dbwXEsIo3WjLWOQ89R6dh1TxwZvSqnvAucD5xuGMe4OjoZh3A7cDrBu3Tpjw4YN1gxwBBs3bqTUzzGlvD6DOXUh5uQ5Zgfaw/D0Rnx+vz6mB74LvvksXrEKnnuBC85cS/fWY+x8+XDJj3nLCwdh6+tceN45zLZrSx0LyXlarA3Al1k/wrVyPMdv1vZn8QY8bNhwFk/uPAGbXmDO4uVU9u2Z2DFtaYBtX+e0BsP+/5vO/fDkC3DOZ7noksttG4acp9az65g6MoWglPo34APAJYZh5H5OajG/Nw+5S3POdaKcBGpHWfM2pNo03AYVjdkpltqQj6YqP739yWxBQalIk14hSiN3f9Mes/l2b//EG28nquYC0Jg+MeHHmrBN3wflgrM/bfdIxBThuOBNKXUrA4HbjiFX70MHaZfn3D4AXABsmrRBCusE60ZZ86a/Z1e/RHTw1m2+wNeGvNSVslotR38yU7DguD8ZIcpafUjvbwpk/7atCN7CqoIeI0hDYugqm0nW1wqv/BJWXwfVs+0di5gyHPVOpJT6IfBRdOVop1JqpvlVCWDoTSz/HfiqUuq9Zg+4O4A+4C57Ri0mJFg3dqsQA92qIdwGFU3ZQK0m6M32iSpJtVqObKsQKVgQwlK1IV82m54J3vpiE/8w1hdLcsRopCZu86TMpu9DMgbnfcnecYgpxWlr3j5jfn9syOX/H3CL+e9vAkHgh0AdsBl4m2EYvZMxQGGxYO2Y06YG6OyckYKKJjpPxKnye/C6XTl9okodvKXxulU2oBRCWKMu5CUcTxFLpujpz8m8TbClXiZ4mxM7ZsEox6lzP2y+DVZdC41L7RuHmHIcFbwZhjHmO6OZfbuFgWBOlLNgHfT36B5IrsFZrUHbY4Xb9A+hRrojCWrMjFtdRaZDe4mnTRMpaRMiRAnUVQwsfbByzVtfvw7eQpHnJ/xY4/anf9DtkC79mn1jEFOSo6ZNxTQUqAUM6O8edtWgzFvYXHRc0UhXNEGtGbzVm5m3kmyvkyOWTOGXYgUhLFeX8zfcY/ZwzGTgJqIvluSo0Ygn0Zv39aXk9j8Db/wOzvsi1OTtZCXEuEnwJuyV2WUhT9GCK7dJbzZ4a6IzEs++4E/mtKkUKwhhvez+puGEpQULmWlTALoPT/jxipKI6r1xaxfAeV+Y3OcW04K8Gwl7BWv19zzr3gZtjxUxp00rzGlTc1sdn8dFhc9NR7i006axZErahAhRArkfwAbWvE387zmcG7x1HZrw4xVl4zegYw+863uyH64oCQnehL2y+5t2Dbsqsz1WGnLWvDXQFR0I3mBwtVqpSOZNiNKoN9e8dUTiOdWmE8+89fYnOZzNvE1i8Lb/WV1huvZGWLxh8p5XTCvybiTsNcrm9K5BBQsnIFiH4fLQMyR4q6vwlnzNmxQsCFEamfWrVhcshGMp2qjBcPug6+CEH6+wJ22H+z4GdYvgiq9PznOKaUmCN2GvQK3+nid4y/Z5w9CZt1AjkXiKZNqgOjd4C/kmp9pUpk2FsFzA6yboddMRjtPTn0QpiMRTE96cvisaJ+TzomrmQdcBi0Y7inQafvdpiLTDn98B/qrSP6eYtiR4E/bKrHkbs2BBN+jNrImpGRK8ybSpEOWrLuTlSGeUVNpgZnUAgOgEk28t3f3MrAnAjBXQss2CUY7h+R/Crod1xm3WqtI/n5jW5N1I2MvjB29ohDVv+nu2YKGiMdtKoDqQG7x5S7/DQjIluysIUSJ1FT72t4cBmFMbBCCanFjm7Vh3P7NqgjBrtS4eiJWwj/uhF+HRW+Dkd8L6j5fueYQwSfAm7Besyxu8uQYVLJyAiqbsguahBQs9/UmSqXTJhhhLpPFL5k2IkqgL+TjQHgFgTp0O3iITDt6izKoJwEwzC1aq7Fv3YfjVDVA9B67+wcCnTiFKSN6NhP1G2N/Uld1iIQWRDjPzpoO36uDA5iCZPlGZwK4UZM2bEKVTG/ISNfcPnluXybyN//ESqTStvTEdvGWmMFu2TnSYw8XDcPcHIB6B6381UIAlRIlJ8CbsV9EEvcP3H8xUm4bSfYAxYuYts71OKYsWpNpUiNLJNN0GmFMbAgqbNj3QHuZDP9s8bEeG1t4YhgGzaoNQNUu/xhyzOHjLFCi0vA7v+5leWyfEJJHgTdivfrFek2IMfrHO9HmrSJlb21Q0Zl+kc9e8TcYuC/1JKVgQolQyH8CguMzbEztaeXpXG2+1DF7P1tIdBdAFC0rpqdNjr1k3YNCNeN94AN72/+CkK6x9bCHGIO9Gwn4NS/Teg3mmTr1uRTBpBm+hxmzmrSowMG2a2d+0VEULyVSaVNqQaVMhSiSz9AEGgrdIYuzM254TusihvS826PKjXf0AzK7Rj8WsVXDiTUgOvt24bf4JPPVNWPNBOOdz1jymEEWQ4E3Yr36J/t6+Z9hVNUEf1fFW84e59ESTVPo9eNwDp25uk89S6E/qQgjJvAlRGplpU6VgdhHVprtb+wBo6xv8wa2lWwdvM2t02xFmroJ0ElrfnPhgX70L/vgVXVn6zlulQEHYQt6NhP3qF+vvHcODt/oKLw3xI+AJQO18uqMJqnOybpC75q00mbeIuVVPyOcZ45ZCiPHI/A1X+j0EvG58bldB06Z7TujgrX1I8Ha0O0qFzz3wWjF7jf5+8LmJDfSN/4EHPqu3vXrfz8EtrwnCHhK8CfvVLQTlypt5qw35aE4e0dk5l5ue/sSg3RUAKnxuvG5VsoKFcFxXwVX4ZdpUiFLITJtmCpGqAp4RW4X09CfoDOtN7Ft79TRoe3jwdGimQW9m3Sz1i6D5VNh+//gHueNBvfXVnHVw3V26R6UQNpHgTdjP44OaedCxd9hV9SEfs9NHoXEZAD3R4cGbUqqkm9OHJfMmREllpk1zg7foCGve/uY3r/Ghn29mjzllCvkyb/3Z6desU98LhzaPb5/TV++CX31IT7/e8GvwVRT/GEJYSII34QwNS/JOmzYGFbON1mzwpqdNvcNuVx/y0dZn0WLkISKZzJsEb0KURGbdauZvuyrgJZrKf9sdLb1sO9LDw9uPA9BU5R/2t9/SHc1us5V16jX6+7bfFj6wdBoe+0fdEmTh+XDjA9LLTTiCBG/CGeoXQ/veYe1CFrmP41FpjAYdvPX2Jwf1eMtYPrOK1490YxgT68qeTziuM28ybSpEaVT6PXjdaszMWyKV5nCnbgNy53P78boVp8+rHVRpnm3QOzTzVrdQT3luu7ewQfW1wl3vh6e/A2tvhBvuBX/luH4/IawmwZtwhvolEOuGSPugi+enjwAQrloEmJm34PAM2PqFdRzviWVf2K2UmTat8EvmTYhSUEoxuzaYrQ6tCnjyVpse7dKb1yul16IubKigudpPe07wlm3QWxMYdn9WX6eb6r52z8iDMQzY+mv48bmw/2m46jvwZ9/TyzuEcAh5NxLO0GC2C+nYCxWN2YtnJQ8B0B5YQCCVpi+WP/N2xoJ6AF7c38G8+pClQ4vE9PxNyCeZNyFK5ZcfO2vQtGkkT7VpZv/TK1bO5KHtLSydUUlDhZ/OSJxkKs0Tb53gO4+8BcCixjzr0s74KGz/Hfzhy3rD+txdEdJp2PWIzrQdfgFmr4V3/0h2ThCOJMGbcIZsr7fdMO/M7MUN/Qc4ZtTTnvRR3a9fzfOteVs+s4oqv4ctBzp579q5lg4tO20qa96EKJncD12V/vyZtwPtuinvpzYs4ZE3WjipuYrGSh+GoXu9ff7ul5lVE+RfrzmNsxbVD38St0dvZXXb+XD7xXDa+3SxVM8R2P2o/l4zT2fa1nwIXDI5JZxJ3o2EM9QthEAN7H8WTr8+e3F1335eTc+iPxynoWJwRVout0uxdkEdW/Z3WD60TMFCSNa8CTEp6kI+oklo64vRWDnQkuNAewS/x8WqOTXc++lzWTqjkmd2tQGw5UAH/Yk0n79k6egf4Kpmwkcfgk23wtbfQDIK/hpYfCFc/o+w8mpwD3+NEcJJ5GOFcAa3B5Zcqqct0npHA9Ipgt172GvMoiMcz26NNbRVSMb6hXXsPN5necuQcCyJ163wy8b0QkyKd66ehQJ+/sy+QZcf6IiwoCGEy6VYO7+O6oA3+6EuE8SdPLN67CdoXArv+j7cfAi+1gE3H4Rrf6kzcRK4iTIgwZtwjpOugHArHHtV/7z3CVzxHjalT6EzEqcnmpk2zZ8wXrdQT5Ns2T98j9SJiMRT0uNNiEm0pKmSdTPd3PncgeyHNtDTpvPrB69lazAzc8/sbsPjUiyZUUQPNrcXXPKhTJQfCd6Ecyy9DFCw60/655fvxAjWs9FYS0c4QU+/fhGvCeX/ZHz6vFpCPjePv9Vq6bDCsSQVUqwgxKR652IvvbEk/7VpPwCGYXDQzLzlaqzUmbfDnVGWNFVKhlxMCxK8CeeoaIQ5Z8CuhyHcDjseRK2+Dr9P756QnTbNU7AAEPC6uXj5DB7ZfpxU2rp+b+F4kpC0CRFiUi2odnPBskbuefEQ6bRBa2+M/kSahUOCt+qAF7dLb4O1YlaVHUMVYtJJ8Cac5aQr4MhL8F9XQzoBaz5IpRc6wnF6zOAtX8FCxhWnzqStL8ZLB6ybOg3HUpJ5E8IG16ydy5GuKFsOdGbbhMxvGDwt6nIp6s11byfPKmC9mxBTgARvwlnO+hSs/4Ru1rv4Ymg+hSqfotPMvLldatR+a5ecPAOfx8Uftx2zbEiReFLWvAlhg8tXNhP0uvndq0d40awkX5Cnj2OmaOHkmZJ5E9ODvCMJZwlUw1Xf1l+mCq+iIxynpaef2qAXpdSId6/0e7hwWSMPb2vha+9cOeptCxWOpZhdK93VhZhsFX4PV5zSzAOvHCGWTLNhedOwNW+A2U6klxWSeRPThGTehONV+RStvTEefeM4FyxrHPP2l5zczNHu/uw0y0RF4knZ11QIm7x7zRzC8RTzG0Lcet2avB/ImqsDNFT4mFHlz/MIQkw9knkTjlfpU/SalabvXjNnzNtnFi3vau1jYb4tcooUllYhQtjmgmVN/P07V/K2lc0jrnf9y7edxIfPXWBJpl2IciCZN+F4VV79gtxY6ef8pWNn3pbOqARg5/FeS54/Iq1ChLCN26X42PmLRt2zeE5tkFVzaydvUELYTII34XiVPh28vWv1bDzusU/ZqoCX2TUBdrf2Tfi502lDZ96kVYgQQgiHkOBNON6cSl1heu36eQXfZ2lzlSWZt2hC72sqmTchhBBOIcGbcLwF1W623XIFy4toA3DSjEp2t/aN2azXMEa/PhzXW3JVSOZNCCGEQ8g7kigLLldxC5GXNVcSS6Y53BlhQcPwogXDMLhj036+9fBbzKsLcfnKZr5w6TJ8nsGfZyIxM/Mm1aZCCCEcQoI3MSUta9ZZup3H+7LBWzyZpiMc581jPdz38mH+sPUY5y5pwKUUP3hiNy/u7+C2D55BXcVAT7dM5k2qTYUQQjiFvCOJKWmZWXG6q7WXy1bM4KdP7+ObD+8gkdLTpEGvm89fspQvX3YSLpfi/lcO89V7X+evfvMaP//I+uzjROKZNW/ypyKEEMIZ5B1JTElVAS+zagI8/mYrO1t6+d2rR7lsxQw2LJ/BwoYK1i2sI+AdmAp9z5q5HOmM8u1HdvLG0R5Wztad2vtiZuZNpk2FEEI4hBQsiClr1dwathzo5Pdbj/Gpi5Zw+4fW8cGzF3D+ssZBgVvGh85eSIXPzW1P7slell3zJpk3IYQQDiHvSGLK+s77T+erPf3MrQsNK0TIpybk5YazF/DTp/fy129bzvyGUE61qWTehBBCOINk3sSUVen3sLipsqDALePGcxaQNuCxHccBvbsCSOZNCCGEc0jwJkSOObVB6it87DimG/yGzYIFWfMmhBDCKSR4EyKHUooVs6p4s6UHgEg8icel8BWwLZcQQggxGeQdSYghTp5ZzVstvaTSBuFYipDPjVLFNQkWQgghSkWCNyGGWDGrmlgyzb62MOFYkkrZGksIIYSDSPAmxBAnm3uo7mjpIRJPEZLgTQghhINI8CbEEMuaK/G4FG8e6yEcT1Lhk2IFIYQQziHBmxBD+D1uljRV8sSOE7y0v5PZtUG7hySEEEJkSfAmRB4nz6rijWM9eNyKv71qhd3DEUIIIbIkeBMij9Vza3Ep+N4H1jC3LmT3cIQQQogsWYktRB4fPHsBl61oZn6DBG5CCCGcRTJvQuTh87gkcBNCCOFIErwJIYQQQpQRCd6EEEIIIcqIBG9CCCGEEGVEgjchhBBCiDIiwZsQQgghRBkp2+BNKfUZpdQ+pVS/UuolpdQFdo9JCCGEEKLUyjJ4U0pdC9wKfB1YA2wC/qiUmm/rwIQQQgghSqwsgzfgL4E7DMP4D8Mw3jQM4/PAMeDTNo9LCCGEEKKkyi54U0r5gDOAR4Zc9Qhw7uSPSAghhBBi8ijDMOweQ1GUUrOBI8BFhmE8lXP514AbDMNYPuT2NwE3ATQ3N59xzz33lHR8fX19VFZWlvQ5phs5ptaTY2otOZ7Wk2NqPTmm1iv1Mb344otfMgxj3dDLp/zepoZh3A7cDrBu3Tpjw4YNJX2+jRs3UurnmG7kmFpPjqm15HhaT46p9eSYWs+uY1p206ZAG5ACmodc3gy0TP5whBBCCCEmT9kFb4ZhxIGXgMuHXHU5uupUCCGEEGLKKtdp0+8CdyqlXgCeBT4FzAZus3VUQgghhBAlVpbBm2EYv1JKNQB/B8wCtgFXGoZxwN6RCSGEEEKUVtlVm06EUuoEUOoArxG9Lk9YR46p9eSYWkuOp/XkmFpPjqn1Sn1MFxiG0TT0wmkVvE0GpdSWfGW9YvzkmFpPjqm15HhaT46p9eSYWs+uY1p2BQtCCCGEENOZBG9CCCGEEGVEgjfr3W73AKYgOabWk2NqLTme1pNjaj05ptaz5ZjKmjchhBBCiDIimTchhBBCiDIiwZsQQgghRBmR4E0IIYQQooxI8GYRpdRnlFL7lFL9SqmXlFIX2D2mcqGUukUpZQz5asm5Xpm3OaqUiiqlNiqlTrFzzE6jlLpQKfU/Sqkj5vH7yJDrxzyGSqk6pdSdSqlu8+tOpVTtZP4eTlLAMb0jz3n7/JDb+JVS31dKtSmlwubjzZ3UX8QhlFI3K6VeVEr1KKVOKKV+r5Q6dcht5DwtQoHHVM7TIiilPquU2moe0x6l1HNKqatyrnfEOSrBmwWUUtcCtwJfB9YAm4A/KqXm2zqw8vIWequzzNdpOdd9Bfgr4PPAeqAV+JNSqmqyB+lgleht4r4IRPNcX8gxvAtYC7zd/FoL3FnCMTvdWMcU4FEGn7dXDrn+34FrgA8AFwDVwB+UUu4SjNfpNgA/As4FLgGSwKNKqfqc28h5WpwNjH1MQc7TYhwGvoo+r9YBjwO/U0qtMq93xjlqGIZ8TfAL2Az8x5DLdgHfsHts5fAF3AJsG+E6BRwD/jbnsiDQC3zS7rE78QvoAz5SzDEEVgAGcF7Obc43L1tu9+9k99fQY2pedgfwh1HuUwPEgRtyLpsHpIEr7P6d7P5CB8cp4M/Mn+U8tfiYmpfJeTrx49oBfNJJ56hk3iZIKeUDzgAeGXLVI+hPQ6Iwi8009D6l1D1KqcXm5YuAmeQcX8MwosBTyPEtVCHH8Bx0gLIp537PAmHkOI/mfKVUq1Jqp1LqP5RSM3KuOwPwMvi4HwLeRI4pQBV69qfT/FnO04kbekwz5DwdB6WUWyl1HToo3oSDzlEJ3iauEXADx4dcfhz9nyzGthn4CDq9/An0cduklGpg4BjK8R2/Qo7hTOCEYX5MBDD/3Yoc55E8BNwIXIqeRjkTeFwp5Tevn4nOggzdtFrOXe1W4FXgOfNnOU8nbugxBTlPi6aUOk0p1QfEgNuA9xiG8ToOOkc9Vj2QEONlGMYfc382F9PuBT4MPJ/3TkLYzDCMe3J+fF0p9RJwALgK+K09oyoPSqnvoqeSzjcMI2X3eKaCkY6pnKfj8hZwOnpK+X3AfyqlNtg4nmEk8zZxbehPLc1DLm8GWobfXIzFMIw+YDuwjIFjKMd3/Ao5hi1Ak1JKZa40/z0DOc4FMQzjKHqx8zLzohZ0Vr5xyE2n9bmrlPo39ML4SwzD2JtzlZyn4zTKMR1GztOxGYYRNwxjt2EYLxmGcTM6m/llHHSOSvA2QYZhxIGXgMuHXHU5g+e8RYGUUgHgZPTC0H3oE/7yIddfgBzfQhVyDJ9Dr+s4J+d+5wAVyHEuiFKqEZiDPm9Bvy4kGHzc56IXNE/LY6qUupWBIGPHkKvlPB2HMY5pvtvLeVo8F+DHSeeo3VUcU+ELuBZdrfNx9Al/K3rB4gK7x1YOX8C3gYvQi0HPAv4A9GSOH7psuxt4L3AqcA9wFKiye+xO+TJfLE43vyLA18x/zy/0GAJ/BF43X2jOMf/9e7t/NyceU/O6b5vHaSG6ZcNz6IxG7jH9sXnZZeg2Qk+gP8W77f79bDiePzT/ri9Br/3JfFXm3EbOUwuPqZyn4zqm/4IOxhaiW1Z9A115+w4nnaO2H6ip8gV8BtiPXuD4EnCh3WMql6+ckz8OHAHuA1bmXK/Q7USOAf3Ak8Cpdo/bSV/mi7KR5+uOQo8hUAf80nwz6DH/XWv37+bEY4puD/AwehFyHL2G6A5g3pDH8APfB9rRAeDvh95munyNcCwN4Jac28h5auExlfN0XMf0DvM4xczj9ig5LVOcco4q84mEEEIIIUQZkDVvQgghhBBlRII3IYQQQogyIsGbEEIIIUQZkeBNCCGEEKKMSPAmhBBCCFFGJHgTQgghhCgjErwJIaY0pdQtSqltRd5no1LqBxN4zl8opb5m1eNNhFLqBaXUNXY8txCiNCR4E0I4jlLqDqXUH/Jcvk4pZSilFhbxcJkdPCyllNqvlPrrPJefBrwb+Peci98L3Gz1GAr0/4B/UUrJ670QU4T8MQshpjTDMPoMw2ifxKf8PHCfYRg9OWPoMAyjdxLHkOt/gSrgHTY9vxDCYhK8CSHKmlJqpVLqQaVUr1KqVSl1t1JqZs71g6ZNlVIepdS/KaU6za9/U0r9WCm1cchDu5RSX1dKtZmP++1M9sq87QLgW2Ym0DAvdwPvR28vlDvGQdOmZtbu75RSP1FK9SilDiul/maM3/MWpdQ2pdSHzfuHzelZn1LqM0qpQ0qpdqXUd3OzbIZhpNAB3AeKOrBCCMeS4E0IUbaUUrOAp4BtwJnojbUrgQdGmSb8a+AjwMeBs9Gvg9fnud0NQBI4F/gc8CXgWvO696I38v5HYJb5BbAKqAG2FDD8L6M3rF4L/CvwTaXUOWPcZyFwNfBOcwx/DvwPsB54m/k7fR54z5D7vUAJpo6FEPbw2D0AIYQYwduVUn1DLhsakH0aeM0wjK9mLlBK3Qh0AOvQQctQXwT+1TCM+8zbfwl4e57bvWEYRqboYKdS6hPApcDdhmF0KKVSQK9hGC0591mA3hj8WAG/3yOGYWSycd9XSn3BfPznRrmPG/ioYRjdwDal1EPooGyOYRhx4E2l1LPAxcB9Ofc7CsxRSnkMw0gWMDYhhINJ8CaEcKqngJuGXHYqcH/Oz2cAF+YJ8gCWMCR4U0rVADNzLzcMw1BKvQDMG3L/rUN+PgrMGGPMQSBhGEZ6jNuN9/EPmoFbxnFgpxm45V429HGigAICQL5jJYQoIxK8CSGcKmIYxu7cC5RStUNu4wIeRE+FDnV8gs+fGPKzwdhLTdoAn1IqZBhGpASPn+8++S5zD7msHug3DEMCNyGmAFnzJoQoZy8DpwAHDMPYPeRrWHWnmbVqQa8RA0AppXJ/LkKc4UHSq+b3leN4vFI6FX2shBBTgARvQohy9kN0gcCvlFJnKaUWK6UuU0rdrpSqGuE+twJfUUq9Rym1HPgOuuDAKPK59wMXKKXmKKUaAQzDOIEOks4fzy9TQhcAD9k9CCGENSR4E0KULcMwjgLnAWl0cLIdHdDFzK98vg3cCfwCeN687H6gv8in/xp6ndwe4ETO5bejK1UdQSk1B10x+wu7xyKEsIYyjGI/bAohxNSilHoFeMYwjM9b8FgBYAfwIcMwnp7w4CY+nm8BNYZhDC3+EEKUKSlYEEJMK0qpBcAVwJOAF/gEuj/bJ6x4fMMw+s12JfVWPJ4FWtHZRiHEFCGZNyHEtKKUmgfcDZyGXjryBvD3hmE8YuvAhBCiQBK8CSGEEEKUESlYEEIIIYQoIxK8CSGEEEKUEQnehBBCCCHKiARvQgghhBBlRII3IYQQQogy8v8DKryC+ELzcI8AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4258, 1)\n"
          ]
        }
      ],
      "source": [
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "def percentage_error(actual,pred):\n",
        "  p_list = []\n",
        "  for i in range(len(actual)):\n",
        "    temp = (abs(actual[i]-pred[i]))/actual[i]\n",
        "    p_list.append(temp)\n",
        "  return sum(p_list)/len(p_list)\n",
        "\n",
        "# total predictions\n",
        "t=x_test\n",
        "t=np.reshape(t, (len(t),len(t[0]), 1))\n",
        "y_pred = model.predict(t)\n",
        "y_pred.shape\n",
        "\n",
        "# single prediction\n",
        "a=x_test[1,:]\n",
        "t=a\n",
        "t=np.reshape(t, (1,len(x_test[0]), 1))\n",
        "model.predict(t)\n",
        "print(y_pred[:,0])\n",
        "print(y_test[:,2])\n",
        "  \n",
        "\n",
        "# linear_mae = mean_absolute_error(y_test[:,2], y_pred[:,0])\n",
        "# print(linear_mae)  \n",
        "print(percentage_error(y_test[:,2], y_pred[:,0]))\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.title(\"Pressure vs Height(in m) for a day\")\n",
        "plt.xlabel(\"Height(in m)\")\n",
        "plt.ylabel(\"Pressure\")\n",
        "\n",
        "plt.plot(y_test[:300,2])\n",
        "plt.plot(y_pred[:300,0])\n",
        "plt.legend(['Actual','Prediction'])\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "print(y_pred.shape)\n"
      ],
      "id": "0cQSzrv08CoY"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def percentage_error(actual,pred):\n",
        "  p_list = []\n",
        "  for i in range(len(actual)):\n",
        "    temp = (abs(actual[i]-pred[i]))/actual[i]\n",
        "    p_list.append(temp)\n",
        "  return sum(p_list)/len(p_list)\n",
        "\n",
        "# total predictions\n",
        "t=x_fit\n",
        "t=np.reshape(t, (len(t),len(t[0]), 1))\n",
        "y_pred = model.predict(t)\n",
        "y_pred.shape\n",
        "\n",
        "# single prediction\n",
        "a=x_fit[1,:]\n",
        "t=a\n",
        "t=np.reshape(t, (1,len(x_test[0]), 1))\n",
        "model.predict(t)\n",
        "\n",
        "print(y_pred[:,0])\n",
        "print(y_fit[:,0])\n",
        "  \n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# linear_mae = mean_absolute_error(y_fit[:,2], y_pred[:,0])\n",
        "# print(linear_mae)  \n",
        "print(percentage_error(y_fit[:], y_pred[:,0]))\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.title(\"Pressure vs Height(in m) for a day\")\n",
        "plt.xlabel(\"Height(in m)\")\n",
        "plt.ylabel(\"Pressure\")\n",
        "\n",
        "plt.plot(y_fit[:600])\n",
        "plt.plot(y_pred[:600,0])\n",
        "plt.legend(['Actual','Prediction'])\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "print(y_pred.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "quIIMpf9p6EG",
        "outputId": "440aa0d6-5316-42bc-b5a7-f2eee628db30"
      },
      "id": "quIIMpf9p6EG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "294/294 [==============================] - 2s 5ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "[72.46946   73.785484  74.904076  ...  9.2152405  9.60257   10.118138 ]\n",
            "tf.Tensor([74.49 74.69 78.21 ... 13.17 12.9  12.6 ], shape=(9389,), dtype=float32)\n",
            "tf.Tensor([0.17927836], shape=(1,), dtype=float32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAHFCAYAAACkWR6dAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAD0E0lEQVR4nOydd5hkVZ2/33Mrp85hcg7ADBkkyxBUFPOCukbUFV0XWfOafophzYphTSiCOYERAUFhyGGGPEwOPbFzd3XlfH5/nHurq6qru6tzdfd5n6ef6rrx1L1V937uNwopJRqNRqPRaDSa2YEx0wPQaDQajUaj0VSOFm8ajUaj0Wg0swgt3jQajUaj0WhmEVq8aTQajUaj0cwitHjTaDQajUajmUVo8abRaDQajUYzi9DiTaPRzFuEEDcLIdrGue51QggphFgwCeM4QwiREUKsnYyxTRVCiC1CiK+OYXlDCPFFIcQhIUROCPHnKRzelGGe5+tmehwajYUWbxpNAUKIq8wLtfWXEUIcEULcJIRYPNPjm48UnJOzh5l/W7WJnFKEEJ8QQrx6hEW+CNwqpdwzTUMaL18C/msMgvWNwMeBvwJvA66fqoFpNPMJ+0wPQKOpUq4D9gFu4DzgrcCFQoiNUsrYTA5MM6m8i+l5iP0EcAvw59IZQoiTgRcBF5fMmq6xjYU/AyHgv4D/V8Hym4B+KeU1UzgmjWbeUW0XBo2mWviHlPKXUsqfSCnfDnwLWAm8argVhBC+6RrcZCGE8M70GGYSKWVaSpmc4WG8A+gE7iucWCVjK0JKmUOJ0LcJISq5f7SgxN6kIBSeydqeRjNb0eJNo6mMe8zXlZCPR0oIIVYIIf4qhAgBf7cWFkK80YwPigsh+oUQfxBCrCzcoBBijRDi90KIdiFEUghxTAhxqxBiYcEylwgh7je3ERNC7BNC/F/BfMuluKJk25vM6ZsKpm0WQuwUQpwihLhXCBEFvm/OE0KI9wkhnjM/V5cQ4kYhRNNIB0UIcYW5n0vKzHtz4RiEEK1CiJ8IIQ6bn7dTCHGHEGLDSPsYLxWegyFxZUIIjxDiO0KIHiFE2Dy/S0aIe6o1txMUQgyYLnZvwfYk4EMJHssdv7lg/VcD95jCaLSxSSHED4UQrxZCbDOP4/NCiMsqOB4rzPU/JoR4rxBiv/md+qcQYrn5HfiEeX7i5ucud/7vBpYCp4+2L+AVwPKCz73JnO8VQnxNqFi4pBBijzkuo2Q71ud9vRDiOSAJvH6E/Z5kHv995ve4RwjxWyHEstGOj7m+SwhxvRCiu/Dcl1luuRDie0KIHeYxDArlvj+xYJkac953yqzfKIRICSG+Usm4NJpStNtUo6mM1eZrb8E0A7gLeBz4CJABEEJ8DBXDdAtwE1APXAM8JIQ4WUrZLYRwAP8APMD3gHZgIXAZsAhoF0KcgBKEz6HcuDFzHC+ZwOeoM/d7K/AbIGhO/wHwTuBnwP+hbs7vA14ghDhTSpkYZnt/B8KoG+q/Sua9HjgG3G++vwU40dz+AaAZuBBYBzxfwdhrhxETjtIJlZyDEfZzM/A64JfAI+YY/z7C8r8F9qNiu04D/gPoAv7HnP8W4Ceo78kN5rROc5yLgWXAt0fYfinnoETRD1DH/lrgViHEMill74hrKt4AuFDnoR74KPAH4E6U+/arqO/ZtcA3USEDhTxhvp4HbBlmH92oz/0hYAnwAXP6DiGEQLlfXwT81NzeJah4uhXAe0q29ULgCnO8HcDOET7bi4D1wM9R373V5vZeICoLefgJ8Gbg18DDKLdvuXN/pjmuW4BDqN/su4H7hBAbpJTtUsqQUAkarxdCfFBKmSlY//Wo7+3PRxmPRlMeKaX+03/6z/wDrgIkSiA1oW48rwd6UOJpsbnczeZy3yxZfxmQBj5dMn01kAC+aL4/2Vz/ihHG8t/mMk0VjHdFyfRN5vRNBdM2m9OuLVn2XHP6W0umn29Ov3qUY/ZL8/jYC6bVoawk3yp4L4EPT+CcjPTXNtZzUHAeC9c9zdzed0vWvcmcfl3BtOvMaT8tWfaPQE/JtAhwc5nPdom5jVeXmVc0NnOaBFLAmoJpJ5nTrxnlOK4wl+sB6gqmf9Gcvg1wFEz/tbkvT5ltJYEbKjh3t5X5DK809/eZYY7xxpLPmwNOqfC74i0zzfp+v3mUda3f5PdLpv+8zLkvd0xWmd+vTxVMu8xc92Ulyz4MPDnW34L+03/Wn3abajTluRNlPTiMsqx0Aq+QUh4tWe77Je9fi7Jo/04I0WT9AQMoC9pF5nJWHNBLxPCxcgPm66tL3UkTIMOg9cfidShxcWfJmHeiPvdFjMxvgUbg0oJprwGc5jyAOEoIbBJCNIxz7NeiLCulf4+VLFfpOSiH5X4sPa/fHWGdH5e8fwBoFELUjLCORaP52l/Bshb3Sin3Wm+klM+ivk+rKlz/VillsOC9dfx+KaVMl0x3oKywpfSjHm7Gw+UoQVZqbfxGwfxCHpZSPl3JhmWBZU0I4RdCNAK7URbmYd28Ji8zX/+vZPoQt6eUMl6wH6+5nxCwq2Q/d6Os6m8pWH4Vynr6i1HGo9EMi3abajTluRbYgXqSPgQcllLKkmVyQFvJtHXm63Cunf0AUsoDQohvAh8E3iyEeAj4G+oGarm+fodyZf4Y+LIQ4h6Uu+n3stgFMxaOyaEu0HWAH9OVV4aWUbb5D9TN/A0o0Yv5f5uU8lEAKWVSCPE/wNeBTiHEY8DtwC+klIcrHPsWa3uFCCHeDxSWrqjoHAzDcpSlZF/J9L1llrU4VPLeEmL1VB6sLypcrtz+rH3Wj3N96yGh9DxY08ttV6CO03hYDnSWCEhQwieHshAWUnouhkUIUQ98GeVmLX1IqK1gXJKh53p3mf24gc+hXKwLS2bnXddSyqwQ4peo8ioBKWXYXCeLClvQaMaFFm8aTXnKCoUS0mVElGUheylmDFwJ+Sd2KeWHhBA/RbmRXoyyPHxKCHGhlHK7lDIuhLgQFVvzMpQr91fAB4UQF5hP/8PdQG3DTI+XmWagbjhvGGadEa1CUsq0EOKPwBVCCCdQgyp78Y2S5b4lhPgLKmP3RahSE58QQrxcSrl5pH2MkYrPwSSRHWZ6JYKsx3ytVHhNdH8jrT+W7dYxOPapZizn6/eoWLxvAE+hYgIlygI8mZ6m76KyhL+LcoEGUcLzW2X283NUTOxrUTGlbwLullJ2TOJ4NPMMLd40msnFshIcklJuH21hKeXzqGD9LwkhTkIFb38AVeMLqTIQN5t/HxVC/CfKpfdalJCzhFVdyaaXj3HMLwIelVJGxrBeIb9FWQkvQ1ki7Ay6TPNIKQ+gbnDfMrP4ngY+ifp8k8WYzkEJB1FiZTXK8mqxZoJjGk5kW/tYOcz8qsNMsnBSfHzGwkHgRUKIWinlQMH0dSjh0zbOcdWjXPfXSSk/WzDdTWXi2Dr3a4DC7826MsteCfxcSvn+MmMoErVSym1CiCeBtwghdpjb+ywazQTQMW8azeRyK8qC8Wkzq64IK1vSLCNQ+vC0A2VlqDOXaWQoT5qvdearJVReWLAPG3D1GMb8O9S14NNlxmszb0ijcS/K7fp6829nYZySGRdUVJ9LSnkElZVZN4axVkJF52AY/mG+vrdk+vsmOKYoZQSElLIdlXl7xgS3P51YMV0Pj3P921Dft2tLpn/QfB0ps3ckLMth6Tn/AJXd6+4wX0sLCpc799nS/Qgh/h2VdVqOn6FiLT+Ksgb+qYLxaDTDoi1vGs0kIqXcb5ap+BqqvtWfUS4Vq8Dv71BZihcD3xNC3IKK9REo0RMwlwH4f2ZdrL+jrBH1qLIHUdQNECnl80KIR1GWuwagD+X+rPi3LaW8XwjxPeAjpvXvH6hswjWo2KFPozIfR9pG1vwsb0d1pfh8ySLrgHuEEH9AWRqTKFfw8cCHKx1rJYzhHJRb9wkhxK3ANUKIWuBRBsuZwPjjvLYClwohPgwcAbqklFbtwL8A/y6EMGRJrbcq5UWoz7B1nOvfhgrk/6wQYjnqgeRi4N+AH0kpt41no1KV5tiMslA7UZa081Hnb9QSKlLKp4UQvwH+0zz3D6EEVznL21+BtwpV33EbcArq9ztcPOVvUPGe/4bKOp5s171mnqHFm0YzyUgpvy6E2IOyJHwK9dR/BFXo9w/mYs+gnvRfhnKRJlCi5tVSyr+Yy/wFVfbibaiaaL2oumOfk1IeLNjlm4AfAR9DiZQbUZawu8cw5mtM1857gP9FxYodQsUQ3TPSugX8FtU2yfq/kMMoN+8lqH6XEhUI/k4p5U8rHWelVHgOhuOtqHpi/47Kmv0n6sa8C3WexsMHUOfoOlTB3vsYPK4/Bd6PEhn3jnP704KZ9XwFqjzKuISmlFIKIV6Dch2+AXW8D6FaiFXc9H4Y3ojKYn03KlP2fpQw/GeF678DlWX+JpTQvweV/VqazPHfqHI0r0eFC2xFhQx8rdxGparteAcqvlVnmWomjBiaQKfRaDSaQoQQp6AC4N8spfzVFGz/H0BQSjls94BqQAjxWlRdv9Wmy1dTIabV+Wxg+SyxsGqqGB3zptFoNAWUxuaZvB+VTXh/mXmTwSeBfxNCrJ2i7U8WHwf+Twu3sSGEaMG0umnhppkMtOVNo9FoChBCfAYVlH8vyn38UvPvBinlu2dybJrZhVC9dM9DuWPPAdaaiToazYTQMW8ajUZTzMMM1qHzo+KxrkPFAmo0Y+FCVNuvw8BVWrhpJgttedNoNBqNRqOZRcwry1tTU5NcsWLFlO4jGo3i8w3XqlIzHvQxnVz08Zx89DGdfPQxnVz08Zx8puOYPvHEEz1SyubS6fNKvK1YsYKtW8dbmqgyNm/ezKZNm6Z0H/MNfUwnF308Jx99TCcffUwnF308J5/pOKZCiIPlputsU41Go9FoNJpZxLSKNyHEC4UQfxVCHBVCSCHEVSXzhRDiOiHEMSFEXAixWQixoWSZeiHEL4QQA+bfL4QQddP5OTQajUaj0Whmium2vPlRrUT+G9XDsZSPAh9C9ZI7E9X38G4hRKBgmV8Dp6GqWV9m/q8rVms0Go1Go5kXTGvMm5TyduB2ACHEzYXzzAbS7we+LKW81Zz2NpSAeyPwIyHE8SjBdr6U8hFzmXcDDwgh1kspd03TR9FoNBqNRqOZEaop5m0lsAC4y5pgNu+9HzjXnHQOEEHVYbJ4CNWo+1w0Go1Go9Fo5jjVlG26wHztLJneCSwuWKZbFhSnM5scdxWsX4QQ4mrgaoDW1lY2b948mWMeQiQSmfJ9zDf0MZ1c9PGcfPQxnXz0MR3EZrPh8/lQDqrxUVNTw1NPPTWJo9JM9JhKKYlGo2Sz2TGvW03ibUqQUt4A3ABwxhlnyKlO69Xp2JOPPqaTiz6ek48+ppOPPqaKUChEZ2cnixcvxuPxjFvAhcNhAoHA6AtqKmYix1RKSTwe5+jRo7S2tlJTUzOm9avJbdphvraWTG8tmNcBNIuCb6/5f0vBMhqNRqPRzAm6urpYvHgxXq93QpY3TXUhhMDr9bJ48WK6urrGvH41ibcDKAH2ImuCEMINXMBgjNsjqIzVcwrWOwfwURwHp9FoNBrNrCedTuPxeGZ6GJopwuPxkE6nx7zetLpNhRB+YI351gCWCSFOAfqklIeEEN8CPiGE2AnsBj6FSlD4NYCUcocQ4k5U5unV5nZ+BNymM001Go1GMxfRFre5y3jP7XRb3s4AnjL/PMBnzf8/Z87/KnA98D1gK7AQeLGUMlywjTcCzwD/MP+eAd4yHYPXaDQajUajmWmmu87bZmBYmWlmkV5n/g23TD/w5kkemkaj0Wg0Gs2soJpi3jQajUaj0WimlOuuu46NGzfO9DAmhBZvGo1Go9FopoQnn3wSm83GeeedN6b1Nm3axDXXXDNFo5r9aPGmGRkpYeAIZDMzPRKNRqPRzDJ+8pOf8N73vpdt27axY8eOmR7OnEGLN83wZDPwh6vg+g3wg3Mh1jfTI9JoNBrNLCEej/PrX/+aq6++miuuuIIbb7yxaP6jjz7KxRdfjM/no7a2losvvphjx45x1VVXcd999/G9730PIQRCCNra2ti8eTNCCHp6evLbaGtrQwjB1q1bAchms7zzne9k5cqVeDwe1q5dy1e/+lVyudy0fvapZs53WNBMgKd/Cdv/DKdfBU/9Cm7/MFzx05kelUajMUlmsrjstpkehmaa+ezfnmf7sdCY1slms9hs4/+unLCohs+8YsOY1rnllltYvnw5J554Im95y1t43etex5e+9CUcDgfPPPMMF110EW95y1v45je/icvl4v777yeTyfDtb3+b3bt3c9xxx/HFL34RgObmZtra2kbdZy6XY/Hixfz+97+nubmZxx9/nKuvvprGxkbe+c53juejVyVavGnKIyU89iNYcCK8/FvgqYeHvg2XfAbql8/06DSaec+O9hAv/fYDrG8N8Lf3nY/Trh0pmurixhtv5C1vUZW8LrzwQrxeL3/5y1+44oor+OpXv8opp5zCDTfckF/++OOPz//vdDrxer0sWFC2bfmwOBwOPve5z+Xfr1ixgieffJLf/OY3Wrxp5gHtz0DXdnjFd0AIOPNd8PB3YetP4UWfnenRaTTznj1dEQB2dYY5Goyzssk3wyPSTBdjtYDB9Pc23bt3Lw8++CC//vWvAVWM9k1vehM33ngjV1xxBU899RSvec1rpmTfP/zhD/nJT37CwYMHicfjpNNpli+fW0YHLd7mMLmcpD+WotHvGvvK++5Rr+tfql5rF8OqTbDjr3DpdUrQaTSamUFKFm77EX92/o0Pp99Nx0BCizdNVfGTn/yEbDbLsmXL8tNUKVc4fPjwuLZpGEbRdoAhraV+97vf8f73v5+vf/3rnHvuudTU1PC9732PP/3pT+PaZ7Wi7exzmJsfbuP0L/yTQ72xsa+8/15o3Qj+lsFp618GffuhW3ci02hmlAP3ceaeb3GKsY/vOL5HVzAy0yPSaPJkMhl+9rOf8aUvfYmnn346//fMM89w0kkncdNNN3Hqqadyzz33DLsNp9NJNpstmtbc3AxAe3t7ftrTTz9dtMyDDz7IWWedxTXXXMNpp53GmjVr2Ldv3+R9uCpBi7c5zBMH+wHY0jbGLNFMEg49pixtJvu7IxxuNt/vvmNyBqjRaMbH1puI2Wr4VO5qTjAOsvnuv/Czh9tmelQaDQB///vf6enp4V3vehcbN24s+nvDG97ATTfdxIc//GGeeuoprr76ap555hl27drFT37yEw4dOgSoWLXHH3+ctrY2enp6yOVyrFmzhqVLl3Ldddexe/du7rrrLr7whS8U7XvdunU8+eST3HHHHezZs4fPf/7z3HfffTNxGKYULd7mMEsaPAA4n/89PPnzylfs2g7ZJCw5Iz/p4m/cxwU/3Ml+sYznHvgLf3rqCIf7xmHR02g0EyOdgF2384jvEp6tu5SEdHBy5AE+89fnZ3pkGg2gEhUuuugiGhsbh8y78soraWtro7u7m3/+85/s3LmTs88+m7POOovf/va3OBwOAD784Q/jdDo54YQTaG5u5tChQzgcDn7729+yf/9+Tj75ZD7zmc/ks1Et3v3ud/O6172ON77xjZx55pm0tbXxoQ99aFo+93SiY97mMOmM5Eyxk1fs/xzsB057a2UrHntavS48hd2dYf701NH8rHvTG3iT/BdX/G4LSZxce/EaPvji9ZM+do1GMwwdz0I2xVaxEZ+vlkfCp/JitnJd5m0zPTKNBoC//vWvw85btWpVUcza/fffX3a5devW8cgjjwyZfu655w5xlRZuz+l0cuONNw6pKffpT386//91113HddddN9JHqHq05W0OE01m+DdbwQ8j2jP8woW0Pw3uWqhfwQd//zQ/2DwYL7DXfwZuUtz5WhenL6/ntmfbh9+OZkq4Z2cnf3rqyEwPQzNTHNkCwOPpVTT6ndybOp5Foo9F9M7wwDQazXShxdscJpLMsN7ROTih49nKVmx/BhaeDEJgMwa/Ii0BF2df9Aow7KwMbWFda4BQQrfNmk4GYmnecfNWPvC7Z8jmBp82ifXBlp/APz4Jj/4QIl0zN0jN1HL4cahdxu6Yj0afk6dyawE4xdg7wwPTaDTThRZvc5hwMsMKOjjQtAmAxJGnR19JSpVN2qLqCPmcgxW5//Rf5/Gqs9bD4jNg/2YCbjuRZHq4LWmmgF8+djD/f77C+u674Lunw98/BFtuhDv/h8z1J/HxT36QrlBihkaqmTI6niW78GTCiQyNfhfvf+OrSUoHp9u0eNNo5gtavM1hsrEB6mU/8ZbTOCYbSB3dNvpK4XZIx6BxNQCdBTf/hTVu9c+qTdD+NE1GjEQ6Rzo7t3rGVTNPHw5S61EBvQ/t61HC7TdvgNolcPVm+GQ7/NcWttmO50uOG4nf85WZHbBmcsmkoP8gsdo1ADT6nVxy4lJ6a4/nJLFX/xY1mnmCFm9zmLqEKoTobF1Lh2wgE+ocZQ2g13x6b1yDlJL2gQTrWwN8+uUnYBhmYd5VF4LMsTr+NAAR7TqdNnZ2hLhgbRPLG70cPbALbn0ntG6At98Oi05VxZOb1/G/dZ/j1uz5LH/6m7DtjzM9bM1k0X8AZJYelyp8urBWPVAFA+tZL44QS+rfokYzH9DibQ7TmFTirWbxcfTKmsoSFnr2qNemtYSTGWKpLFecvoR3nL9ycJnFZ4DDx/Lg4wCEtXibFsKJNIf74hy/sIY6j4MrOr4JuSy8/pfgKm57k5IGH0tfTajpVPjb+yGkE0vmBObv87FQAwCL6lQ5oEjtempEjGTf+CrXazSa2YUWb3OY+nQHAA2L19BHDY5kBdlovfvA7uHnz6f42K0qwWGB+XSfx+6EFeexsPdRAMI67m1a2N0ZBuC4BQFeIJ/j5MQWuOgTUD+0Z18mmyONnWfP+LKq2fePj0/3cDVTQa8Sb194VP3mFtYq8ZZsWAdAtkPXetNo5gNavM1RpJQ0ZntI2PzYPTUknA14U30qIWEkeveSa1jFp/+6g9ufU+JvYal4A1h9Mb5IG8tFh7a8TRO7OlQLpHWtAa6M/JJu0QRn/kfZZTNZdZ573Uvh3Gvh+T/BkSembayaKaJnL12yjghefE4bNW5VqjPdeBwAomvHTI5Oo9FME1q8zVES6Ryt9BFztQKQcjViIwuJ4Mgr9u4lUaNcpNdevIbPvnIDpy6rH7rcussAuNR4Use8TRMHe6M47QaL47tZl9zG7xyvBEcZYQ1kcipwPZrMwnnXgqcBHvj6dA5XY7K3K8LFX99MTyQ58Y0FD3JQqn7DhiEQQsWhOv2NdMh6bL2677BGMx/Q4m2OEk6maRV9xL1KvGU8TWrGSHFvmRT0tzHgWwHAqcvqedu5K7BZiQqFNKwk1XCcEm86SHrCbG3r496d5WuzDcTSJDNZ2nqjLGvwYjx5Eynh4tbshcNuz6oBF0tlVDzcme+EXXcot7hmWvnOv/awvyfK/bu7J7wtOXCYY1L9lgst3h6njQO5hTgHDkx4HxrNbOOWW27JP8gA3Hzzzfj9/gltc/PmzQgh6OmpsLj9NKPF2xwlksiwUPSR9i5UE3yWeBvhBhI8qDLZnEsBaA64RtxHeu1LONPYSTJUnV/u2cR379nL/95e3uV18ufu4k0/foyDvTHWNNjh+T+xs+EiOtPlrW4A6awl3rJqwpnvApsDHvvhpI9dMzJHg3EAWmuGP18VkcvBwFGOmuLNaRu8fHudNtpkK+7wweHW1mimnauuugohlIXY4XCwatUqPvzhDxONRqd0v69//evZv39/xcuvWLGCr3+92DNx7rnn0t7eXrY/azWgxdscJRpP0MwAWb8Sb4av2Zwxgngzy4QctS0CRhdv9uMvxy5yNHTcN/EBz3NCiTT90dSQ6VbPvq0H+2nrjXKRfRskBtjbehmxVJZcrnwMYyylrDJR85VAK2y8Ap76JfZ0ZGo+hKYsx0zxJsoYsMdEpBORS3NMNrKswctv3312fpYSbwtwJXshEZrgjjSTwbpP3sF3/rVnpocx41x66aW0t7ezf/9+vvCFL/D973+fD3/4w0OWy2QyRT1KJ4LH46GlpWVC23A6nSxYsKDIoldNaPE2R0kGj2EIiaxRQsxRo77I6fAIbZNM8XZAKsHX4HOOuA/nsjPoknUs6dTibaKE4mn6Y6khYiyRzhX9f3rsQXDX0tt8DgDxdHbItqSU+bZlsWTB/LPeDekYLV0PTMEn0AxH+4AqdJ0dRmhXzIAqA3JENvGxlx7HaQWxqF6nnTapQiToq9zioJkaBmJpUtkc37x790wPZcZxuVwsWLCApUuX8sY3vpE3velN/PnPf+a6665j48aN3HzzzaxevRqXy0U0GmVgYICrr76alpYWAoEAF154IVu3bi3a5s9//nOWL1+O1+vl5S9/OZ2dxTVMy7lNb7/9ds466yw8Hg+NjY284hWvIJFIsGnTJg4ePMhHPvKRvJUQyrtN//jHP3LiiSficrlYunQpX/va14oE54oVK/jCF77Au9/9bmpqaliyZAlf+9rXJvuQAmCfkq1qZp7QMQCEKd7cdcrylgh24RhunZ494G3kSMJNg8+JwzaytheGjQfE6VwefFjFy9lHFnua4QklMuSkimOq9Q6eoXCisAyLZFn/Y7DqItweVSIimsrgcxX/jGOpbEHMW4F4W3gytGxgQcc93PzQAXKS4vp9miklM0ni7ZhsIuAuPudep42DcoF607cfFp0ysX1pJsTBPuUWtLqhTDp3fAw6nhvTKp5sBmwTuOUvOBFe+uXxr2+Nw+MhnVbXtQMHDvDrX/+aP/zhDzidTlwuFxdddBG1tbXcdtttNDQ08LOf/YyLL76YXbt2sXDhQh577DGuuuoqPv/5z3PllVdy77338olPfGLEfd5555288pWv5GMf+xg33XQTmUyGu+66i1wuxx//+EdOPvlk3vGOd/Cf//mfw27jiSee4Morr+RTn/oUb3rTm9iyZQvvfve7aW5u5n3ve19+ueuvv57PfvazfOQjH+GOO+7g2muv5fzzz+ecc86Z8LErRIu3OYowxZutbjEADQEfYekhFR6h1lvvPmhcQ08kSZO/MiH2uOss/i35Lzj4IKy+eMLjnq9YIq0vlioSbyFz+uUnLeSaDSmcf+qENZfgQ/WcjSWzUFyfN78ODLpPAeW3O+XfqbnrUzzwyCMctS/R4m2KiReI52x2ouLtCADHZCMBd7Eo8Dhs+SxUbXmbedp6YwC01owcejLfePzxx/n1r3/NJZdcAkAqleIXv/gFra3KanzPPffw9NNP093djcd8QP385z/P3/72N37xi1/w0Y9+lG9/+9tccsklfPKTnwRg3bp1bNmyhRtvvHHY/X7+85/niiuu4Atf+EJ+2kknnQSA1+vFZrMRCARYsGDBsNv45je/yYUXXshnP/vZ/H63bdvGV77ylSLx9uIXv5hrrrkGgPe973185zvf4V//+pcWb5rKsEVURX173RIA6r1OQnixx/qHX6l3L6y5hO5jyVHj3Sx2uE8jlXLi3H2XFm/jJJXJ5d2jfdEUK5t8+XkDcSW+rjx9Ccf3/k5NXH0x3sPqpxtNDc30DcUHp0VTJW7VE69E3vVpXhC+i+8bb5zMj6Epw4GewcDs7ETjecIdpG1eIniHWN4MQyAdXsKOZgJ9OuN0pjlonvdKr6NjZhwWsHg4TCAQGH3BSebOO+/E7/eTyWRIp9O86lWv4rvf/S7f//73WbJkSV64gbJuxWIxmpubi7aRSCTYt09lyu/YsYNXvOIVRfPPOeecEcXbU089xVVXXTWhz7Fjxw4uv/zyIfv98pe/TCgUoqamBhgUhRaLFi2iq2uEcKVxosXbHMURbScmXbgDqo1Og89JSPqojw+UXyEZhkgHNK6ha1eSM5aXqe1WBpvLy27nBja26Tiq8WJZ3WqIMDAwANQPmRdwO2DfPdC0HmqX4OtSiSexUnEG9BbUE4uXirvAArrqTuHy/gf4UvwKYqkMXqe+DEwVOzsGkwcmHPMW7SbhbIAoQ8QbqLi3HudiAn26HMxMY1neNPDCF76QG264AYfDwaJFi3A4Bq3GPp+vaNlcLkdraysPPDD0fmKJo2qkMKmh8PNZ83K5XOkqE0YnLMxRXPEO2mUDXjMeqt7nZADf8EV6zWSFbMNqOgYS+Z6Jo+Fx2HjWcRJ0bqusd6pmCFZywRbXezn97n8rO6/OkYaDD8Ma5W6wBFe0TI09qzTF2ha/KtJbwq6a81gietgoDtBhBtNrpoadHeH8/xOOeYt0EXGoh7Ea99BYKr/LTod9kXabVgGHzJi3eJmHq/mG1+tlzZo1LF++fIiwKeW0006js7MTwzBYs2ZN0Z+VPXr88cfz6KOPFq1X+r6UU089lX/961/Dznc6nWSzI5+r448/noceeqho2iOPPMKSJUtmxKKpxdscxRPvokM24Lar2Kg6j4OQ9GJPDmN5M4u39ruXkcnJMYm3J4wT1RttfRsXoXiaxXTjEhlqw3uhvy0/z7K8NfQ8CZkErFbizW+K8nKWN0u8rW72F8e8mTztPJ2sFLzYtlWLtylmR3sof66GK+tSMdEewrY6nDYDt8M2ZHZLwEVbbgFEOiGpy8HMJF1hZf2Opyff4jKXufTSSznvvPN41atexR133MGBAwd45JFH+MxnPpO3xl177bX885//5Etf+hJ79uzhxz/+MX/6059G3O4nP/lJ/vCHP/CpT32K7du38/zzz3P99dcTiykL6YoVK3jggQc4evTosEV5P/ShD3Hfffdx3XXXsXv3bn71q1/xf//3f3z0ox+d3INQIVq8zVF8yU66RQOG2R3BZggGpA9nJlx+hd69gOAQKmBzcYXize20sS23AmwuODKYzp3O5njjjx/l91sPT+RjzAvCiQzn2LYPTnj29/l/rfg1/5H71DFefi6gsgthGMtbf5yWgIs6r2NozBtwJOXj8dzxvMTYym3PtesOGVPIzo4wGxYpd8+ELW/RLoKirqzLFKClxsXutFmMu1/Hvc0kfRFVszFRppSPZniEENx+++1cfPHFvOtd72L9+vW87nWvY9euXSxapConnH322dx444384Ac/4KSTTuKPf/wj11133YjbfdnLXsaf/vQn7rjjDk499VQuvPBC7r33XgxDSaDPfe5zHD58mNWrVw+Jt7M47bTT+MMf/sCtt97Kxo0b+djHPsYHPvCBfHLCdKODXeYiuRyBVDd9tsHsFiEEA/hwDyfeevZA3VKORtQNZiyWt0jGpspQFIi3joEED+/r5eF9vRy/oIYTl9SO//PMcUKJNOcY2+mVAaSrhqaCEgDhRBqHTWA/cC8sPwecXoB8eZDhLG+L6z14nfaybpueuGSzOJOPGz/j4ccf48aAm/++dO0Ufbr5RSqT46lD/Zy1qpGBWJrucJLLT1zIYwf6yE4k7iWXRcZ6eTbmpLm2fBB8S8DNYwN14ILt257mhAUnjn9/mnGTzGQJmw9E891tevPNNw8777rrrisrugKBAN/+9rf59re/Pey6b3/723n7299eNK1QRF111VVDEhRe+cpX8spXvrLs9s4++2yeeeaZommbNm0aUjT4ta99La997Wvz78PhcFG8W1tb25Btb968edjPMRG05W0uEunERpY+W/ETRBgfzlwMsumh6/TuhcY1+Wrwi+oqa+XjcdhUodglZ0L70/ltFzbhfvpIcFwfY74Qiqc5QRxkG2s44lgB3TsH5yXSrHKFEN078i5TKLC8lXGLHgvGWVznweeyEU0NVi3f0xkml5P0JyU76l4IwIuNrcTS2vI2WdyxrZ3X3/Aoh/ti7OtRrst1rSoeZkKWt1gfQuboE7V8/cqTyy7SUuPiiFS/+SNtukH9TNFndkpx2oyyRbQ1mslAi7e5iJl80OVcUjQ5LMzMntL2OVKaNd7WciwYp8ZtH1JHajg8Tpt6ulxyuorJ6tymhhAZbPXU1jO1fexmO5FYnFXiGMecKzlsW67ORUaJ31A8o1piQVEpFpfdwGk3CMaKhXguJzkWTOQtb1KqzgwdAwledP39fPTWZwkmJKJuGfH643ih8SzpzOS0pNFAZ0jFEHaFk+zrUuJt/QJV6X0iMW993UfVtlavYuPi8lbsloCbED5C0ssCOfmlCTSVYV37ltR7tNtUM2Vo8TYX6VEtWbpdy4smhzDbhZRmnEa6IBWGxjXs6YqwuN5b8a7cpuVNLj5DTTBdp5blrcZtL6p1pRmKLXgAl8jQ7VnFAWMpyGxegIcTac7lGfAvgNYN+XWEECxr8HLfrm6u+MHDPH9MJaLs74mQyuZY2ejLW+diqQzdZgD1LU8coSOWo7XGhWf9xZxh20Myrs/PZNFviulgLMW+7igOm2B5o3pomojlbcde9X04cf3w7m2rIOxR2YQ/fmzc+9JMDMvytrjeQzKTm3iiikZTBi3e5iI9e0gINzFXcWPeKKblLR4sXr5XNU8Oepfx6P5eLj6ufMBmOTxm1lvStxh8LUPE25krGrTlbRRsPcrF1e1dxV6xTE3sfJ5oMsPuY/2clnlKWd1KGiSvaPSxqzPM1oP9XP6dB7nliSPct1tlSp23pqlAvGWL2mzFM9Ba44aVF+ImRctAcayHZvxYltD+WJp93RFWNPpw2tVldiJ13rIhVdevoXnRsMu0BFSowxHZjE+LtxmjN6qufVbSVyKjrW+ayUeLt9mAlHB4C2z/q7KSjUbPbo4Yi/GU9LwcdJsGi5c3rTx3d/rJSXj1KYsrHprHob5C8XQOlpwBRy3xliLgtrN+QYBDfTEyWZ0yPxze/p3kEPR7lrMnuxgcPjiyhZ88cICV0afw58Jw/MuHrLeyadBCesLCGj77t+e5b3c3q5t9LG3w5pMaoqlMUcssgJYaNyw/lywGK8JPTu0HnEcEY8rqsqczzOMH+li/IIDdzPieUJHeqPrd+xpHEm/K8nZENlGT7FDXDc20Y7lNLfE2GUkLU1HkVVMdjPfcavFW7aSi8OvXwY2Xwu/fAt88AR68fuQLc88eDoolecuLRViYhQTLiTebi3vbXSxr8LK2tfKCgx5zHypp4Qy1rVgf3ZEkzX4XKxp9ZHKSdl1PbFjWxp7gqHs9dpePaAYVP3j4MXa0h/h33xPg9JdtPbbCbKO1vjXAq05ZRDiR4dH9vZyzuhEYPDexVLaoZRZAa8AF7hoO21eyMvH81H7AeUS/Kd5+dP9+Euks7790HTZTvE3EbWrEekhLGw7v8J1P6n1OPvvKDXQaLXhy0eELcmumlL5oCrshlHUbJpy04PP5OHr0KKlUakj2o2b2IqUklUpx9OjRIZ0mKkGXCqlmpIQ/Xg17/wkv/gIsOwce/g788zpVhPOS/zd0nVA7DBxih/0iPI7i0xsRpqVmiNt0HzSu5rn2MCctrhvTEK1iobFUFhadpia2P01P2EOj30m9TzW474+lWNpQeSzdfCE20M3G3G6ebHknHqddXeiXng0PfAPZeJhLMvfDSa8Bx9DSLQtr1c3B57Kx0HzKT2VyrGpSsY0+swtDLJkdYnlbYK6737ORs8N3QTYDNn05mCiFCSRnrWxgzbNfJ7NKZQlPxPLmSPQQFLU0GyM/b7/t3BV85dFlEAKCh8BTWZs7zeTRG0lR73PmH54mmrSwZMkSenp6OHjwIJnM+DPDE4kEbndlVQQ0lTHRY2q326mtraWpqWns6457r5qpZ/tfYOdtcOln4dz3qWlX/gz+9t/wwNfBXQvnXVu8TtuDADyUPYHVzuILfUT4QQKJki4LPXtINa7j8KE4b3xBcZLDaFgxb4l0FhadqiYefZLe6JmsbfFT61FZq6WWn0f39/KNu3bx2Vdu5IRF1duzbio41BvDMGBJvZf+Z25nsZAkV16MJ2IjkcrCqk1w/1f5Uc/b1ArWuS/hpCV1CAHvv3RdkZV1mSmSC8uJhBIZhIBVTT72dUdp8pvB7YET8Yb/Al3Pq1p9mglRKN7O9HbCg9djf/B6XNw8IfHmTvUxYKujkmjUmHexKd4O63M6A/RGUzT6nPlrYzw1MZenYRi0tLTk20ONl82bN3PqqadOaBuaYmbymGq3abWSy8HmL0Pz8cU3byHg5dfDhtfA3f9PxcEVcuA+cNfydHrpkIbjGcNNWjiL3SnZDPQfoNOhAuU3Lh6bkLL2EU9nwVMHDavh2FP0RJI0+V158TYQL7b8PH6gjy1t/bzr51tLNznnufoXW/nv3z4NQOrZP9Eh66lbcw4ep1kXasV5sPEKAB5p/feiLNNCmvwuDnzpcl64rrmoqPLyxmLxFk9lCcXT+F12bn77C7hynSNvteuqNQu5HntqKj7qvMNymwKclxpsF/dy++MTEm++dB8RW2VWtKTfjFkNHhr3/jTjpy+apNHvLA4p0WgmGS3eqpW9/4TuHXDBB8Eo6WNo2ODVP1SFcf94NRx9Qk1PhGDnbchVFxHPDFrFLIQQJGz+YrdpfxvkMuxKq6e6jYvG1gnBY1r38kG5i05FHn2SYCxdJN72dIU52DuYdZo0M7AKi/nOB7rDSXZ2hHnqUD8PPLePRd0P8Lj3QtYurMXjsJHJSdLZHNGXfofLkl/m6eM/UtF2WwIuzNCqvHu6NGGhxu1gaYOXy1c581XBU4GlhKUHCro6aMZHIp0lmRm0sqzpf1CFOthcHCcOTyjmLZAJEnM2VLSszdtAFLcWbzNEXzRFg8+VDynR4k0zFWjxVq088xvwNCgLWwFdoQQ3PniAnM0Fb/g1+Jvh56+BbbfCPZ+HeD+JF6g2IZ6ShAVDQNwWKHabmtX87w82sb41kI9Rq5QhF6jFpyHCx2imn6aAMy/evvXPPfznLwezGqNJtXwykyOVmT+ZVI/s7wUgJ+HuO/+ES2S45DVvx2W3FR3LngTslMtoDpRvhVSK3WbQWuOmtWbwppEvFZJUCQs1nqGFl/0uJ9vlcnLtulzIRCm0uoHEH2mDhadA4xrWGEfH3x5LSupkkKSrsaLFa7xOjshm5IAWbzNBb6TUbarFm2by0eKtGkmEYNftsPHf+Mrd+3j9jx7Jz/rGXbv5/G3bebytD/wtcNXtULcMbnkHPH4DnPEOIo0nAQzJNjWEIG4Eit2m3TsAuKOjhhesrOzJvpCimDdAmnFvJxn7afS5cDsMnDb1NTvSH8uvFyto6xROlGnXNUd5dH8vAZcdj8OGP6jqu/mWqUSPfIBzKpsvqtvkr1xMr2zysabFn39vubSjqQzhRJqaMg3NfS4723PLEZ3PQ07fZCZCf3Twe9xAGCMTg/oV0LyO1Rxl3NVyUhFcpMi4KxRvbgdHck3Ifi3ephurr2njJCYsaKqPUCJNNDmzbQW1eKtG9t+rWk1tfC27O8LsMdvs9EdT/Plp1Sbnr8+YRTjrlsLV98Kbb4W3/hUu/2ZeDAVKbtaGgJjNV+w27d5Fyr+E7pSDM8cj3pzFT5cffQiyUnCSsZ/mgHLPWRafUCKTv5BFC55Gw4n501tzT2eY4xfWcO0lazneOES/cxG4VZyhp9DyZrqTK7W8AXzjdSfzjStPyb+3GQKX3VAxb4lhLG9uO9vlckQ6Bn37J/DJNBHzYv71K0/mx68whVb9cmhazxLRhcjEx7XdTKgTgJy3suLZAbedI7JJu01nAEvAN/gHLW8xbXmbc/xg8z5O+dxd5GawdIsWb9XI3n+BqwaWnEkwniYUTyOl5PG2PpKZHCubfNz1fMfg8jYHrLkUVl0IQhAyxVBNSX9SwxDEjKFu037fSgCOX1B5fTcLT4nb9A/P9rNHLuEUsS+f0egpyHq1LEqxgqeW0jIWc5n93VFWNft49wtXcWFNJ95lJ+XnFR5L6zg1+ysXbwtrPfkSIBY+l13FvMXTQ8Q8gN9l5/ncCvWm49kxfhpNIZY1eWWTl9NrzP7BpuXNQFIXPzi+7far37rwVybe6rwOjskmjOTA0D7GminFeuhq9Lnwucxs7xm20Ggmn6P9cRbUujFKut5MJ1q8VRtSwr57YOULweYgGEuRyUliqWw+4P9lJy6gJ5IaVvSEzMzOUkuLIQQxW4HbNJeFnj0csS9HCMZVh6005s1uCLbm1nGasYcmr9k6Kz3oL+oyRUk0lc0H2M8Xy1t/NEVvNMXqZj9GNklN7CCuRYPizV1gxbSyc2u9Q61lY8HjsOXrvJWKeVDibo9cQs5w6KSFCWJZnz0Ou0oEAhXSUKsyuQOp8TWLT5jizQi0VrT88gYf7dK0/IV0m6zpxOpr2uh34nPaEQLCWrzNOY4F4yyqHVp7czrR4q3aGDis/lZeqN6aN/GBeJqDvTHqvI58RujhvljZTViibojlTUDM8CnLWy6nbjCZBLvlYhbUuPNCbCy47AZCqDgtUALwsdzxBEQcX5+q3G/d1DYZT7Put+fz9OfP51jbThaYFcjnS8zb/h7l/l7d4lMuLZmDxjX5+YWWt2gqi8MmcNnHfk4K8bls7OgIE05kWFI/9GLjd9lIYydaswbateVtIljuMZ/LBsGD4GsGpw8CC9T0VO+4tpsYUOLNXVtZna+VzT6OSTMEInRkXPvUjA9LvDX4nBiGwO+0E5knD6fziaPBOIvLXE+nEy3eqg2zsTtLz0RKOUS8LW/05S1kw4o3syBubTnLmxFQoiEVgW4VMP9MYkG+NthYEULFVVklElprXDyaO17NbHsIUGJkET183/FtehKwMrOPHzu+wVKzpFxonlzc9nUry+mqJr8S6KBiFk0Kkz9iycyQOn3jweu0s6M9hCHg5ScN7YtZ6zE7YNSs127TCRIzrc8ep011Oqkx6635lcXMn+oZ13bj/e0ANLZW1nPY77KT8ZvneuDouPapGR+W27TJp8Id/G77vHk4nS+kszk6QwmW1Gnxpink6BNgd0PrRmKpLOmsCogMxdO09UZZ0ehlab0l3soHQOctb57im78QEBVmNmIimC8T8shAE8sbxt5bzcLtsOUTETJZSTf17MwthV13qGk5ySccv0YgeXP8I1ybfh/HG4f5r+RNwPxxmx7tV+drcb0HBkyLSO2S/PzB5I8c0VQWn3NiVjdQFxqAF65rHhIPB9BoloY55l4D0W6IdE94n/OVuBnz5nXaIdYLPrPljd3JAAECmfGJt3Soi6D0sbip8hqMNS1LySEgpMXbdBKKpxFiMFnM77LnE1k0c4OOgQQ5iba8aUo4skW1tLE5CBZ0JeiJpDgWjLO8wUut10HAbedw/3CWtzR2Qwwp0msIQcQwkxKiPdC9k1xgEQejNpY3jb/vqMtukDDj2iwLnPOUK+DQwxA8zFfPE7zc9ig/zr6MozRzX+5kfph5OS8M/Y2XGFvG9mSay8ITN8MTP4Ps7HqiHTCTBhw2Q4k3YUBgYX5+ods0lsoMqdM3HqwYw4++5Liy82s9DmyG4JBthbnC9gnvc74Sy8e82ZR48w6W9ug1Ggikx+c2JdpNn6grG7M4HMub6+imDjmg3abTSTiZwee0Y5gBvQG3Fm9zjaNB9RC+SFveNHlyOejYpgp7AgMFfRIf2tdDTsLaViW+ltZ7R4x5q/E48lX0LWyGoNNuioX+A9C5nWjtWoAJW96sjgnJTJaXblzAqk1mX857Ps/rOr4B7jpip/0nL9nQSr3XwTcyr6PDdxxfd/yQ2u4nKtuRlPCXa1Rv179dCw99e9xjngn6YynqvWbdtoEjEFikMoVN3EXiLZvvkDARfvSW0/nhm08btn+sYQjqvQ72oNy3mY7ntZtnnMRTWVx2A5shINZXJN76jXpqMuMTb454LxFb3ZjWWdbg5ViukWxQi7fpJJrM4C/43frdjnkTFjJfOKbFm2YIA4chHYUWFTMWjA9WbP/LU0cxBFywVrliWmtceatKKaF4pmxBViEEnXYzbqb9WejaTqf/BIBxx7xBseUtkc7hshvQsBLOuQae/R0c3Qovv56PvfZsfvSWM1je6CONnbtOvJ5+o4637H4fPP5jJc5G4qlfwDO/hgv/B9a+GB7+LiQj4x73dNMfS1NvZY8OHC5ymUJxkd5YMjukyPJ4OG1ZPZdtXDjiMg0+JwcTPvA0cO8D93HidXfx28d1jbCxEk1l1DnLJCEVBu9g3cR+o4GaTN+4tutN95KssECvRUuNi2OygZwWb9NKNJnNlwgBCLjsRPTD0Jyi3zSqNI6xG9Fko8VbNWEmEFjirdDyFk1lOW1ZPXWm5cbjtA1buduyvJViCEgJJ9QuhW1/BJllt309MDHxVmp5y2etXvIZeMV34O13wsbXFixvfu1qF/EB/9fY4TkNbv+w6hKRDJffSe8+uONjqoTKhR+Ds9+r4vYOPjTucU83A7EUtXnLWxnxVlDUM5pS7pfpoMHnpC+WJtN0HPVRVah3V+cw50EzLLFU1ox3M0VakeWtkdpsr7Kuj5GaXJCcp2lM6zQHXLTLRmzhY6M/FGkmjUiJ5U27TecelmfCPwmekYmgxVs1YbaqolnFJw3Ei5/YLjl+sM6T227LW7tKCcXL1/QyhCCbk9CwCsy+h0/mVtHocxIYQzxNKYVjyVveAOxOOP1tsPycouU9+d6bdvA28uW665TQ2/5nuGGTch0XYMvE4HdvUS7GV/8QDAOWngWGY1aJt7zlTUoId+RLSFjYDIHPaSOUSCshME0Xh0afi75oig73KtaJw4DULX3GQTyVVdbTmOkeLRBvA7Z67GQh3j+mbcbiMWqJIvyV1XizaAm4lXjLxse8T834iSYzReEOfpd93iRkzRfCCWVht9tmVj5p8VZNdO1UAeyeOoCihAWAy08cdH+5nYPWrlJUK6ShN35DqIbo+RIGTet4PuiakNUNwOUwiixvrlHqxVmWOafdoCXgoiOcggs+CG/7m3KD/uQSeOwGSMWgaycnP/NplRl75U1Qa47d6YXFp+fLkcwG8jFvqYhqf+YfWrer3uekP5pSN4FJcJtWQoPPSftAgodDzdSIOBv9Ed1Mexwoy5sNYmZWaYF4i9rMTNExCqlIn2qNlc9crRDlNrUK9eqM0+kiUire3HZiqax6aNbMCcKJ8t1qphst3qqJ3r1FRVv7oqlBKxawrEBkjcvyZgjVi239ZVC/El73cw72RlneOP5kBQCXORYpJclMDrd95K+VZXlLprMsrvNwNBhHSgkrzof3PADLzoY7PgJfXAjfPwtv7DC8/pew+uLiDS0/B9qfhnRiQuOfDjLZHOFEhjqvQ2X6giriWoJyYaaIWy64aaDB5ySezvL7QyoZ5mTnsXzHDE3lxFPZwUxTKBFvZsJIfGxxb8mgqvEmygj9kQi47PTZTMGna71NG9FUqdtUXYd1od65QziRmZCnarKYefmoGaS/TQkrk55Ikia/i5+94wVFIg5U3NhwN9jhY96ECn854VXqD+iNto2p+Xk5LMtbKptDSka1vNWbgZ4SVSsnkc7RF03R6Hfx6+cTfPPgNWx56wcQhx4DTx2PDbRy3nEvG7qhBSdCLgM9u2HhSUPnVxGWC7zOM7J4q/ealjcr+H0asJKSl60/HdpgrTjM4WEeDDTDE0tnVC/aMjFvcbsl3sZmeUsOKMubERibeBNCkPYtggS6y8I0Ui5hASCcTE+41Z2mOggnyicETjfa8lYtpGIQ7YK65flJvZEUTX4na1r8Q/qOuh02sjmZL8JqkcxkSaRzZb9cym06aL5PZ3MkM7kJB15aVkCrxlup0CzlAy9ax3s3rebVpyzOp1tbtXM+9efn6Imm6Gg8Czb9D5z1btLOuvIbatmgXmdBbTIrQ6ne51TFcKGsK6ze66DdLALpdU2PeHvxCQs4c0U9H3vt2RBYxKrcoXzBWU3lDCYsmJY3z2C2acyyvMXGZnnLhlQ/VGft2GLeAOw1rWSwacvbNFLObWpN18wNlNt05oW4Fm/VQvCgeq1fkZ/UE0nS6C9vFStspVSIFRxbzvImhCgSb1HzgjLRemKW5c0ay2iWN7/LzkcvOw6n3WCxJd7M7gNWS6/9ZiupEWlcDTYndD4/gdFPD8GYKvtS5y0Qb94y4s3nzJeAma5s0xMW1fCH95xLS40bWo5jWfagdpuOg6KEBXcd2AbPX9xuxbyNTbzlzI4XrtoFoyw5lKZaL72iQce8TROpTI5UJoffWZywABPvInOgJ8oP79unwks0M4pym2rLm8aif6h4642khq0lY5XbKI17C8XLN6UH0/JWsLj1NBiYBMtbMp0jma7M8laI1Sz9Xzu7SGVy+VIo+7orqN9mc0DTeujaMfZBTzN5y5vXMaLlrcE7eL6ny21aRMsJLEofJJlMjb6spojBhIXi7goAabufLMaY3aYi2kVcOvEHKm+NZbGgxsOxXD1Si7dpYcjDcG4w/jc5wTCEd9y8hS/fsTPf+F4zc4SqJOZNi7cqYCCWVvFukBdvUkp6o0maholHcw1jeQvlLW9DBZnNKLa8WeLNP8GnCJfDIJHJ5t2m7lEsb4VYlrZbnjjCbx4/pKrTAzvaw/znL5/gXzs6R95A6wmzQrzlLW8ep4p5cwbAMbRCd12BWJ+MDgtjpuV4nDJFQ6p9+vc9yymyvJWIN2HYiAjfmN2mtngPvdTgL2NJH41FdW6O5urJhTrGvK5m7BRdT/vb4PoTWLz9RwBDwlvGSsq8tv5+6xE27+qa0LY0EyOUSOuYNw08uKeHkz93F0fbdoHDl7/oh+IZ0lk5guVtGPE2ouWtRLwlJsdt6rbbSGdlvrzEWCxvQgj+742nArC7M5x/svzN44e4Y1sHP7pv/8gbaFqnArKrvNNC0LS81fkcqpTEMKUfZt7ypgpEL8m0Tf++ZzHZnCSVzeF12MuKN7tNEBI1Y3abOhK99MjaIldcpSys9dAl61VNQc2UEzXjRP0uO/z1Wgi3s/DJbyIYjAceL1YSxFfu3MlVN22Z8Fg14yOZyZLK5LTbVAPPHAkCMNB5EGoW5lP/eqIq7mm4TNDBmLcSt6lZ/Xn4mLfB9/knxUmIeYPBjMqxiDeAl5+0iJOW1NLWG6XftFDZTQucZYk73BfjwT09Q1duWqdee/eOZ+jTRn8shc0QykUd7S6baQpQ7xs8bzNieTMLRC/PHJz+fc9ikuYzlHKb9g0RbzbDIIR/zG5TV7KXoKjNNzofCwvr3HTKemzpyPCdSzSTRt5t6hBwZAv4mjFyac4UuyZseZuRa4FmCFbsonabavLmV3eyG/ytZLI5cjlJjxm03ugrL97yMW+ZUsub6TYdJuZNlnObTtjypsbytX/sNMc2dovR0novzx4eQEr4/Ks2sPeLL+PVpyziUF8MgGt+8xRvvvExHttf0tzbEm89u8f/AaaB/liaOo8DIYRymw4j3poKElSah0lWmVKcPoLuxaySh8jpwqIVk8yqY+V1Gur8FvQ1BfUwMkBgzG5TX7qPsK1+XGNaVOuhU6p1U8Fj49qGpnIipoJvTB2GdAwu+DAAZxgTF28z3YpJowiPEJY03WjxNsNYlbd96V7wt7Lmk3fw3l89yZ4u5QZsqRlOvA11mz60t4cf3KcsUOU7LAiyZbJNJx7zpsbyzJEB9X6MljeApQ1ewuZ4rAzbZQ1e2gfiJDOSZw4HAfjC30vi2xpWgbBVvXgbiKdUgV4wLW/lG42vbfHzxdecyN+vPZ8VTRMrnjxe+n1rWCcOT9jVM5+wLG8BWxKyySGWN0MIBsZqecvl8GWCROzjE2/NARedqHV/dfdj49qGpnKsMJT6kNmjevm5ZAKLWWsczcesjRfPOB6INZOP1df05N3fg6+untG+wVq8zTBRM06sJtNHxqcKcd75fAc/fmA/GxbVsLbFX3Y9t139mAvbGP3o/v0c7otjiPI/9tJsU+spYsKWN0dpAeGxX2iWFdSxs+L8ljZ4yUl46Jga55kr6nnu6EC+Jhyg+qc2rKx68dYfTavWWLnciJY3IQRvPGsZGxaNPbtwsgjVrGGl6CAej83YGGYbluWtNme6J0tj3gzBAD5IhCrfaCKIjSwxZ8Poy5bBZgi6ZB0AkZ6xF+rtDid5/MDYLIXzmT4rKWlgp+q73HwcucZ1rBFHJ2x501QHlrfKmw0CcrDC+QxQVeJNCGETQnxeCHFACJEwX78ghLAXLCOEENcJIY4JIeJCiM1CiA0zOe6JEE5k8JLAI+P0MPiEfbA3xrsvXK3cbGXwOC236eBFYVeHujHkJGXXG5KwYMVoTDAw3mW3lbwf+9eqULxZcX5WYeKfb1clU657pTrNdz1fEoDdtA66q1y8xVKqDEoiCDI7rHirBmK163GILOnuPTM9lFmD9QwVyJnirCQhxWYThKUHkqHKn9bNkjJJV3krbSVc+oJTAFjuHINoNDnzf//J6370yLj3Pd/ojahQF0/ogPII2J3IpnWsEcdIpidW563QCq6tcDNH1DSxuzNh8IzPIj5ZVJV4A/4H+C/gWuA44L/N9x8vWOajwIeA9wFnAl3A3UKIwPQOdXKIJNO0COVKOZoptracvGR464slmAbiaT7+x2fZ1RGmM5QccV/59lgm0WQGj8OG3Taxr0Gp5W20Ir3lOGNFPf9x/kq+9NoTWWm6C9e2+HFa8XRXnsSGRbWsavKxeVd38cpN66BvH2Srt4p5MJYeta9ptZBoWA+A7Kz+zhXVgmV582dV6MCQhAUhCOMBJKQqKEANEFElITLu8Yu3j7/6TOK48Sa7R1+4gK1t2uI2VnojKeq9DozwMahdAoBoPg6PSOGOTqz0TrIgtnmi7Qw14ydmZhQ70yFViHsGmfmou2LOBf4mpfyb+b5NCPFX4CxQVjfg/cCXpZS3mtPehhJwbwR+NO0jniCRRIYWggA80VdcFmRJvbfMGgrLNXnPjk7u3dXNHdtGLwdgGAyxvE1GFlOp5W20xvTlcDtsfOrlJxRNa/S7eOJTl3L/Aw9y8XGqPdD5a5v4w9YjpDK5vLCjaR1kU6pLRePq8X2IKSYYT41aoLdayNavJi1tGLOgfl61kM82zQbNf0qzTU3LG6jMT1f5cIgizO9K1jsBoS8EfUYD/nSZTO0ReNqMMQXI5eS4sl3nG71RsyNO6JiqPwnYWlRClS/SBlww7m0XVhWohmD5+YrlrXKkBiAws9fwarO8PQhcJIQ4DkAIcQJwMXC7OX8lsAC4y1pBShkH7kcJv1lHJJmhRQQBuGVXumiebYQLpmXtsuqiWXXERkKUJCxEktlJqVdTannzTmJbp4DboVLvTc5d3UQ8nS26uVR7xmkirfrNFrXGqmLLm9vt4YBcgKNv50wPZdZgiTdP2rK8Dc02Defc5sKVuTClaXmzjbEpfSlBeyM1YxRvhZX8UzpeqyJ6wilavAZEOqFmMQC2uqUAeOITtbwNngPdIWvmiJk/dFtyYMbdptUm4b8CBIDtQogsanz/K6X8vjnfavBXWna/E1hcboNCiKuBqwFaW1vZvHnzZI+5iEgkMqZ9HOmM8wrPAGShS9axqtZg/4D6oY60nYyZpbq3cyA/rckjuOYUF3ZDlF23pytBNJrLzzt4LIFMyQkfk/0D6gu9yCf4yJluHnv4gQltr5TCY5pNSwTwq39uJbZWWSrt6QjnA/seu4PD7UO7Fsw0fQl1PruPHGD3sYdZBzz89G5SrrG5siaL0b6je/qzBOVSWjuem/Lfy1whFE0Agu4Dz9GAwX2PPgVi8KHm6NEU6awLDHjikc2Ea0a/mS/Zt5WVUnC0Z2BC50HkaliT2TumbWzfOxiC8a/N9xc9QE0XY72WzjSHumOc4usDJLvaI7Rv3ozIZbhACjJduyf0WfoHYpzWYiOekYTC4zsus+14ViPb9qiHmmykh/beKBHXzB3TahNvrwfeinKBPg+cAnxbCHFASnnjeDYopbwBuAHgjDPOkJs2bZqckQ7D5s2bGcs+vv7cA6y0J0kO2Ani58uvOIX3/PJJXrCygU2bzhlxXfs/byeaHnwMe+VpK7jqFScMu/yfO56iIx3Mj+97Ox9mQUCMup/R8LX1wSOPcMKyFl5z2RkT2lY5So/pDbse5FjWYNOmAmPrM62srsmyeorP73jY1RGGzfdzxskbWNe7FfbAuZe+oqhx+XQy2ne05ViIO7Yu4eXpR9l07pngnJmSJbOJOw/cDaRY1exDBBvZdNHFRfMfT+zkiUPbADh9w1pYvWnUbUZ6fk8fAU47cQObzlw27rH98+lf0RjcwuILL6w4O+63h5+AIyoU48yzz6El4B73/sfLWK+lM8mj+3vpjj/G6avtEIL1Z2xi/bpNAHTdX8ciV5zTJvBZbI/ew8oljUSTGQ70RNm06YVj3sZsOp7VykPR7fgOt+HIRFi8ZgN7DP+MHdNqc5t+Dfi6lPK3UsrnpJS/AL7JYMKCFdjVWrJea8G8WUM2JwnFMzQSJO5qAgSXHt/Kr/7jLH78ltFFUGlJjje8YOmIy5dmm0aT2Ukp/nj6sno+cOk6vnrFSRPeViWcu6aJLW39fPZvzw+m4Detq1q3qdU2x+c0uyt4GmZMuFWCx2ljtzS/S13adVoJVsKCPTG0uwIot2moMOatAnLhbnpkrXK3T4Coqxk3KUgMjL6wiVX2AphwjbK5TiKd5Q03PEo2J1lkmHX8ahbl53fRSCA5So/mUUhmsrgdxpC4Zc30EklmaXakATnjbtNqE29eIFsyLcvgOA+gRNqLrJlCCDcqEvTh6RjgZLL6E7dzqC9GQ66P2uYl7Pnfl2K3GZy3pola7+jtN6xYs7NWNnDgSy9jXevICbdCiKI6b7FUZlLi0wxD8N+XrqVhmD6sk80Fa1Sg6E0PtfHkQfNiaYm3KrywJcw6Eqpp+fA13qqFhbVuDrlVxilHn5jZwcwSkllw2gyMeHnxZjOM4oSFSoh20ytrVH3AiYzNbcbMjaHHaX9Ui7dKsfpJAzRkzdjCQvFmNFGTmph4S6RzuOy2IXHLmukllsrQ6jTrjM5wtmm1ibe/AR8TQlwuhFghhHgN8EHgTwBS9Xb6FvA/QojXCiE2AjcDEeDXMzPkiVOb7UP4W3GMsWSHZTVbUOseth5cIaXtsWKp7Mw0P58g56xu5Gumle/5Y2bwd9M6VUMtOjNxZCMRM8Wb12kbsUBvteB22HjNhWfSKesI7Z11z0QzQjIrTXHeOyRZAcBmMGbxZov30EPtYGeO8Y7NY4m3yoPm+63SNuiEhdEIJQZLFLUaA6pAb4FVpsdopi7dNaEHy2Qmi8thYCsp96SZXqLJLK12U7x56mZ0LNUm3t4H3AJ8H9gBfAP4MfDJgmW+ClwPfA/YCiwEXiylnFWdlwv7RvrTPRAo9QSPzhteoOJgshX2oCxtj6XEW/W674ZDCMGVZyylye8qEG9r1WsVuk5jZgszj8Nmtsaq3jIhFictreep3Foc7dryVgmprNWUvhe8Q8+vzTCIYmWbVnapciZ66JUTF29pr7q25EKViTcpJf2xFAtq1Hi15W1krJZJX3j1RlZ64ur3XfAw3WtrxiUT6uFyHGRzknRW4rbbMERl1/t4KluUMayZHKLJDE12s/OMdpsOIqUMSynfL6VcLqX0SClXSSk/IaVMFCwjpZTXSSkXSindUsoLpZTbZnLchURSkhUf+zv/3D6ymdx6mnWQwZsZAP+CEZcvx3+cv5Krzl3Bu19YWW0zwxBYv3spJdFUBp9r9lneLDYsqmF7uynemk03X/eumRvQMMTNmDePc/aIN6/TxlO5NXgihyDaO9PDqXqSWYnXIVTj+WFi3jLYkXZPZaVCUlEc2biKefNMzG2a8yvxlhmorDl9KJEhm5O0aPFWEVabwfULAoh43xDx3mc3LZ8DR8e1fatAr8th0JDtxp8bPXbxzTc+xmmfvxuAzbu68gJTMzFiqQyNNlO8abfp3KItpC50Nz54YMTlrED7ZrNA73gsb3abwXWv3MCJI3RiKKTQbZpI55BycmuyTTcbFtWwpzOsLm6BReDwQU/1tXTKu01tUjUmr3K3KSgr4dO5NerN0a0zO5hZQDILTY6kan1WRry5zPjUnNNfmeXNdP9H7HWDxajHidPjJyS9ZAcqs7xZ8W4LalQlfy3eRsYSbwG3XYVFlLjNg3bz9x4ap3gzC/Se0/Z9Pr3nSn6a+BAMjNyr9gkzFvjZI0GuumkLn/pz1dg3ZjWRZIYGw+yQot2mc4u0adpyOUY+tNYF8ZMXmj/0cVjexorKNlX/W20+ZmPMm8WGRbVkcpI9nRHVPqJpTXW6TS3xlgmqCbPA8uZx2nhWriSHAUe2zPRwqp5kVtJqMy/qZcSblXSQdVQq3lTge9w5/tZYFh6HjU5Zj6zQbdofs8SbsrwldczbiESSyqoVcDuU27zk9x1yWpa3kQXXcCQyWU4QbZx44KfsCJxDgCj84xMVrXvPTlXouX0gMcqSmkqIpbLUCku8abfpnMLqYuK2jyyK0mZpgUDGdEmNw/I2VgwxmGZeFEQ/S9mwqAaA54+ZboSm9VUp3hLpLEKAK2X2i5wllrc4bvoDa7V4q4BkFppsEfWmjHhrNDOxUzZfZeLN7K6QLbOtseJx2uiUdYhIZdmmliXJyh7XlreRsY6X32VX2eQl5yziaCSDbUKWt3fa7yBr9/L7pf+PW4yXwI7bRnTD2s3uPPea4q3JPz2VAOY6kWSGGqJgc4FjZgvCa/E2yViirLRlVCnWBdGfMsWbf+rFmxAiH+yarz02CXXeZoplDV78LntxxunA4cobf08TsVQWr8OGmAVN6S08pqjvCJwIR56AbGaUNeY3yayk2TBFWZls03pTCCUqFW+m2zTnmVhrLFAPaJ3UY4tWVq7CerCr1+KtIqxsU79dqlp6JTFvDoeDPqNh3DFvqXiEy4zH6VhyGSlHDbeIFyv3/LO/G3YdqwboM0fUg22Ne2JJLxoVchRLZQnIyIy7TEGLt0knYVapc9ltqq7S1p9Cz94hy1kJC750DyDAN/GL9GgYBWnm0eTst7wZhuCEhTVVn3EaS2XxOO15V1i5bMRqw7IcHwicBqkwHHtqhkdU3SQz0IAl3oa3vMVEpeJNWUzkJLjY3Q4bXbIee6yzonIVCTM7usZjlgrR4m1Ewok0fpcdW8KsOVki3h02g27RNG7Lm3P/3fhEkq6Vr8IQgqO0wIITYe+/yi6fyuTyDdQtLEGuGT/JTI5sTuLPRWbcZQpavE06cbNdlceeg1+8Fm77APz0xSoLrQDrguhN9qgYiWmouG8rqM4dN3/Ms9nyBrCq2cehPjP7Z8GJ6rXjuZkbUBniqYxZ481qSl/94s0wBG6HwR7vaWrC/s0zOp5qJ5GV1IvhxZvVJSFKhdmmkW6iePB4Jt6azOu00yEbMHLpIdehclg3+jqPrvNWCZFERiUrxCzLevHv22k36BRN44558x26l6D0EV9w1mCpkDWXwuFHIVH8XYomM3z5DtUVZePimsExJrXlfKJYx9CbC894pilo8TbpxMzfyGm9f4eu5+GCD0M8CPd9tWg564LoSXZPS7ICFLfHstymHsfstbwBtNS46YkkyWRzUL8SXDVw7OmZHlYRsVR2sMabYa+KH34leJ12eqUfFpwE+++d6eFULbmcJJaGekIqFqZML1in3SDgtqsWWRXFvHXSJeuo8Uz84cpKWAAqKtRrJTNZglNb3kYmnBdvZghMiXh32gw6aFSWt9wYj6WU1By9jwdyJ+J2OcxyT6Z4y2XgwP1Fi//8kYP89CFV6eBdF6zKW3y1eJs4A2YnDU82pN2mc5GYaXnb2HcXNB8Hl/w/OOFV8OxvITNYNNEqFeJKdE9LsgKY7bFKsk1nu+WttcaFlNATSamM04UnQ/vTMz2sIuLp7GCNN2+TGucswOOwEU/lYN1L4NAjFVlt5iPhRAYJ1MrwkAKthTT4nASzbiXeRnFf5sIddMnaSYlV8jptdMk6c7CjizfLbVqr3aYVEU6mzWSF8uLNYRO0y0bIpgatc5XStR1Xopv7cyfhstvUA3hOwpIXgNMPe/9ZtHjAPXg9X2IPsfXDZ3Dp8S1EElq8TRRLvLkzYe02nYvEMpJmgqyIPqNEG8DJb1D1vfbenV/OuiC6Ej3TkqwAZraplbBgxrz5ZnHMG0BrQJUz6AyZqfALT4aObZCtnqKUcasNWax3ViQrWHicNuLpDKx/Gcgc7L5zpodUlQTj6qHMnxsom6xg0eBz0p9xKYtJZuTSDTJsWd4mLt7cDhtd1Kk3kdGTFmKpLDZD5At4a7fpyCjLm0N5WGDIjd1pNzgqTUE3Vtdp24MAPJzdgNthYLMKrdudsPJCFfdW8CBgM7NMP2j/Paffcjbipy+l1pHNe1o042cgpu4pjlSoKrwnWrxNMrEMXGA8i4GE416uJq6+WJ3sHX/LL5fK5hDkcMSnU7yJITFv3llveSsRb4tOhWwSunfO4KiKyfeQnSXdFSyU5S2rjmnNEnj+TzM9pKrEeiL3ZgbKxrtZNHid9GRU4dvRXKci2kmXrJ8Ut6nXaaM7b3kbvVxIPK2yo51mr+WktryNSN5tarW/chcXTXfYDI5mTVE/1qSFtgeIehZxlGazMT35FoehJRfCwCFy3YMJWvFUllPFHq6x/YWsfwF07+DFoT9qy9skEIynsJHFlg5rt+lcJJaWnGnsImr4oXWjmmhzwNoXw+5/QE6JplQmRwNhhMxAYJpi3graY82VmLdWswp8ZzipJiw8Rb1WUdybcpvaZ6V4i6Wyyg140uuUi6aCm/98I2g+kbvT/SOLN5+T7qRpSRtJvCXDGOmYsrxNgtvU47CRxEnC5q/I8hZPKTe/EAKnzci3Z9KUpz+WUv1nE2ZTeoe3aL7TbtBmibexlAuREg4+TEfDGQAFjenVRfxLuxcDcPDxv+ZXiaezvN9+KxF7PeK/tsDSszgx/ICOeZsEgrG0qvEG2m06F4lnJC8wdrLHuaE4tmn9SyHeB4cfB1TM2xJhZh/WLpmWsZkW9Xy9GssMP5tp9LswBHRZlreGVeAMVFXcWyyVweuwqVIhs8xtasU/ccqblOv0yV/M7KCqkKBpeXMkRxZvXqeN/qzVnH6EjNOwEliT5TY1DIHLbhBxNFYkvmOmeAMlPHTM2/CkszmCsTRNfpdym3rqhsQ8Om0GXVkf0u6G0Bjcpt07IdbL0VqV8e22Yt7MB/CgayF7c4vwHdqcXyUQ3MmFtmcJXPhfGJ4aWHkhC6I7cWXCZCpoaK8ZnmAsPdhdQbtN5x6uTIjVRjs7HBuKZ6y5RGUa7rodUJa3pZZ4q18xLWMzzItKTqqUct8s7mtqYTMETX7XoNvUSlqoIstbLJWlxp6GVGTWWd7ilnhrWqOsx49+v+qKIM80A7EUdjLYkiO7TR02QyUswMiWN9M61s3kWN5ACceQvbEyy1s6m7fIa/E2Mr0RFe/Y5Hcpt2mJyxTUeZdSQM2iscW8mfFuhwKnAsryli8VgrLk3ps7hcbux/LJRKcc+QUx6UKc+U61jVUXYpDjLGMH2nM6MQbiaRa7zPuMdpvOLR7c08Py9H4AdtjWFs9018KK8/NB3+lsjmVCFeKkbvm0jM8ysuWkZFdHOB8vNttZWOfhSH98cMLiU1Wtt0xy5gZVQDyVpVGYlpZZZHnzOm3FxT1f+BFlPb73izM3qCokGEtTZ7lTRhBvTrtBMFdBzJvZxmqySoWAEuJBW0PFblOreLfTpsXbSPRE1DVGibeBshYZp13dZnOBxWMXbzVL6LYtBMBlNzDMi/jmXV24HTb+nD0fm0zDc7dA33429N7Nn41LB916i89AIthotBHPaMvbRAjGUix0mfcUbXmbO2SyOT79l22c4z4IwC6xcuhC616qqv/37jMtb13kPE3g8k/LGIVpeWvribL1YD8vP3nhtOx3qlnb4mdPV2RwwtKzVdJCFXQFSKSzZHKSBquA6ywSb+5CtynA0hfAGe+ER74Hj3xft8wyGYinWWAbvjWWhRJvZj/EkcRbodt0kixvHqeNPtGgtj1KmZJYKpN3m7ochs42HQFLvDUHnMptOozlDSBbswz62yrbcC4HBx+CFeeRyOZw2g2EEHnvyVU3beHenV08L1dw1LMeHv4O/OUa0oaL3zlfU7BzNzHfElaJY/nuP5rxEYynWeA0jQQ65m3uYLcZ3PT2M3ll/SG67Qvpz3mHLrT+MvW66w6SlnibJqsbDKaR37Vd3RxeefKiadv3VLK2xU93OEkwZtbRW3a2ej30yMwNyqTfHFOLMQstbw7b0LY6L/lfWHcZ/OPj8N1TizKo5yvBeJqFjuG7K1g4bAYRWYF4i3SQFXbCRmDS2td5nDZ6RT1k4qN2eIinc3gcyuKnLW8j01PkNh0o606z+lzHA8tV0lIFRZrbdmxRy67aRDKdw2Va7wpjlK2ks181/bdymx56lFua30vEWXyNSdasYpVoJ6EtbxMiGEvTbLPEW92MjgW0eJtUljf6qIsd4Jh7bfkLXv0KaDkBdt1BOitZJroQDSumbXzW774vqi44i+s807bvqWRdawCA3Z2m9c3XpJrUH5x58WYd60bMG+YIN/dqQ9V5y+az2wBweOANv1Z/7lr4w1XQ9tCMjbEaCMbStNrM794IfWtddoMIlngbQUBFugjbG6hxO/LW8oniddjpkqZVKDyy6zTfzg0d8zYaluWtcYSYt9XNyrNyGLOqQAXWt8f+eav6Z9UmkplcvtF84dchnVW/yyezq+A9D8B/P8Nm72X5ZfPL1a9mpegotqJrxkwonqbBZrZi1G7TOUYqiifeQYdnzfC1kda/DA49Qm1wO0tED6J5/bQNzzK5x1IZPA7bpN0YZpq1reriuKer4Il22dmq999Y29FMMpZ4q5VBNWEWWd48ThtSlqnzZRhw3OVw1d9VjcIHr5+ZAVYJoXiaFmN0y5vTbpDCgbQ5R3GbdhA0Gqg3WxtNBh6njU6r1ltk5IzTIQkL2m06LL2RJG6Hgc9hDBvzdsIi1WP0+bjpUu87MOp210a30iaWQM0ikunsoOWt4Jptier+aBoaV0Pd0qJzZ5GuW41XJPGkdYeUiRCMp6k3ouDwqSLJM4wWb5NJzx4Ekl7vquGfVk99M8gcr3r+WgwhMY67fNqGZ4m1aHKwFMBcYHGdh3qvgwd2F7SeWXauuph275i5gTEo3gKZINg9ZfteVivWTWCI69TCXQsnXqn6nkZ7p3Fk1UU4maHRGD3mzYp9yjn9QxqKFxHppFvU5/tSTgYeh432bGWWt6JSITZDF+kdgZ5Iiia/C5GOqc4ZZSxvNW4Hyxu9PBo0G8X3jyLeMklOSG3jMXESQJHlzSgQb1b9vd7oYNvFeCo71PLWsBqA2uSxsX04TZ5cThKMpVRiUhW4TEGLt8mlexcA/b4RxFvDSlj/MnzpPtUsunVD+eWmAMttGk1mZn1x3kKEELzhBcu4a3sHB3vNrL8qiXvrNy+s3nS/srrNImun1fc2OlKBzw2vUTetPf+YplFVH+FEmnrCqr6g3TXsclbHgpwjMKrlrSNXS8Mkijev08bRjCksRrO8FWabarfpiPRGU6bLdEBNGObGvmFRDU905pRltnffyBs9/DhukjyQVUXeEwWWt3Ju075oMt/2MJHODRFv1Khivt7U/H3AmiiRVIacBL+MVIXLFLR4m1y6d5ITNqK+5SRHcjW85of8c9F7+Kx497TezK1g12hBNtlc4W3nrEACf3rKrGBevwICi/K1kmaKvlgaIcCZ7JtVNd6AfB3AYS1vAAtOVBbFjm3TNKrqI5LMKPE2gtUNwGHegLNO//DiLZOCeB9H0zVKFEwSbqeNnrQL7O4Ry4WkszkyOZl/uHPYDDIzHHpQzUQSaQKu4VtjWSxt8NIxkIDm46BrFG/AvnvIYHBfah1SSpKZ8gkLFjk5WCg6kS7jVQmoqgI+7TYdN1ZfU18uUhWZpqDF2+TSvYu4ZxF2p5NUJlcc6F2Iu4Z7mt/M4/YzpnV4Ih/zNjQuYrazoNbNacvqudvMpEUIWLUJ9m/OtySbCfqiSeo8DkSse1bFuwH5xuQjttYxbNC8Hrq2T9OoqgspJZFEhlpCoyajWJa3rGME8RZVtR8PpQKT6jb1OmzE0jkVoziC29QS6pYAsBmCTFZnKQ5HNJlVvxPL8jaMVabG7SCVzZFp2QCdz+djcTPZ3JD2Y3LnbTyeO56w9JJIq/nl3KaF9EVV4kQ8ncVtL76t210+gtKHL6Mtb+Ml3wIvG9Ju0zlJz25i3iX5p6SRAn1TmVz+Yj5dzFW3qcWLTmjl+WMhjgbNdO7VF0O8f0ZbZfVH0yrwPNoz+yxvJW7TWCrDh37/DIf7YhzqjQ0u2HLCvBVvyYyyVAVkeFTxZl0XMnb/8NmmprDqlHWT6jbNZw77W0d0m4ZMC07Arc693RDkRqkLN5+JJDPqdxIPqgnDWN785m8p0XACpKP5uLev/WMX/37Do4MLdu1E9Ozm9uwLAOUlSRSUCjGGaWdodXooZ3mz2wQdsoGAtryNm2BcHV9XOqTdpnOS9zzA7nXvyYuykWJF0tlc3o0yXRgFljf3HHObAmxaryxbj+wznzBXXwQI2HvPjI2pL5qi0euYdU3podBtqsTb04eC3PrkES795n288Gv35pMxaDleueLmYdJC2Ow55M+NLt6shIW03Te85S3cDkCnrJ908SYl5HwtI1reOsw2cwtqVUkTmyF0T8wRiKYySphZbtNhrDKWeAvXHacmdDwHwL7uCG2FD0LbbkEKg39klVcmlsyWWN7Kj8P6LZbLNrUbBp2yHn9Wi7fxYlne7KnytfxmAi3eJhOHh7SzDpdjdPE285a3uXfq17UEqPU4ePyAKSJ8TarP6b5/zdiY+mMpFnnSkE3NYrepcutYFk0r+/DvzymhQcvx6rVn9/QOsAqwXMq+7OjizWqTlLaP4DYNqZjNdtlIo2/yYt6sG3ra2zKi5e2YeY4X1brhwev5ZNvbdSeNEYgmM3id9lHdpn7TktnnXQU2JxzZAihRELGajmYz8NSviC+7iG5UXFWp5c02jNu0N5pCSqmWLRFvDsvylumfyEed1wzE0zhJY2TiWrzNZSxRNlKKfdpseTKd5EuFzMGYN1AuhTNX1LOlreAitfpiOPz4yKUZppD+WIrFDqt48GwTb4OWt/O+fA8fueXZovl/e9osPVC7RL2awmM+EUlkcJHCKRPgq0y8pWwjWN4GDpM1nPRSM+nZpgBJT4sSGul42eXaB5TlbWHADo98n4WpNl6Q2TJp45hLpDI50lmJ32UbdJu6asouG7Asb1k7LDsH9qoHymA8TcqKe9t5G4SP0b329fn1YqkMyUwWl718zFuNJQqjqfz9ZojlzWbQQT2BbFAL8XEyEE9Ta/Uv1m7TuUv+Ij2CeEtmcnk3ynRhPbVlc3LOZZtavGBlAwd6ohzpN10Ray4BmVW1yGaAYCxNq9380c9St2kkmRmMIyygPWROC5iV402X33winDTLhEAFblP1+0vafKr3biY5dKGBo0TdCwBBk38y3aZmzJXLfICIdJVdrj0YJ+Cy4z+8GaJdZLHxsszMWa6rGSsW1OcyLW/OANjsZZe1LG+RRAbWXKrqTw4cybvjIvEU3P91aFxD+4KLCvaRNeu8lY95cztsBNx2+qIp4mayibvEq2I3BJ2yAYNcPiFGMzaCsRQtjurpawpavE0J1lPScAkLD+/r4YE9PdNueTMKdjekFtAc4bINKi3+r8+YVqGlZ4OnAbb/ddrHkkirC2/zLOxrCuomYIjBYOhS8g8n7jpVLiQ8cv2wuUgkkaFBVCbeLNdX0mYWak5Ghi40cIQBRyvA5HZYsAouO80HiGHKhbQPJFhY54Z2ZWV9vvZC1uVG7wgwH4kUibfgiO40K+Ytksyo3sCAfOa3DJiB8DxxM3Q+Bxf+D9H0YIxhLJVRdd6GiXmzGYImv4veaIqEmbVaanlz2Ax6pWkRjHaP45NqgrE0S9zKKq3dpnOY0SxvV92k3BD5grLTRKHJfS66TQGWNXo5fXk9tz5xRBWutNnh+JfD7jshnZjWsQyYmXsN+b6ms8vyJoTA57RzuC82ZJ7DJga/30JAzUIIzb8K7pFkhvoKxZvTpn5zCcOrJpTLOA0dpcfWRI3bPqmWeZ9paQ/ZzVp0wwjt9oEEC2s9EDwIgYV0e1bQQm95K+E8x2oM77csb8NkmsKg5S2czEDzOljzInjke9Rkg5wmdlP34Odg5YVw4pVFpXksy1s+27TEbWoIQYPPSV80mbe8lXpVbIagj4C5wR40YycYT9PqNO8fbm15m7NY4q20fo+FJZwS6ektfinmgXgDeOs5y9nXHeVvz5pi4oRXQyoy7YkLlniry/c1nV3iDZRV4XD/UJfpyiZf8cNJYNG8dJtGkhkaKnWb2tXvL2FYlreSuLdsBsLtdNA0qQV6AVpq1Pbas6YFZljLW5yFtW7VPL1uOQOuxRhICB6a1PHMBYrcpvHgiLFQAZcDYDA54eJPIdNx/un6CL93fo60uwleewMIUSTegvE0Ug56SkrdpnaboN7rIBhLEzcbz1uen0JCwhxbTGecjoeBWJoWu+U2rZvRsVho8TYFjJSwkMnmiCYznLWygd+9++xpHVfh736uxrwBvOKkRZywsIYv3r5Dtada+UIVp7D9L9M6DiueJZANgqt2xNZJ1YrPZeNIgeXt9WcsxWYIjl9YUxwWEFgwLy1v4TG4Ta3rQkxYlrcS8RY+BjLHkVzDpCYrAMqaBrTFvSCMspa3SDJDTyTF0gYv9B+E+uUMuFVrJfrbJnU8c4GomYXtc5pFeke4qbsdBjZDEEmqawKLTqHt5b/jntwp3Jh9KY9e8vt87GhhOzqrvd6g5a14uzYhcNoN0tlc3hhQ7toespmiPaYtb+OhN5qkVce8zX1GKhVyLJggk5P82+lLOG5B+cykqaIwzXyuxryBejr96hUn0RdN8Z179oDNAcddDrvugNRQF+BUYVnefOn+WWl1A2VVCJs3k3s+dCFf/rcTefB/LmJFo490VuZ7KlKzUAmCeVbQNZzI0GxEkIhRs9Csuo7Dirc+FVu2O9U06eLN57JT47ZzLJQCX/lyIW09KoxjdYNDZQ7XLSfkMTOJtXgbQrQ05m0Et6kQAr/LPmh5AzoCG/hQ+r18KfMm+i23Jso6J4SKRuiLmeLNvF6XlgoxDIHDZpDOShKm5a20wwJAzPCTxdBu03HSE0nRZFneRjjP04kWb1PASEV628w4txWNvmkdE8wftynAxsW1nL68nqcPB9WEk96gYoy2/3naxhA0L7zuVP+sS1awsDJOARp8ToQQLKz1DMZ1Wta3wCKVQRmfX7WkIsk0zbaI6powTKahxaDlTVnBSsXb0QOqS8XDfTWTmmlqsajOw7FgAgKtZbNND5jiba07CEioX0HC1URcOrV4K4Pl3hyMeasbcXl/wYMQDPbLBIpEXSiRwe+043XY6IsUW95EiXizm+ItlckNG/MGYLfZiYiAtryNg1Qmx0A8TZ2IKQ+KUR33Ti3epoB8Vpkp3rK5QQvFwbx48077uOaL29TiuAU17O4Iq9jDFedD41rYetO07d+yvDkSvbPY8jbY47LG7chPL/2O512G8yympi+aosUeIe0IjLqsJd4iqN9+R3dx5l9n205S0kY7jZNueQNYWOumfSAO/gVl3aaWeFtqmOewbil2m8Ex2QgDhyd9PLOdvOXNLlVM7SgWmYC72PJmXR+AIlEXjKWo9znxuuz0RFSiyHCN6Q0hcNiEcpsOk20KKjYubNRoy9s4sLpX1IkIeKrD6gZavE0Jpdmmr/3Bw3zj7l2AyuayGYLmwPTHP82HbNNC1i8IEE1lWf+pO7ntuXY4/So48rhqDD0NDMTTGAKM+Ozra2phFeqt9zqKgqWHZFR7zSzG+PwSbz3hFE1GlLRj9Iu6YQjshmDPgDp2f3t0W9H8ZPdeDssWchg0TGJ3BYuFdR5VhNffUjZh4UBPlEW1bpwJq0NJM4ZQmYpynonySoiali6fNEu+jBLI7nfZhyQjWBSKur5Ymnqvg3qvI+85OGGhCrEpVypEuU1zBXXeyog3wyAkaiA2/1rYTRRLQPtykaop0AtavE0JhXXepJTsOBbK/wjDiQwBt32I+Xs6mA913gpZv2DQGnLdX58ncvzrwOaCrT+dlv0PxNPUuQ1ErHfWuk0ta1tpZrSr1G1qBfHOM7dpTyRJPSHSjsriV512g66EwYD00kzxsaqJH+GQbAGUWJ5sFtW66YumyHhbVL2vXHE2/L7uCCubfYM3eG8TdkPQLwP6pl+GSDKD3RA406b7exTLW73PSVd4sORKXzSFy25Q53Xke+SCSlKo9zl56caFZHKS5Y1e1rT4gaGlQmyFMW/mg1S5a7vDJggJv7a8jQNLvHlz4apJVgAt3qaEQqtEMKbanxzuU8GO4USagHvk2JiposjyNg/cputblXhb3uilJ5Li4WM5OPEKeOpX03IRC8bSLPUkQeZmrXj7jwtWsqLRy+UnLiyaPsTyZl3U5pmFpjuSpEaGKnKbgineQgk6ZT0tBeItlc6ylE4OSlWgd6TWeuNlvZkgdTBVo76TBQVbE+ksO9pDbFxca/42BHgbsNkEfTIAsfklyishlszgc9kRo/Q1tdiwqIZ93ZG89a03kqLR51Tu1MIM01iKBq+TK89YgiHgRce35h/2S0uFWOItlc2RGKbDAqgWWUFteRsXVpFyZzpUNWVCQIu3KaGwzltnWBX2OxqMk8nmlOXNNflP1ZVQKN5880C8+Vx2Hv/kJfzj/S/EZTd4ZH8vnPd+yCTg0R9M+f6D8TRLnbOzNZbF8kYfmz9yEV+54qSi6VbB2fnsNk2ks4QTaXyZgYotbw6bQWcoQYdsoInBYxXvO0yNiLNozcm8dOMCXlYilieD89Y04rIbbOk14+kK4t62t4dIZyWnLq1TN3hPPRg2bEIQJADx3nmXSTwakWTWTFYIqgmjWN5OXlqHlLDtqBJ7vdEkjX4XftdQy1ud18mSei9/eu95/Pela/PzypYKMWPerDpv5d2mghA1yjKem976orOd3qiyvNlToyelTCdavE0BhdmmnSF14rM5ydaD/YSqxPJW45kZATndtATcuB02zlhRzyP7elV18xNeCY//WGWITSED8TSLnGZpkllqeRuOIZY3V62qHzaP3Ka90RR+4thkunK3qc2gP5ami3oacoPiLXVMxb/ZF2zgB28+ndop+H16nXYuWNvEPw6aE8y4t21HB3jt9x8G4JSl9Soj0XzYsBmCPulHZFMqKF+TJ5rMqIQeS7yNYpU5eYma/4wZQtMXTdGQt7yp+LdEOks0laXBp87/yUvrCBQkCpWWCrEsb1Kqjg8OmyjbmcNhMwgJHyAhObXXvblGTySFyy4QiaB2m851HDaBEJZ4G2zJ9IYbHmVLW3/Rj3E6KXxqm4qbQzVz7uomdnaE6Y0k4fwPqgvYYzdM6T4HYikW2KwCrrPT8jYcg6VCzLgpw1BPpfPIbdoTTuZbY1Uq3qxYwU5ZR122b9AK0qnKhGSajpv8gRZwzcVrOZw2XbymeLP6AC+p97Cg1g3R3vz31W6IwRpk2uVWRDSVGWxKD6Na3hp8TpY2eHjmSBAocJsWJDJYhb2H62tbGittM0S+fmAonsFdprsCqGzTAani5ubTA9Zk0BtJsciLeoDRbtO5jRACp80gmc3RHR7aE7BmhixvhT98V5lCjnOZc1arUhaP7u+DRafA+svh4e9O6YVsIJ6mZZY2pR+Nsl1EvA0VH89YKkPHwPT2mp1seiLJfGussbhNATplPXayeUFk9OygQ9bjCIzcpWGinLK0jnWrVqs3YSXeesJJ/C47f/zPc9X0WA/41DiU5c0Sb/NHmFdCJJlRdRDjQTWhApfayUvqeOZwodvUib+ghEi/WRuy3ltevA0pFWJmMAOEEmncw4TDOAyDAWHWFtXibUyEE2kWW03ptdt07uO0GyTTyvIWcNk5Z9XgRXnm3KaD/89EtutMcuLiWnxOG4/sNxMVLvqEsr49/H9Tsr9cTjIQT9NICCv4ey4xxG0KyqVQYczbVT/dwtlfmt5es5NNT2TsljenfVC8AaolFuDq3cHu3JKioshThcPtIYQ/32WhK5xkTYuflhq3WiDak7e82QxDZZuCFm8lxJJZ0206AIYDHJ5R1zllaR1Hg3EO98VIpHM0+FxFJUSsdljDibehMW+D36lwIlM2WQG05W0ihBOZqmuNBVq8TRkuu8oA6gwlWFjn5jdXn51P/58pt2npU9t8wmEzOGtVI7c9285zRwZgwUbY8FqVuDAFmaeRVIachDqCqoBtlVTlniyGFOkF8DRUfIN/vE0tZ7X0mY30RFLjsLyp32CHNMV88DAkBvD17+IpuRbvNCQSeRw2eqjLJyx0hRO0WHUnczklwH3abToakWRmsDWWp071sxqFk8y4t3t2qg4XjT5leQuZljerHdZwRZqHuk2NvDU3FE8PW7/TbjMI5sVbcNRxagYJJ9M0O0zLm3abzn1cdhupTI6DvTGW1KuK6l7zqXqmLG/zzdpWyicvPx6HzeCr/9ipJmz6OGTi8OD1k76vgcKm9HPMZQrDWN68DWO+MVg1lGYjwViKFrvKJk45KxNv1oPbLrmUDDY4+gQcegxBjkdzx6vsxSnG7bDRRX0+5q0rnKSlxhRv8X5VRsRbmLCgxVs5oqlMQWusyirvb1ysvicP7lUPjI1+FfOWyuRIZrL5av71vvIP+KUP4DZj0BUfTgwv3hyGIIi2vI2HcCJDo2FWDdBu07mP024QS2XY1x3JF4u1TNrVkLAwH1nd7OeCNU3s7TKz5prXqZ6nW34CofZJ3Ve+KX0mOGvLhIxE2f69nvox3xh6zBpKs5H+WJqFjigYdrK2ytrd/fsLlgKQwMUeYxUcfhwOPkhW2Hkqtwavaxosb04bHblaCHeSzGQJxtK0BEyXqdX70jsY8xYy23npm34xUcvyFg9WfFP3Ou3UuO3s6lAW2wafMy/Yo8ksHQMJ7IagaZgOG+U7LFgxb5l8A/tS7DZBMKfP43gIJzI02MyqAdptOvdx2gx2doRJZ2W+WKxVf2emS4VMh2umWlnV7KN9IJHvS8im/4FcBh74+qTux8oac6f65qZ4K+iwcLgvxmXfup+I9EAqPKRy/0j0lEnomS0EYylabRHlLq7Qqv2SDQt4yYZWhIBnWAcHH4KtN3Os7gwSuKYl5s3rsNGRq0NGOuk2s+HzblMrhKAgYUFikHP4dKmQApKZLOmsVPUyE8GKLW8AjX4Xh/qUGGjyu/CbD/ORhEriaQm4hhTjtRjaYcHIP0iNZHmz2wyS2MEZ0OJtDEgpCSfMpvSg3abzAZfDYH+3MrUOWt6qQ7xNh2umWlndrFwHVhNu6lfAaW+FJ34G/QeHX3GMWJY3Z6JvzrtNtx7sY2dHmKMJ06KcDI+6vnUPms1u0/5YmiYjPCZxLoTgR285g7eevZz75KlYdbceWXwVMD09hz1OG92yFpFN0turuizk3aZ5y9tgzBtA1uGr6LzOF2JJs6/pGN2moOLcLFpqXPnrcTiZpiOUUOVahmGIeBODbtNEOjdswoLDEGRzjMs6Pp9JZnKks5JaIqqOpbOyTirTgRZvU4T1NGQzBKuaVYr2cD+s6cLqbeqfIfFYDawyxdu+7gIrwgUfVj/M+786afsJxlM4yGBLDcx58XbEbP3WnzVvOsnQ6Oubv49ZLd6iKeoJ512MY8HttHFPeiO8+Y9w2VfY7ToJn9M2rMVlMnE7bHSb2a7hniMAg27TvOVNiTdrPDmHX1veCrCyQ/Nu0zG40xr9SrzVex247Lb8w3wkkRlVvJUtFWIraHs4guUtK1GWIy3eKsbqfBGQZlN6o3okU/WMZI5h3dxaA658o/qzV6qLfJO/fDzDVJPOqvY2gXlseVve6MUQsKO9wIpQuxjOfCc8/Rvo2Tsp+wnG0jRg1Xibe27Twsb0R/qVeOtJmzedxMjiLZeT+Yb2szvmLUWNHBjX+fU4bCQzOXKrLoaz30M0ncM7Tb9Lj8NGF3UAxPuOAgVu03xTenWtGrS8+bXlrYBoSt3U/U6zVMgY3GmN5vXfEsx5y5vpNm2tGcnyVvzeboj8gxAM37PaYROmeNOWt7EQTigPijcXqSqXKWjxNmVY4q2uoF7Pf120hr9fe75q/jwDWIUg57Plze2wccHaZn635dBg3BvA+R8Auws2f2lS9hOKp1loN292c9HyVlCk90hQxYN0pkwBMIrlLZLK5Ntkds9Sy5tVx8+fHRhX9wzLQpLIKPdbNJmZtn7DHqeNLlkHQCbYjiEGBQXRHnDVqN8Cg5Ye5TbVljcL69pRY0uAzI4pC9Fym1quasvy1h5KEEtlWTiS27RcY/qCguuu4TosGAbZnNTibYxYljdvNlRVmaagxduU4cqLt8HMUsMQbFg0M8INBi8Spy6tnoyZmeC/L11LfyzNH588MjjR3wJnvQe23ZpvVTQRgrE0y1xWU/q5J96sLiKpzKDlrSNpftdHsbwVNuGerQkLoUQaQ2bwZELjc5ua4i2eUuItlsrkSwlNNR7HoHiT4Q4a/a5Bd1ysp+jz2E03UcauExYKiZgxbzXSPCZjsbxZ4s2yvJnX5b2d6mFvZMubGPLeUYHlza4tb+PCula5MiFteZsvOM0noOEqZc8EJy+t49b/PIcPvGjdTA9lRjltWT2rmnzctb2zeMa57wO7Gx774YT3MRBPs9hpirc51tfUwmk3SKSzHAsq8XYkZiUsjCzeQmYyhxCz1/LWH0tThyXOJ2J5U+7jqFWtfxpwO2xE8JBx+HFG2wddpqDcpgWfxwrxydh1wkIhMdPy5rfE21gsb6aVs9WyvLnM2n+meFtUN3ynhnJuU0cFMW8Om1GcsGCZvjUjYrlNnamgyiqvIrR4myIst1Kh5a0aOH15w7zutGDxohNaeXR/LyHzxwmoIrMnXQnP/n7CT6fBeIoFdvPCPgdj3kCJt8N9MdJZic0QHIyaliOrUfcwWOJtTbOfrtBsFW8pGoQpUseZsADFljffNMW8qVJBgoR3Ef5EiXgraEoPBZY3HfNWhJWw4M+Nw/Lmtyxv6ri7HQY2Q6jOL8CKRt+w6w6xvJXEvA1XycBuFFjechltRa2QsHme7clg1bU41OJtinDa1Y+smixvmkEuPaGVdFby8N6S1lhnvkt1XXjqVxPa/kA8Q4sRVj0Px1BGYDbhtBlsO6ZuOKcuraPNEm+jWN4sV8SaFj+RZIZYKjPi8tVIfzRFoxh/Qkre8ma2B2sfSNA4TGHWycZyrUU9C6lPd9FcZHkbbEoPgzFvaZt2mxZi1XH05cZueVve6MNmCNaa9T+FEDT6nERTWQIuO03+4e8ZQ2LeStymw5WBsrJNpSUyteu0IsKJDDayGMkBbXmbL1g9H6vN8qZRnLK0Dq/Txi8fPcRdz3cMzlh4Eiw9G7b8WPV5HCcDMfPm7muuuIDrbMNpN+g0LWfnr20ilrMjDceoMW+WtXNNiyrbMhutb8eC8Xxf04kkLMTTWQZiabrCSda1+idziKPuO+xcQKvsGiwTkstBtLsoRtMSbxm7F7IpyMze7ODJZH9PlHqvA1/O/A6MoVTI4joPj3/iEs5bM/i9OXlpHQArm30jtjG0ldZ5sxWXChmue4/DSjxxmePU4q0iQvE0NVZ4hLa8zQ8sd0idtrxVJQ6bwclL6nhwbw9X/+KJfC9SAE6/Cvrb4MiWcW9/IJ6mTgaLrBhzDSujuiXgMuvnCbLOwJgsbwCdZpX/2cSR/jgtNku8jSdhQR27eCrL7i61nXWt01MA1EqWaBfN1Ikoi7ym5TPWq1xqgUX5Za1SISmb6crT1jcA9ndH1Hc+EVQTxhjM3lhSLur05UpU1XpGftgf0h5LVOg2NZfJusxxavFWEQPxNEvdVlP66kr00+Jtioia4q1eW96qlvPXDj753rura3DGcZeDzQXP/3Fc201nc0RTWWqzQfC1THCU1YtV0qDJ78pn0GUcgdEtb2bMm9XtomsWZpweCcZZ5laJGuN5Iq83j1dnKMFuM1B97XRZ3ky36YG0uhktM8zabmGzv29gQX7ZvNvUbvbFrKAA83xgX3eU1c0+VaBX2MA5sXN3olk+ynKjD0fZUiEViDcrqSHtMkM4tHiriP5YiiV58aYtb/OCfDbSPC6IW+38xwUr+fu159Pkd/GHJw4PNll318DaF8Hzfx6X63SwKX3/nCwTYvGJlx0PwGnL6/KxnUnb6FmJoUQat8NgSb3KqpuN4u1of1xlE7vrwDb2B7QVjT48Dhvb20M8cziIz2lj8QhZhpOJ27SYPh9TN/JWacZ95sXbwvyytlLLm671RiiRpieSHLS8eeomHBpxxop6Lj9pIde9csOIyw3tbVpc523YmDdLhDvr1AQt3ioiGEuzyGH2NfVqy9u8IJYq6H2nqUpcdhsbFtXyngtX8dDeXr5+167BmRteA5EOOPTImLergpklnlQf+OeueDt+YQ33fWQTH3/p8fkMurjhq8htWuN2UOtx4LQbdM1Ct+nRYFw1pR9nJrHNEBy3MMBND7Xx+61HeNEJrSPGOk0mdptqZr41pG5GTanDasYIlrekYVretNs037N6VZNpeZuE4q0uu43vvfG0UeuAlnObOiqIebPcpmm76ZrX4q0igvE0LQ7Twq4tb/MDyyU3UsFFTXXwHxes4qyVDWxp6xucuO4ysHvG5TodiKfwE8eWS85pyxuozDmfy563vEWFr6KEhRqPAyEEzX7XrLO8JdJZusNJGsT4+pparGtRN9IzV9Tz9StPnqzhVYTHaWNfzM2A9BKItKmJYTNxp0C8DYl505a3fF3DJfXeQcvbNFHqNjUMgcMY3W1qxcWlDJe6rmnxVhEDsRTNNjNhQce8zQ8++pL1PPyxi4vT8DVVy3ELAuzpjCCt4pUuP6y+GPbcPeZtDcTTBWUk5m7MWyFOu0HAZScsvRUU6c3kbzKtNS66wrPL8tY+oMZbkxtfayyLVc1KEL3jvJV5y8h0oTJOBW1iMfa+PWpiuF09bBS4gS3LW8IYW8zbw3t7WPGxv9PWE53MYVcFlqW4tcalRNA0tk0qdZvaDVEk6Fz28t8jl5kgk0hndZeFMRCMp2kwIiquscpKPmnxNkXYbcaIlbI11cXa1gCRZIYH9vSQy5kCbvVFEDwIfQfGtK1gLE1jvin93La8FdLgdxLMeSpoj5WmxnTvtATc+XIjs4Uj/SoGxpMJTiib+KrzVvCLd76AyzYuGH3hScaq7t/hWAa9e9XEcEeR1Q0KYt4M04OQjle0/VueUK3nth6ceyKhM5zEYRPK2hwPTqtFZkipkBJL3HCud6v1WiyVVZbCeHAqhjensPoX1xFW57jKSj5p8abRMFim4a0/fZw7rbpvqzap1/2bx7StYCxNszC7DMzhmLdSGnxO+nNuZZ0ZIdEjlCixvM2ymLej/XFA4kj2T8jy5rLbuGBt87TFuhVi1RXrdS9XFrdESJXHqVlStFxevAlLvMUq2n7OtGBPs0FxWugKJWn2u5TFa5rdpqVflVJL3HB4zQxjJd605a0SQok0UkJARqrOZQpavGk0AEUFUre2mRe2xjVQs3jM4q0/lqJJzEPLm9dJT9oFyBED28NmzBtAS42bUCIzaomEauJoME6diCJymVnb+uykJXUA7MEUa4cehZ7dqkh1AVZ7rKQwwz8qtLxlTeN1peJiNtEVTtBc41YPKImBaXWbllraCgv0joSnsB2bFm8VYXXR8OdCVVegF7R402gAVUz55+94ASsavfmWTwihrG8H7htTyZD+WIolTlO8zNGm9OVo8DnpTpk3+WFio6SURTFvVn/H2dRl4Wh/nPV+s9PABBIWZpKTl6j4nQeTa0EY8PB3QOZg0WlFy1luuiRmsfEKxZsVejATVsWppiuUpDXgglRYHbPpTFgo7W06LstbnRZvFRA0Sz55MtXXGgu0eNNo8rxwXTMXrmtm29EBslbc26pN6kLX8WzF2+mPplloD6sncvv86bBR63HQnTbF2zBxb8lMjlQ2NxjzZmZjz6akhSPBOGsD5nhnqThf3eznlScv4vNvOA8Wnw5tD6gZi0vEm2nZyWCAzTl2t+lcFG/hBC01rsG4sWlNWCh+X2qJGw6vw4p5y5iWt+Akj2zuEYypBzRXakBb3jSaaufkpXXEUlm2HzPFx8oXqlfr5lYB/bEUrUZoXrlMQT3d92bM2KhhLG9WX9O829S0vM2mpIWj/XFWeEzxNkvbnxmG4Dv/fipnr2qENZeqifUrwV+cHW2VCsnmAIe3crdpbm7GvCUzWfpjaVoD7nG3xpoIpZZMS7ytbPLx6lMWlVsFAK9rsJcunnrIxCs+l/OVflO82VPBqox50xVkNZoCNq1vwW4IbnvuGCcuqVXZd3XLx9TntC+aokGEhtwI5zpel52QNEtKDGN5C8VV55GafMLC7LK85XKSjlCCJYusquuz0/JWxHnvhxXnK/FWgi0v3nKmeKus9IdleYO5ZXnrjagbenPABfFjauI0Wt5KsSyb935404jLFblNfVZz+iA4dEWE4eiLpnGRwsjEq1K8Vd1zkRBioRDiZ0KIbiFEQgixXQhxYcF8IYS4TghxTAgRF0JsFkKM3FNEo6mQBp+T89c2cdsz7YMlQ5acCUe2VryNYCxNfS44a4PZx4vPaSOMeTMYzfJmuk3rvQ7shqAnMjssb6FEmmxO0ijG35S+6nC4lXirXTxkliUOMjmpbvSVxryZP518+MEcwQpir/M6CixvM3djr9Rt6raXZJuCjnsbhb5okkbDfFjRbtOREULUAQ+hHtcuB44H3gcUdA3no8CHzOlnmvPuFkIEpnWwmjnLv522hKPB+GCz+iVnQugoDBwddV0pJX2xFIE53pS+HB5noeVtoOwy4YSyvFkJC0IIGnzOvEWj2um3bt5yQFminN4ZHtHUYhgCIcwEhHG4TTPj6A1czVh9i2s8jkHxM41u01IqFW+GIXDaIG7FvIEWb6PQF02x1GM+VOqEhVH5KNAupXyrlPJxKeUBKeW/pJQ7QFndgPcDX5ZS3iql3Aa8DQgAb5yxUWvmFJdtXMDCWjc3P9ymJiw9U71W4DqNp7PITApPdv7FvPmcNiKjWd7ixTFvAI1+16yxvPVFlcgMZCfWXWE2YTdEgeVtbAkLmezcsrxZ4q3W45iRhIVSKhVvAC6btryNhb5oimVuM5yjCt2m1Rbz9mrgTiHE74CLgGPAT4DvSdW3aCWwALjLWkFKGRdC3A+cC/yodINCiKuBqwFaW1vZvHnzlH6ASCQy5fuYb8zEMd1Yl+H+/T3ce++9GDLD+YaTY4/8kX3ddSOu1xPP0WB2V9h9tI9jVfhdmKrjubc7QxwXOQwO797GgczQfTxxWN38tj21hWNu9exopOLsPzY7fjdPdynLYabvECGcPGmOeU7/7qXkwMFD9CWS2EIhnqrgc/b2KQvdth07aAzvHdduq/GYPn5EfX93PPME/vZnWSps3P/wlhmrvr9j+/N4e3dVtKxTSA4cPsYjngHOAXY+/Sgdnf5R15uvHDgW54JsNwBbtu8nemjog8hMfkfHLN6EEG7g5cBq4EdSyqAQYjXQL6XsG3ntUVkFvBe4HvgycArwXXPe/6GEG0BnyXqdwNCADUBKeQNwA8AZZ5whN23aNMEhjszmzZuZ6n3MN2bimB5xH+Tug9s47rSzWVjrgQOnsZQOlo4yjm1HB2i6fwcA6047n3XHj7z8TDBVx9PX1gdPPELWWcPy1jqWl9nHrvv2wfM7efFFL8TvUpefP3c8xROH+mfF76Z762F48lmaPVlcNSvzY57Lv3vnPXeyaPESGsKLIXi4os/5w92PQG8fa9auY9NZy8e132o8pnvu3w/bdvCSiy4gcPdfoLeBTRddNL2DuPPv+X9PPvFENp3QWtFq7gdvJ1DfyDkXnQuPwnHLWjjuvE1TNMjZz+ee2MzqgIAuOPOCF5eNCZ3J7+iY3KZCiDXADuCHwP8CliP4P4GvTtJ4npRSflxK+ZSU8ibgO8B/TcK2NZqKWd2snkj3dZkBq0vOgGNPQ2bk2KyeSJImqzXWPHObWhltaYd/2GzTcCKDIZSL1aLJ75o1MW9WwLoj0TdvElJshlAxbGNym6rXueg2Vd9fO8R6Z8R1/uO3nsEXXr0RGKvbVCi3qdMPhl27TUehP5qi2WZe/6vQbTrWmLdvAXcDrUBh5OpfUW7OidIObC+ZtgNYZv5vNp2k9FGjtWCeRjNhVrf4ANjXbXZKWHImZJPQ+dyI63WFkjQyP8Wbz2x+nbL5R8w2DbgdRfWqGv0uYqmsKiBa5fTHUtgNgYj1zo1M0wooFm9j67CQmWPZpgNx1drNMATE+mbkO/CiE1rzD5fGGGPe4qmscvHqFlkjks1JgvE0DSKsxG4VJiaNVbydC3xdSlnaiPAQMHyFwMp5CFhfMm0dcND8/wBKpL3Immm6cS8AHp6E/Ws0ADT7XQTcdvZ2meJt8enq9eiTI67XFU7MX8ubWQg0aRvZ8mZlmgIgJacG7+IksW9WWN/6YykWeHKITHweiTfDTFjwVmx5y+YTFuZetmmtlWwT7ZmxEhILat3YDcHCWnfF6zgtyxto8TYK/bEUUkKdDFathX082aaOMtOWgWVumBDXA2cLIT4phFgjhLgSuBb4HoCZtPAt4H+EEK8VQmwEbgYiwK8nYf8aDaBKWKxvDfDMkaCaULsE/K1w9IkR1+sMJVnkiIDdDa75Vb3Ga1re4jbfsJa3sGl5y3P/1zn76Y/xV9f/I739tukY5oToj6ZZ7jGtT1V6UZ9s7IYwS4Voy1uReIv1zth3YGWTj22ffQnrWiu/xrhsZocF0OJtFKys8ppssGofwscq3u4CPljwXgohaoDPAn8vv0rlSCm3oDJOXwdsQ8XV/T/g+wWLfRUl8r4HbAUWAi+WUoYnun+NppCLjmvh2SMDtA/Elath8emjFuvtDCVY7IioH/wc7Os4Eh6Hsrxt65UkIuVvDKFEJt9dgWgP3PcVgisvZ19uIc1bvwmyum/2fbEUy5xmHEyVXtQnG1u+VIhPhQ7kSh0vQ5nLMW+1HgfkchCfGbephdthG32hAlw2QSieLuhvqsXbcPSEVekib7q/an/nYxVvHwLOF0LsAtzA74A2VBboxyZjQFLKv0spT5ZSuqWU66SU3zEtbtZ8KaW8Tkq50FzmQrPem0Yzqbxkg0puvvGBA8qSsPg06N0zYlPnrnCSViM8b6wyhdgMgctu0JN2k42VN8SH4gWWt6d/Bbk00XM+wo+yLycQ3DGqW3qmCcZSLHGaVsV5UoTZbhOks7nBVkoVuE7Tprs0k8vBH98N3z0dDj4ylcOcFkIJFfNGIggyN6tc50JAbzTFO2/eqpvTj0K3WXfSlazexKQxiTcp5VFU+Y6voGqqbUUV1j1NStk96aPTaGaQNS1+XrpxAT958AB/fOooLD5DzTj21LDrdIUSNIiBeXNjLyWZyRHGi1vGylrRwoWWt+f+AEvPwrXoBP6ZNWMK99877n2nMjmetdzcU0RfNE2rzYyD9FfnE/lk43XaVaxUXryN7jpNZZR4s6VC8OxvoXcvPHj9VA5zWghZlrdYr5owiwo1r61Tt/tH9vdqy9sodIeTCHLYEr2z3/ImhHAIITqAVVLKn0opr5FSvldK+RMpZWWBEBrNLOP7bzqNJr+Lh/f2wKJT1cSj5V2nuZykO5KktorjJKaDsPRgI0dfcOjNQcW82SHcAR3PwbrLCLjt9FFDt3897N887v1+f/NeXvl/D/H527ZzyxNHJvAJyiOlJBhL0WxYlrf5cY59TptytTnMjLsKLG9JU7yt6HtQTWjZAIcercjlWq1IKVW2qbtQvFVf26ThuGCJg4+99DgAko4aSIUhm57hUVUn3ZEkzbY4Ipep2t95xeJNSpkG0sDcCmLQaEZACMFpy+r427PH+OkT/cimdcO69oLxNOlsDl+mf95YZcoRRt3k9x0q7gWby0kiyYxyO+39l5q49kW47DacNoP9/tPh8GOQGV+rrGePKFftjQ8e4MN/eCbvupssIskMmZykQQbBGRi0RM1xfC470WRmbJY389ivCD6urFPnXgPJAegqrQQ1e0hmcqSzUj18RHvUxFnkNgVYUq/OYb9UpZC067Q83eEka3xWYlJ1XsvHGvP2XeDjQohqa6ul0UwZpyyrI52VfO627bT7TlBJC2VcggPxNLVEMWT1Pq1NB2GzOf3h9uLSi9FUhpw0m9IfuF8do1ZVbNTvtnPAtR6yKejeOa797u4szll64uDkuoX6o/+/vTePk+2s6/zfT51ae9+Xu2+5N8nNvgDZICiEXRAURFHUAZwRcfQnoigyOM4gM6MivxFRdH7ooOACimwGwnITSEhCAklu1pu73769d1d1176d5/fHc04tvdzu6q7qqur6vl+vfnX3Oaeqnnqqu+vTn+/mzLW0W0uctwcs4pk8+J03/HU4b27YtD91FoaPwt7bzIkLD9VolbUnmjJ9CLuC3qLz1qD5UKuxs8eIt9mcK94kdLoSs7EM+0LOz3mDvsaVirc7gNcDF5VS31RKfbH0owbrE4S6c+fhYv7a1xd2QXwaFi8uu24xmS3p8daaOW+dAW/BeUvHI2Xn3De/zqDPhJ53vaBQkdsZ9HLas99cOFl5/dF0NMVYOMnvvvoKHv3Ay/BZirufrG7f7nDCtA/oyEVa6vVt9y9x3jLrCZvmAc1A+jwMXAY9e0z7nPkztV1sDYmlzc9vR6l4azLnbafjvE1mnf5wIt5WZCaaZnegsavKKxVvs8Dnga9iGvPOLfkQhG3HlTu6eP6/v4pff9lhPj/ljNddoWXIYirLAG4+VGP+t1Zr7n//j/DxX7gTALWkUa8r3vpVzCSw77qpcK4j4OW0PQzekMmFq5Dnp0wRwdEdXfR3BHjdNTv4+4fOLXPjNsO8I95CmbkWc968RrgUct7WV7DQzyKhfAz6DxmR3rMXwmdru9gaEk0Z57Uz4OS8+dqbLnQ+0B7A7/UwlhTxdilmoml2eJ3CpAYVbxWFP7XWv1CrhQhCI+OzPLzu2lH+7Bt7yCsf1sVH4Ogbyq5ZTOYYVBHzTcf6hkVvN7qCPuh2krjT5cLJffMbjTt5T0vE22JGmxDbVOXO25zTVHOwMwDA777mCr74+Dhf+OFF3vfKyyu+v5WIOOLNn5ptLectYJHI5NHeIArWDJvm8ja2hgNqwhzov8x87t0LkXOr37DBKTrH7lzT5nLdwIzTGu0Ocj7pFI4kxHNZSt7WzMfTDHmigIJQYxalbGTCgiC0JAcGO7hstI/nrUNw4eFl56OpLEOueOsc2drFNRLBLgA8mXLnbdERbwORJ0B5itW7mFBqNJWD4Sth+pmKHzLsiLfedj9g5qUOdwWZXEht6Cms/BhZvOSwUo3buLMWtAe85G1NxuO4NWs4b26l6QGPI94GDpnPPXshfL5Wy6w5rngrhE2bqNK0lKDXYo5u801itr6LaUCiqSy2hh69YF5jqzFT/CtalVLqOJeoNtVaX7PpFQlCA/Paa0f59jcOceTi3ahssixsspjKMqgiaI8PFeqt4yrrTMCIN29mqfPmJHzPPQ5DV5aND+sMeomls9B30LyhpBYg2L3uh5yPZ0xkzh1dBIx2B5mopnhLZBhQznNqpbCpM/Ysrv0EYE3nzS1W2KVmyOPB6t5tTvTuNRWnybDpM9ZkuM5xV9Bnqk2bNDXCayniOmBSFGLT9V5OwxFJOK+z3dj/pFXqvH0Ok/PmfnwRk/u22/laELY1r716Bw/bl6Ps7LK8t8VkzjhvHcMtNxqrDH87afwEs+X5NIupHAqb0PQPzaixEjqDXmKpHPQfNAfmTlX0kPPxDN0hH16r+CdtpDvI5GJ1xdveoJvE3EphU0e82SYkvaZ4c9qEDBNmweoDjzPGqXef+dykeW8F5y3QvGFTAK/lIWtjhElcnLelRJJGvLU38GgsqDzn7fdXOq6U+k1gb1VWJAgNzJ7+Nqy9L8IeVyw+ey89++8onFtMZRm1FlEdrfPGviJKsWj10JadLzscTWXZrybxpBdg181l5zoCXqKpHLrvgMmrmj9txpGtk/lEhr42f9mxka4g33hmCq01qgpiOhzPGvGWBFroNW73G/EVyztvF2uETV3nbUTNE7YGKAQXu3eZzwsXy0LmzcKyatNmFW8eRd7Wxj2Oi/O2FDe3NZgJQ3vjyppq5bz9C/AzVbovQWhoPvTmWznBbmafKh/ltJjMMqwirZ3v5hC1eunML3Hekjlusk6ab0qKFcC8IeZsTbpzL6Aqdt7C8Uwh381lpDtIKmuzkKxOF/lwIsMuX2NXoNWCgvOWU+Dxrem8pbImGX5IRQhbJXlhbhFPkwqGaCpLyGfhszOQiTW1eMvmbcd5k6mWS3H/XvjSjTsaC6on3l4MrN38RxC2Abt625jovoEdsSexc0VhEE3l6CfSUq7MasR9fXTlI2XHoqksN/vOmJy4gSNl59xh9dG8zzg085WHTfuWiLfRbpOPWK28t/l4hlHLKcJoode4PeA4b267kDWct0UnvDiswsypEvHmvhE2aZ5VNJUzrlvScZSbVLz5LA85W0vYdBUiiSw+cljphe0j3pY25VVKfUkp9Qjw15hB9YLQEoQuu4M2Upx84oHCsXgySZdehA5x3pK+XrrtSNmxaCrHtep5Ew71lP/p6XTcnWgqa3KjKsyLmo+vEDbtDhIgQ/bpr1ZlpmYkkWXIs2iazfo7Nn1/zYLrvBWG06/hvC0mswTI0KtizHmMwDk5HSWS1qbtQmyq5muuBdF0rnw0VpMWLFgeVSLeZsCu7hi5ZieSyNLXBP06K3XeljblnQa+AbxKa/1fq7w2QWhYdlxmcnYiF58rHPMk5vCgW8qVWY10YIBeFsrGiKUTUQ7aZ2HnTcuu73aqRBeSWdONP3Jh3Y+ltSacWB42He0K8L98f8k13/kl+NrvbOyJLHmMPhZNsUILFaS41aaxdA78bWtOWFhIZhlSJmQ+6zhvL/uT+3jjJx4wodMmdt46A95ie42mdd4Uubxt/k7ZOUhF6r2khiKSzLAv4FaVN+7fcmnSKwgboD1kQnKZTKZwzJ9y8kck541MsA8fedMWwumHNRh7Fgt7WbECQHebEW+RZNaETaMTkMuA17/s2qVE0zmyeU1fu6/s+GD8OX7M+h7zwT30PfQXcPM7iz3HKiSZzZPO2S031xRKnLd1hk0XklmGccQbfYUWG6dn4nDFUBOLt6wJ78fGzIEmbcTt9XjI5XUxJBifadqedbVgIZFlf2ABMkDnaL2XsyqVhk09SilPyfcjSql3KKVuq/7SBKFxCTniLZtNA8aZCaacNyUJm5INmnBDNlp8o96bfMp8sWu589brhDwjiQx07wb0ivNjVyKeLpmZWoJv7EEAPr3jdwEFx/+pkqdQRtjp/dSZC7dUmxAo5rzF1xk2Nc5bBIBpespzDjuGmjZsOhtLm7zKqDMzt0nFm2UpsrZddJWi1Z0B3OxEkln2+JwZ1V0767uYS1Bp2PQrwHsAlFIdwCPA/wKOKaV+rsprE4SGJRQ0Pa9yjvMWTmSLOV4NbLVvFXabEW/pSPGN4VDmWeZ8O1bMI3Gb60YSWehxmrourC90msqanJ2gb8mfs/PfY8ozxCPZ/XDgJXD8nyt9GgXcCQ5tmVnobM437Y3id3rnZXK2I97Wdt5GnLmQc7priXgbNk6PXrXXe0OStzUTkZQZ7B6bNnNNA82Z9+hzW4V07jAHRLyVEUlk2OUJg8e7fQoWgJuAbzlfvxFYBIaAdwLvreK6BKGhUZYj3hzn7WI4yZATKhLxBnaHCTfkwk6ISWuuzD/HeOdVK17fFfKhlONwuR3515n35ramCHqt4kGt4fxDnGu72oiHy19resdV2ILEJZzI4CWHPz3fcs6qUspJcredsOnaztuoz1wT1h1MRErEXseQuX0mVsslV53paIqcrdnZE4LYZFMLeK/lhE3d9I7oeH0X1GBEElmGlPN77qlWQ47qU+nKOoCI8/VdwL9qrbMYQXewiusShMbGmXeXyxpH5mIkyaBaIBfoAW+gjgtrDPI9e8lpD3r2BAD23BmGVZjpnutWvN7yKLqCPhYSmZJmrhWKN1+JeEuGITZJuPsKphZScOhl5vjJb2zo+YQTWQZYQKGb+o17o3g9yrzhrzPnbciKkfB0cHIuzW//y/HCOdsNOTdZ3tvFsHnOBeetSUOmUNLnLdBh2vYsTtR7SQ2D1prxhSTDeh66dtR7OZekUvF2HrhNKdUOvAK4xzneh/R5E1oJy+Ro5V3nLZI0eT5SrABAMBjinB7GM2fEW+bUvQCEh1646m162nzGefMGzJvjOnPe3LBpwFvy5yxyDgDdu49oOke0bZeZm/r8PSvdxZqE45lCHlcjJzHXCp/lIVsQb2s7bwOeKHFvz7Jzca+TGN9keW8XHfdwV0/IhBmbWbxZTtgUzM9yVMSby2wsQypr05efha7G/j2vVLz9CfBpYAy4CNznHH8xcHy1GwnCtsNjcrTyTpPe8UiSYU8EqwVdmZVo81uc1jvwh81EBfvMd5nR3eR6L1v1Nj1t/sJcQTpH1p2Lk8oZ5y1Q6rxFzgMQHNgHOI16L3s5nP3ums7RSoQTGYaVGxZvvdfY8ijyto32hdBrtApZTGbpVVHi3uXD58Me51iTOW9jZc7bVFP/k+b1eIzzBkagiHgrcCFsfrbbMzPFnMAGpSLxprX+S+AW4BeB27XWbne/U8DvVXltgtC4eCxsFHbOCZuGk4x4FlBN/Ee9mrT5LU7qHQQWz0I2SeDsN7nfPkpHyLfqbXpCvsJcwUocgXQhbFry5yxsnLfB3WaSw/NTMRM6zSXh3P0VP5/ZWJq9bu+nlnTeFFlbc/+5OOlkrPjm75C3dSF8vZDM0mMvkPR1F86/7UV7AJilxxxoMvF2MZKkt81HGxlILzZ1XqvXbdIL5mdZwqYFLswn6CCBNxffdmFTtNaPaK3/VWsdA1BK+bTWX9FaV/4XURCaFaXI4y2It7OzMfp1uKn/qFeTkM/L8/ZOPHYW7v8YVirMF/O30hFYvbVkb5vPVJtCZc5bodq01Hk7B8FuDu7ZieVRPDOxCPtuN9MRTn6z4uczvZhmn38RUA1dgVYrTG8wm0fGUwRVllSmfF7sp+4/w10fNYGYhWSWTnuBpOO8veP2/fzUzUa8TefbQHmaLmx6fi7B7r624rqbuGjF647HAiPeYpMyZcFhLJxkRDnjz7aTeFNK/apS6k0l3/8fIKmUek4pdeQSNxWEbUfe40XnMsTTOWamx/GTbei+QFtJm9/im/YN2MoLx/6QrL+H79jXmPFCq9DT5i933uIzkF97qPyKBQuR89Czh6DP4sBAuxFvvhDsvW1DeW/T0TQ7vY7jYlXU23xb4LVMwUJCm2KcdDJedn4snOT8fIJkJk8ik6MtFyHq6QJgsDNAf4fJEZ1L5J2xTM3lvJ2eiXFgoL3oGDZx6LwwYQGge6eZstBkYrpWjIUTHAk1h8NeqfP2q8AMgFLqxcCbgZ8GHgP+uKorE4QGx1ZeUuk0b/rEA8U2IQ3+C79VtPktFujgyQPvAMvPYzd9hCxeOgKXCJu2+VhM5cwbixt+XsebSrFVSGnBwnno2QvA4ZFOvvnsNL/wqYexD70M5p6veHbqTDRtpgY08Zv2ZnBDbUmMeMumylt9ZBwxML6QpJMkls4xY3cCMNQVKDiuiXTeadTbPOItkckxvpDiwGCHcamgqSuOLY/C1mDbuvA74uaItjoXIykOtznibTs5b8BO4Izz9euAf9Za/xPwIeBFVVyXIDQ8tseHnxzPTkYZbhKrfasI+Y0L9tCed8H7znCm93YAOi7lvDn5cIupXFEEryN0msqtEDYtSSq//ZBpCvzt52b4u1lTMDH2/S+t+7lorZmJpunT8y0rzk2ozSaFcdCyS5y3jPMajEeS9Crz5jeVawdgsCNYeG1S2byZUNFETs+ZWfNcDwy2Q7T5w6Y+p+lyztZmjjCIeHOYiabZ43WmKzT473ql4s1tygvwcsBNHskCwWotShCaAa18eDGuz+1DJeE+gTZnmHkia/pJRZ0RVpfKeetxRmSFE5mSBqJrJ1MvC5vms6bPm9NT7Kdu3s1Tv/8Krt7ZzQfvT3PeHmTs+180zsM6WEhmyeRtunJzTe24bAavR7GYzJF0wqbZdLl4cwsYxiNJenHEW7YNgL52Pz7Lg+VRpjK4yYbTF8TbQIcRncpq2qH0YF5LwDRdLjTEPlfHFTUOM9E0o54whPrA19iSplLx9nXgr5RSfw0cAv7dOX6UoiMnCC2Btnz4VI7XX7eDd1wbAlRTtxCoJpZH4fd6SGSNaIul1iPeSkZkVeC8pXM2PstMAQAgPms+O2O4lFK0B7z8w7texGfe8SLie+7k6szj/M13nlvXc5mOprHIE8q0svOmuBBOkHSct1yqvF2IK94uRlL0KCN20j6T8zbg5LsFvR6SGbsYNm2SJPkzM+b57B9oN2HTjqGG7ry/Fu7vSTavwd9mchDFeSNva+bjaQb1XFPkLlf6E/hu4H5gEPgJrbUTK+IG4LPVXJggNDpZbeEjz97+djNipn0QrNVzulqNNr9FMmNcsVg6S5vfKgqsFegpHU7fNmAcjnU6b2WjseIz5vOSqtD2gJdbDw1w+e1vpF2l+c49X+DxC5E1738mmi5OV2jZnDePKUhwct5y6dXDpt2Yc7/x+hfxh2+8mqEu42AEfVbRebOzkIps3RPYBOMLKfrb/SYVIDrV9BXlbti00Ki3Z4+IN2AunsbW0JObafgGvVB5n7dFrfV7tNav11rfXXL8v2itP1z95QlC4+L1BfCS58WXDZheSU3wC7+VtPksEgXxlruk6wamVQg4zpvHs+52IamsXd6gdxXx5qIO/gja38lP+h/k3Z/5ATPR9CXvfzqaaunpCmAqFLWmEDa1l4q3vBEC45Ek3coUMwwNjfLWF+wpXBP0WSbE7YaemyTvbWoxxbAjQIlNNXW+GxgXFShWnPbskbApMBs1qS+d6YniiL4GpmLvVyk1rJR6r1LqE0qpAefYbUqp/dVfniA0Ll0dIV5ysJub9vUZh6jBO3JvNaES5y2ayl2yWAGgJ1SS8waOeFvbeUtn8+UNel3xtppD4guirnw9r7C+TywW432fe/yS9z+9mC5OV2jZnDezv67zll/mvJnXeTySpAenEjXUU3ZNwOchnbWL7uU6+/jVm8mFFCPdpeKtuZ03N+ct6zpvvfuN87aOtjzbmZlYmi7i+DMLZk8anEr7vN0IPAf8DPAfgC7n1MuB/17dpQlCY6MsPyHL+e918aI4b0to83tJZJyct3SOzjWct86gF48yBQLmwOg6q03z5ZWmBedtYPUbXfOTWNkYv33gNI+eC6P16sULpsebU4HW5K7LRnHdGjfnbemIrKzrvC2YnLe8r2NZCkHIdd5c8dYkRQsF5y2fMz9bTe6+ukI877xmDFxmer1V2D5nuzETTbNHOW5w3zYTb8AfAR/TWl8PlMYavgbcVrVVCUIz4PGZ/1azSVPdKG1Cygj5S8Km63DePB5Fd8hX7rwtjq/5OKmsvdx5s/wQ6Fr9RvvugM5Rbk18m8VUjtlYZtVLp6Np9gWigGp612WjuG5NIWyaKZ8P6+a8ZXI2PSqGDvYsu4+ynDco9kxrYNK5PHPxDCNdQeMCa9s0tm1iXCGedQtGBg6bz7Mn6rSixmAmmmavcv6h2G7OG3Aj8LcrHJ8AWjOeILQuliPe3NCehE3LaPNbJEvmXXZeokGvS2+bv3xEViqy5iD55QULs6ZNiFq9OAKPBVe9iV1z99PHIqdnYqteOhNNscdyGvS2aEGK10lyd/u8kV252hSgm9XEm8eMMgt0gjfUFM7b9KLxKEa7g8V/JJqgEvFSuM5bznXe+g+Zz7PP12lFjcFMNM0hryve9tZ3MeugUvGWBHpXOH450Pi/iYJQTSwf5DPFwc4SNi2jrcR5m49n6HNaRlyK7jZfedgU1gydprJ5Akudt7a+tRd4/dvw2Fl+3Poup2biq142HU2zwzPX9I7LZvA5bk3CyXljSdjUdd4AulUc1bb8bSLodcKmSpncwSbIeZtaTAEw3B2ExTFzsNnFm1XS5w1MbmL7kJk80sLMxNIc9s+aQqdAZ72XsyaVird/A/6LUsr5DUYrpfYB/wP4fDUXJggNj+U3LQ/EeVuRkM9LMpPHtjXhRIb+9rXFW2+bvzxsCusQb3a585ZagNBK/2MuYegK9M6b+CnvMU5NR1e9bGYxzWB+punftDeD5bo1eMlqC5VbIt5KnLce4nhWEM9BX9GJNY16G7/adMpx3oa7ArBw0RxschFfaNKbL8nzHLis5Z232WiavZ7ppgiZQuXi7b1AH2a+aRvwXeAkEAE+UNWVCUKj4/GasGkhnCLOWynGecuxkMxia9Npfy16Qr5i2NSZkLDWEPNlBQupBQh2r2uN6vq3cZkaI3PhkRXPJzN5ouks3dnpYjf6FsTnvOErZYoWVK48lF0aNu1RMTwrOG+FalNomikL83Ej3vrbA+b33N9x6VzKJsBbGI9V0iS5/1DLi7eZWJpRe7IpihWgcvGWA+4E3gD8FvAx4JVa65dorVePOwjCdsTyF3PefO1N/0e92rhh07m4cdLWI96620rFm9Onza0eXYV01i4Pm1Yg3rjqjWRUgKunVx6XNRNN000cn51qesdlM7ihtoDXQ4rAMvGWcaZcgKZHxVZ0PgvVpuCIt8YPm4adn8WeNp8Jm3btvHQuZRPgW9F5OwzJeYjP1WlV9SeyGKM3N9M0ztuly79KUEpZwAJwrdb6W8C3arYqQWgG3IIFt01Ik/9RrzYhv0U6ZzMbM+7FesRbb5ufWDpHNm/jc1t9uOOuViGV3bjzRrCb8Z2v4JUX7uHs5CwHdpQ39p2OptipnMeXsCl+y0NaB/DkUmXns3nNUGeQcCSMj/yK4i1YKt46h83rlE019AzJ+XiGzqDXTCVYuLgtBLxVmG26JGwKJu+tvXnntm6UdC5PV3ocT0BvP+dNa50HzgFr/wUWhFbA8pmct4Wxlg6prUab3wiq+04Y52xdYdPSKQuWz4iANcJr6ZxNwOv8KctlTCXkCtWOq2Hd+LN0qSRz3//csnPT0TSjynEjWvg1dgsW/F4PKRXAyi933oa6AiUNelcSbx5SuZKwKTR83lskkaHXGdvG4vi2aAfkhk1LQ90F8daiodPZWKbY4613X13Xsl4qDZv+AfARd7KCILQ0HqfadGGsKcapbDUhvzH2//zYKWC94s1cs5B0ihbah9YMm2ZydtF5Sy+az+t13oAd17yM83qY/hP/uOzc9GKKUeWMcN4GrstG8ZY4bxkVxFsSNtVak8nbDHcG6XaG0q8knoNei7ytjWhwmx03eN7bfCJrxrblMkZodjX/77krxPOlzlvPXpMG0qK93mabrMcbVBA2dXgvsB+4qJQaA8ry3LTW11RrYYLQ8Fh+0zIhl2xpV2Y1SttHwPoLFqCYa0T74CXFm20b4eB33ARSziSECsSbZXl4uPfV/ETkUzB/GvoOFM7NxNLs9MyhPT5Ue2s26IVy5y2TCxC0i2FTd7rCcFeABXUp580I7FQ2j89tdtzgeW+RRMb83EYnAL0tBLwbNs2W5rx5LOg72LLO20w0zT41Sd7bhtUkjbgrFW+fAzQgyT2CYHmNcANx3lbgJYcHuXtfL98/a+aCBkrbeayCG6IqFC10DMLk8VWvd1tUFAoWUhHzeclczbVIXvkW8vf/DamHP037K/9L4fj0YpqrfWFU1w7wVDwKetvgvuH7LA8ZFcCbXyicc8NvQ11Bptz/51cJm4Jp7dLptoFp8LBpOJHh4GBHSUV584dNfStVmwIMHobJJ+uwovozE0tzmRoj338Yq0lyl9f110gp1aaU+jjwLuBXME15P661/v3Sj1ouVBAaDqvESRLxtoxDQx3883+8taLbuDlvhV5vazhvacfd24zzBnD08su5174Wz+OfATtfOD4dTbPLM9/yr6+bJ+WzPGStoKm+dXAd1ja/xYjP6f+2hvNG2wCgGj5sGo5nnUpTp8fbNgibun3e8kurqwcOm/mmufTyG21zZqJpjnjGsEaO1nsp62a9/0r+PvDzwFeAzwIvAz5RozUJQnPgKRmV1OJv7pfi4d/9Ub75Gy9Z17WueFsoDZumFlZ9Q0nnjNAKuDlvyYj5XKF4u2ZnN1+2fpRQchJOfbtwfDqaZpi5lq40hWJ7CcujyHpC+O1izpvrvPm9HnYGnddpLfFmeaF9oKGnLGRyNrF0jr42f1G8bYOwqZu/WBY2BSPedN6kDrQY8fAkg2oBa/jKei9l3axXvL0R+A9a63dprf8z8BrgDU77EEFoTSwRb+thqDNoQk/roCPgxfIoIskS5w1WbRfiuj6FatMNOm9ey4N9+JWE6UL/8NOF43OLcfpyMy3/+rrOm0dB2uogpIsTFtzQtc/y8BNXtqGtAPhCy+6jKN6ccF3nSHE6SQPi/gz2tPtNm5BAV1OMTVqLwngs53WbjaX5yhMTTAedeZ4tWLQQmHee89Dl9V1IBaxXvO0GvuN+o7V+GNOwt/kTAARho7jirWMYvIFLXyusC6UUPSFfecECrBo6TVdJvAHccWQHn8/dBs9+BeJz5PI2KjGLRX5bOC6bwVuYsKDIetsJ6SQ4OVOlArpXxVGhnhV7HhZy3hy3lO7dxZFTDUg4bn4Ge9t8pqJ8m7ivrnjLOmHTP/76c7z7Mz/g1+9xik1aULx1RU+aL4a2n/NmAZklx3JUXvAgCNsHN+etxV2ZatMZ9PKZh85z/8lZcCu/VhFvKzpvHi/42ip+3Kt2dvNP+TtRdhaO/xM/OB9hB26D3tZ+jd03fI+CrLcTDxoyZh6sG37zWR4Ttl5lrqzb9y+ezpkDXTuLw94bkOmoyesb6gzCwnno3VvnFVUHN2yad5y3M7OmyOTBi2nsrp0tWXE6mDxNwtMBnc0z4nC94k0Bf6eU+qL7AQSBv1pyTBBaB4/zv4uIt6ryo1eYBq6f/8GYyYuCNZ03f6l4C3ZvaNrFvoE2TrKbyY4r4Qf/l88+dI7DfqdBb5M07qwVbthUKUXW54TAU6anXqa0aCQZXlW8DXWaSQrTzrB3uneZ1ysdreHKN87EghFvo91BiJyHnj11XlF1KIRNHeftYiRJf7ufvK35briP6NhT9VxeXdiVPcts28GmmpKzXvH2t8A4MFfy8XfAhSXHBKF1KDhv0uOtmvzea6/khfv7OD+XKA6nX6Uqsei8Oem3lYzGWkLAa7Gnr41vtL0app8m+twx7hxyWl9sE9dlo7hhU9d5AwoNkQs5b95LO2/DXUGUgvGFJe11GjR0OumItyF/yvxcbRPx5ispWMjbmolIitddazKgTukd+MInQS+f87tdiaeyHOQC0a5D9V5KRawr7Km1/oVaL0QQmg43502ct6qzp6+Ne0/MgL8dvKFLOG9OtelS522DHBrq4B/nXsTPhPp4fexr7KbfhFJWSMBvJYriTZG5pPM2D6Mr92r3ez0MdASYiDhtRgribawhE8UnFlL0t/sJxBxxuU3Em1VoFWIzHU2RszWHhjr4kzdfy9Q3DxKMf43U/AWC/dvj+V6Kv7z3FLu8C7xGxTnbd6Tey6mI1u06KQibRXLeasbe/jamo2ne9n8eJt82sGq1aTq7Sth0gxwc6uC5uRy50RvZryboz1xsmnE5tcRXCJtCzuuIN8d5K7QKsYDEHLStPth8R3ew4Lz9wXecUWYNmvc2tZhixA2ZwrYRb+60jGxeczFsXoudvSHeeMMubnmh6ct46ukf1m19W8kf/vuz/NNX7gZANVGbEBDxJggbx++8ibV4PlQt2N1nCg6+e3KWRasX4quETfPVC5sCXDnaRSZvM0M3gypCd+oi9Il4KxYsKHI+J2y6xHkL6AzkUpcUb6PdISYWUuTyNn9zPEVOeyByobaL3yATC6livhuY+Z/bAKUUQZ+HZDbPxYgRb7t6jLPcNmJChzp8pm7r22qOKvNcA7uuq+9CKkTEmyBslEM/Cj/zORi5ut4r2Xbs6StWi+aC/WuGTavlvF23uweAk/E2BligLT0tzhvFsKnlKRFvadOWxXXegjkzBu2S4q0nyEQkyamZOHksLuoBaFChMLmQLDpv/o5Vc/makc6gj8VktpDXN9Jtikm83TvIaAt/tDEFdS24ynOWs/Yw/QPNMdPURcSbIGwUyweXvbzeq9iWHBwqNvVN+vsqa9Ib7Nnw4+7pa6Ov3c9jYT+WcpK2xXkrtJcAyPuXOG+u+5mJmOOXDJuGiGfyfO+UeT3H1GhDdvRPZvKEE1lGukoqTZuoEnEtuoJeoqkcsXQOpUxzbIBgwM+4HiAQa8xQdi24Sp3hSb2fvnb/2hc3ECLeBEFoOLqCPu77zZcCkPD1Gedt6SBtlrQKyaUhl9yU86aU4vrdPTwXK+kTJ2HxQpK7Rym0N0RWW2inxYcroIOZtZ23y4aNKP/MwyYUOevfAXOnG6660e19tm+gHSLntk2+m0tXyMdiKkssnaPD70U5wjTos7igB2mLt4Z46ybGHs8MZ3yHCj/jzYKIN0EQGhK3I3/M2wN2DlKRZdeUOW+bmK5QyqHhDmZ1yX1I2BSNEVceZYoXooSwnf1eSJpJBG05Z/8vId5euL8fy6M4MWW6+Z9jxIRfk+Earr5yTs+a9e0faN9WPd5c3LBpPJ2jPVBsOhH0ebigB+lINmb7lmpz1HMWgMm25qo0BRFvgiA0KG4RQszbZw6skPeWLu3zVhBvPZt63J09IWbpAsD2d0Jb36bubzvgmp4epfBaHqK6rRA2vTCfoDPopS0XMRddYr9Cfsu0FAGGOgOczpuGzI0WOj0zY5y3/R25bdXjzcUNm8bTedoDxRHlQa/FmB4ilA1DOlbHFW4NVznFCuHu5qo0BRFvgiA0KAHHeVuwesyBS4g3n6Wq5rzt7Akxo81jqr792yrXaaPYTlhTKYXXo4jShk6a/T4/n2BPXxsqOQ/Ks6Z4/n/fej2vv24HP3btDk5kndm1cydrufyKOT0bZ0d3kLbEuDmw3cSbEzaNpnOFfDcAj0cxoRxB7VbZbmOu9pxhTA8Q6h6s91IqRsSbIAgNiVuEsKB6zIEVxVuegNdjcnbcsOomxduOnhCLtJHWXpTkuwHgTFJCKdM2JKw7TENeiuKNxByE+sBz6beVl185zMd+6no6gl5OZAfRlh+mGmsk0+mZGAcGO4oCZptNUekK+lhM5paFTQGmvK54O1eHlW0dtq05qs5y3N7PYGeg3supGBFvgiA0JEop/F4PYY8jxmIriLesXd4mBDbvvPWGAMXf518GV//kpu5ru6B1MefN61HM0YWKT2PbmgvhpOnLl5irKMTc7veSw4s9cKThxNvFSJLdfSEInzUHtpmI7wx6yeRt5uOZZeJt1usMZw9vc/GmNQNqgXE9wJCIN0EQhOoR9HqI6E4TjlvBecvk7fIGvbBp8dYVNGPP/mvu5+DKH9vUfW0XutvMnuztb8dreZjV3aj4DNPRNJmcbcRbdAo6htd9nyG/ed0y/Vc2lHizbU04kaW/PQDzZ8zP0zbLe+wKmddzPJIsC5sCJH09pFVw+ztvGjxoutsCvOmG5puSI+JNEISGJeCzSOUxFYwrhU2zdnmPN9i0eBOWc+vBAf7yZ2/kvXcdwfIoZnU3nlySiRnTr21Xbwii42YO7DpxE+UTfVdAbHLVXn5bzWIqS97W9Lb7TQPhbVht3BU0gi2ds8sKFgBCfi+z3pGWcN48aA4OdxX+OWkm1jWYXhAEoR4EfR4zv7R98BLOW4l48/iqMkT+T99yXdP1fao1rzg6ApjikFmMQM4tmrFlHX4LopPQtX7x1uY3bz8LPVfSDzD2CBx5ZVXXvBHm4xkA+tp9xnnbhhNUXHcZWBY2DfosZrwj7NzmzpvWYGEbV78Jac5VC4LQEgS8Fqlc3oi32PL5pulsfvlorCpUh77h+p287todm76f7YjX4yn2wXNmzrblIpDPQOf696zNCZvO91wDVgDOfqfaS90Q4YQj3kJeU7CwDSdsdIWKgq3Dv0S8eS0mPEPGeWuw5snVxNYaJeJNEASh+pQ5b4nlYbVlzluoZ2sX2IJ4PYoZR7x5HDe0Le0I6w04b7G8BbtfAGfuW36RbcPd74d//FlIRja17vUyHzdNh4f1LNjZbRo2Xd15C/g8TDIEmWgxFWEbYmstzlutUEq9XymllVJ/VnJMKaU+pJQaV0ollVLHlFJH67lOQRBqQ7nztlrOW0nBguS71Ry3YAHASprXJJRyxFsFzlsh5y2Th/0vhsnjsDheftGxD8ODfw7Pfhm++t7NL34dzMfTAPRnnCkD29B5291XHP+2tGAh6LOY0E6BxtLXYxth22ApjRbxVl2UUi8C3gU8seTU+4DfAN4D3AxMA/copTq3doWCINSagNdx3joGjROQTZadz+Tt5WFToaa4rUIAvEnjhgaSU+ZkJc6bz4iGRCZP/MiPAxp++HeF852Lz8N3/gSu/Wm47qfh+XvAzlfnSVwC13nrSjnzPbeh8xb0WYWczpVy3sYL4m37jsmy3bEhyrr0hQ1KQ4o3pVQ38PfALwLhkuMK+DXgI1rrz2utnwTeDnQCP12HpQqCUEOCvhLnDZZVJCYy+ULLCRFvW4PXUuTwkg30EUhMAjifVUWtQtoKzluOzz5v8Z38VeQe/CTE5yA6yZVP/09TvfrKD8OBl5omzOOPVf8JOSwks3zzmSnCiQwBrwf/wjmw/NC1PXMfDwy0AyyrNg16PYzle80321q85QBQazSVblQaddWfBD6ntf72kuP7gRHg6+4BrXUSuA+4deuWJwjCVlBw3grirTx0msjkaHfFWzIi4m0L8DpvdsnuA3TEzExSX+Q09OwGa/0tF9qdnLd4Os94JMVHcj+NTkXI/9WPov/idvyZRXjz30KoFw7caW505lg1n0oZH/jCk/yHv32EH5wL09/uR0XOQs9e8DSnM7MWR0ZMsCqVtcuOB30WF7NdJhdsYTuLN9d5a1QZdGkarlWIUuqdwCHgbSucHnE+Ty05PgXsXOX+3oUJvzI8PMyxY8eqs9BViMViNX+MVkP2tLo0035G5lNEojaPPneBG4EnHvwW8/2LhfPhaJLIXIZjx47x4kSYselFTtfhuTXTnm6WE2ETujyf7WX/4oMApM89wkJohCcr2AOtNR4FT504xWzS5im9j3emf53/OP8lvIE+Epe/EftkDE6a+3xRYIiF48d4Jn9jlZ+R4dSYCcn/8HyYXZ0eouePk/H3cnybvK5Lf0bvGtAkdnvxTD3DsdlnC8dnJtMsZDTp9h7mTzzKc55jy+9sG7CYSPFjwOzc/IZ/d+v5e99Q4k0pdQT4MHC71jpbjfvUWn8S4+Rx00036TvvvLMad7sqx44do9aP0WrInlaXZtrPu+ee4FR0mhvveAX84H1cc2AErr+zcD73rbu5bN9u7rztABzLsufwVey5487V7q5mNNOebpbu82F46AEC+26m/Yf3MMIc7clxOm58S8V7MPzgNwn0DGB5kuzpS/LAwg0cy1wHGfjvoRAnFgb4wGuvxGd5YOwagrEphmu0z1+ceoyn5y6S13DZjn46J2bhypdtm9d1pZ/RH7tr+XU/yDzH3WdP4h88wGggz+g2ef5LmZqdg4dhYGiY6zf4HOv5e99ofuEtwADwlFIqp5TKAS8Bftn5es65bmlixTAwuXXLFARhKwj6LFLZ/IphU9vWJDJ503JCpitsGW7YdLHzEACv8T2C0nkYvrLi+xruCjK1mGI2muHISCe//arLec01pujhd+9P8rffO8fxi85rO3AEZk+aMsEaMNQVLHx9ZU8O0ovbslhhLQI+Eya2O0e3ebWp+TlSTRo2bbRVfwG4Griu5OMR4B+cr09gRNrL3RsopYLAHcADW7hOQRC2gIDXQzpng78dfO1lBQvJrAnftQesEvHWU4dVthZey1QpLnQcBOCt1jfNiaHKOzaNdgeZWEgyG0sz0BHgF2/fz5+99Xr62v2Fa+Zjpmkug4chl4SFC5t7AqvQUZK4fzQ0b77Yhm1C1iLoiLdc+w6T87ZNG/XaTuWylmrTzaO1jmitnyz9AOLAvPO9Bv4U+C2l1BuVUlcBfwPEgM/UbeGCINSEgM8inbPRWkP7QNmUhXjGVIuVOW+Brnoss6XwOeItHhjiROcLOMQY7LgeBo9UfF/DXUHGIynmExkGO4xgU0px097ewjXjC057mIHD5vPsic09gVXIlxh6Byzn56wFnbegz8iCTPsoZOPbtlGvzhvxJs7b1vE/gY8CH8e4cqPAXVrraF1XJQhC1XGnJ6Rzy+ebJtKlzlvEHAz1Lr0LocpYTtg0Z9t8dfAdLNIBr/jDDY0lG+kOkszm0Rr6OwKF4y/Y31f4ejySMl8MOOJw5rmNL/4S5EscplHbycLp3VuTx2pk3Ka98aCTnbRN24W4zhtNOsO44cWb1vpOrfWvlHyvtdYf0lqPaq2DWuuXOA6dIAjbDDeEUxxOXwybljlvSacdpIzHqjle580ul9ec8h3mDR1/D3tv2dB9jXYX88wGSsTbnUeGcAwgxiOO89beD239NXPebNuIt86Al/b4eTMtwheqyWM1MsNO7t+06jcHtmneWyHnzdNQdZvrpuHFmyAIrUtn0PxhPTcfN1MW4sWwaSLjOG9+b3HupThvNcfNecvZmnQ2X5xwsQGGu0rFWzHP7dBQB598eRsv3N/HxELJVI2BI7ULmzrO29/84s2o8Fno3VeTx2l0XEF9Puf8Li2M1XE1tUO7zpuETQVBEKrLK46O0Bnw8hf3nio6b85/zPG047yVhk2l2rTmuNWmubxNJm8XQtsb4cBgO37Lw9EdXVy7u6fsnFKKnT2hYtgUYOCy2oVNbU3Q5+HGvX0wf6YlixWgKKjPpDuNsNmmzpsr3tQGwv2NgIg3QRAalu6QjzfduItvPD2N3TYAOl8QauXOWxj8HRV1+Bc2hq/MebMJeDderTfUGeSJD93Fl99zeyFEXspId5DJxVQhpMngEUjOmxFaVSZvayylIB2D2CT0H6z6YzQDQZ9Ff7uf8cUcdIxs25w37eY4SthUEASh+uwfaCeTt4l5nTCOU7RQcN78lgmbSsh0S7BKct7Suc2FTcGIhdXcj8HOAHlbE0k6PdsLRQvPrnj9ZsjbGo9Hwfwpc6D/UNUfo1kY7TEtXOjavr3etDvbVJw3QRCE6jPi5ODM2k4bEKddSMF5CzjOm/R42xJ8llttqjcdNl0Lt4hhNpY2B9x2JLPVD53aWhthOnfSHGhl8dYdYnIhBZ2jEFs6jXJ7UKg2lT5vgiAI1cdNoJ7Mm0HaBectU+K8pSJSabpFFJ03m3TW3rTzdikK4i3qiLfuXaZZcw3y3gph0znHees7UPXHaBZGu4OmyrdjGKIT9V5OTdB5N2wq4k0QBKHqjHabdg1jmXZzwGkXkkjnsTzKOD/JiIi3LcJtFZLdAudtsNNUoM64zptSZtJCDcKmtnbCpnMnoWtXS7YJcelp87OYyqE7R4yrnUvXe0lVpxg2bU4Z1JyrFgShZehv9+OzFGeTQVP95oRx4pkcbX4nX0rCpluGUgrLo8jbW+e8zURLxMPAEZipfruQovN2smWLFVxcQZ5rGzIHottvdLit3T5vzSmDmnPVgiC0DB6PYrgryMRiFtqHTCUgEEvlTKUpOGFTKVjYKrweVShY2Ey16Vp0h3z4LMWsO98UTN5bdLzYmLlK5G2wFI54a918Nyg2x86EnCkL2zDvTTsthxDxJgiCUBtGu4NcjCShcxii5o3k8bEIB4faIZuEXErCpluIz/KYgoVcbcOmSin62wPFggWAkavN58nqDtaxtabPEzOzPFtcvBXG0gUHzYHtmPdWCJtKzpsgCEJNODzcydPji3xv2sf81HnGI0lOTMV4yeHBktFY4rxtFZZHmYKFXG3DpgADnf4l4u0a83nyeFUfJ29r9uK0xWhx8eY6b8mgGzbdhs6b0+dNwqaCIAg14gX7+4ilc5xNd5JfnOQ3P/c4AC85PFRoHUL7UB1X2Fr4LEUmb5OzdU3DpgCDHQEmSqcsdA6bKsjJJ6r6OHlbs0e74k1y3gAS3m7TxHaLnbeHTs8VGzPXCFvGYwmCINSWm/f1ATBNL/0s8uiZGX7pJQc4PNxRaB1Ch4i3rcLyKOJp8+ZXa+ftloP9PDcV5dRMrHhw5BqYqL54263HjVjp2VPV+242CmHTPEYob2HO270nZnjLJx/kUw+cre0D5Z3xWNIqRBAEoTbs6Alx2VAHO3btw6M03/+1a3n/q64wlaYF522gvotsIbweDwmnz14tc94A3nDdTjwK/vkRMyD93hMz/PPkEHrmGUhHq/Y4ea3ZZY+bgfQtPmbNDZumsvkt7/V2ctqI9DOzsTWu3ByFalPJeRMEQagdn/tPt/L6228AoDMzWzwRl7DpVuOzFMlsvvB1LRnqCvKqq0b52wfOcmE+wdv/v4f54vxulLZh7PvLrv+Hh8/zjacrd4psW7PTHm/5fDcocd5ytpmysIU5b5GEqSz2W7UVVYXB9B4ZjyUIglAzukM+/D07zDelfafis+Brg0BHfRbWglgeRTprO1/X/m3k/a++HICXf/ReAH5oH0LjgfMPll1n25oPf/UZ/vK+UxU/hm3n2ZmfEPHGEuetc2udt7NzCQDCicwaV24S7Yo3GUwvCIJQW7p3ms+LF4vHYtPQPlif9bQoPstjXBnA2oJ3kV29bXzpPbfjdYRijDZm2i+Dcw+UXXdmLs5iKseJqVihmnC9dGVnCJBu6bFYLgHfEuctOb9lUxbOzsYBzGzVGuL2eZNqU0EQhFrTPgRWACLnisfiIt62GsujyDjizaO2Jux0aKiDL7z7Nl55dITOoJfHAzcY5y21WLjmsfMRABaS2fLGvutgOGty6sR5g6B3Sc4bbEnRgtaaM454m4rWWLwVct6aUwY156oFQWhNPB7o2Q2RC8VjsRmpNN1ivJaHVM6EnawtzBk6NNTBX/zsjdy0t5d70leDnYUz9xbOP3YhUvj6+anKihkGs46bK87bcucNtmRE1mIqRyxtCmGmauy8YUu1qSAIwtbRvRsi54vfi/O25Xg9imwhbLr1Cd+7etv4VmI/BLrguX8vHD87F2dHdxCA56crq1b0205YMNhVtXU2K2XOW+eIObgF4s0tVjgy3Ek8ky8IuVrgOm8yHksQBGEr6NlTFG+ZhOnz1r27vmtqMSxlmvRCfcRbR9DLQgb0Fa+Fp79oRqQB04tpju7sprfNx5MXFyq6T6UdodCkCezVpNx52zrxNh834u3wSCcA04u1c9+00+fNI61CBEEQtoCePZCYNcItfNYc69tf1yW1GpZHFQsWtijnrZSOgJdsXpO98ichE4VnvwLAdDTFcFeA6/f0loVQ14NyO+57WrvHG1CYmpHK5qFtAJQFsa1w3rIA7OkLARQaQdeCQs6bhE0FQRC2gJ695nPkHMyfNl+LeNtSLI8i6zhvnjo4b51B444tjrwIevfDg39OOpsjnMgy1Bnk+t09PD8dYyGZXfd9esR5K2B5FD7LEegej9Ood+uctx09Rry5jaBrQbHPW3PKoOZctSAIrcuQ6fnF1FMl4k2SzLcSj0eRzZtWHPVy3gBiGQ23vBsuPsri098AYLgrwA17ewF4vAL3zaNz2KimzYGqNkGvZZw3MKHTLRBvbm+3na54y9bOecN13mrcDLhWyE+pIAjNxeDlYPlh4jEIn4FQr/kQtgyvR5F3BofXJefNFW/pHFz/s9Czh45vfxAvOYY6g1y1oxuAZycXL3U3ZXh0jjziurkEfMVeflsl3iKJLB4FQ52m6CSZqaF4s13nWMSbIAhC7bF8MHwUJh6HuZPiutWB0t5u9Qiblok3XxBe+RFCkef4De8/M9QVoLvNx0CHn1PT8XXfp0fnsZs0eb0WBJY6b1uQ8zafyNDb5qc9YF6HRCZvmnA7BSnVRLsTFqTPmyAIwhYxcg2cuQ/OfAd2v6jeq2k5vCWCzVunalOAWMrJibr8NTy36038J++X2HPy7wE4MNjB6QqGm3t0nryItwJlzlvHCCTmIFfbkVWRRIaeNh8hv3kdLn/yj+CPLoP/faNJk6gi7gQOKVgQBEHYKo682vlCwzVvrutSWpHSUOlWTVgopcx5c/jSjv+Hr9s30fmt98PDf8XBwXZOzVTivOXEeSsh6LVIlzpvUPMpC+F4lr52P21+L9er57nqzKfgiteBnYMv/KdCqLMq2OZnRwoWBEEQtoojr4QbfwH23AKj19Z7NS1Haai0Xn3eAKIl4u3CYpY/bH+fEfZffS9vSPwL8/EM4fj63CIPeWzJeSuwLOcNap73Fk5k6GnzE/JZvM17DylvF7zhE3DXfzNpEk9/oXoPZkurEEEQhK3ndX8Kv3g31MH5aXW8ZeJt6x+/M2B6sRXCpsBYOMlIbze8+f/C0R/nhSc/ys9ZX1t36NQS562MZdWmANGJmj5mOJGht82HpfP8qOeHPN99OwQ64aqfwO7ew/N3/zkLifW3f7kUbp83KVgQBEEQWoKygoU6iOegz4NHQSxdfCO/MJ9gV2/IFLS86f8Q3/dyPuj9NNFTD6/rPk3OmzhvLsty3qCmYVOtNeFElt52P5z/Hj0qzpOdt5mTHg/HB17Nwegj/PVX7qvSA0qfN0EQBKGFKC9Y2Pq3EaUUHQFvoQN/KptnOppmV2+bucBjYb3pr5ijiyt+8KF15UpZOocW561AyGcVW3W0O1MWaui8JTJ5Mjmb3jY/jBnB/WTgusL5J/tejkdpQmfvqc4DivMmCIIgtBKlOW/1Mi46gz6iTth0PGJaSex2xioBBDt7+YT35xiOPQMn7l7z/jw6T16mKxRoD3iJuzmFHgs6hiBaO+fNbdDb2+aDyeNMqGHCdvH1fCIxyFl7mCOLD7KY2nzoVEufN0EQBKGVKM1zq0fBApiKUzdsOhY24q3gvDk8O/AKZqwheOB/r3l/Fnm0FCwUMPtbMp6qc6Smzps717S3zQ8TT3DGd9D0eXM4F07wbfs6bvU8RWQhuvkHLIRNRbwJgiAILUBpqLQe47HAVJyOR1JorUvEW6jsmh39HfwTd8H5ByB89pL3Z+k8tjhvBVzx5vZDo2Okpjlv7lzTfn8G5k9xwX+oXLzNJXjUcw0hlSF/8Qebf8BCn7fmlEHNuWpBEAShbtR7wgLAa68Z5fjFBf7tsXHGwgm8HsVwV7Dsmj19bXw2cbP55ql/veT9eZAJC6V0BL3YGpJl801r57y5YdOh1BkAJkMHCzl3qWyeycUUiZEbAfCOra8I5VIUw6bNKYOac9WCIAhC3fBaJa1C6uS8vf2WfYx2B/n2c9OMhZPs6AktC+FePtLJmB4kNng9PP1vl7w/r86hxXkr0L60EXJnbacsuGHTntQ4ANHQbhIZ89jPTkbRGg7u3cspe5TQ5Pc3/4CFsGlzvuYi3gRBEISKKHXe6pXz5vEodvWGmFpMMRZOLAuZAty4tw+AZzteCOOPQWJ+1fuzyEu1aQmdgSUjyGo8ZcENm7YlxgCIt+8qOG8PnZ4D4KWXD/GofZiu2R8Uwp4bRqpNBUEQhFbCW+cJCy5DXUGmFtOMhZMrirfBzgD7+tu4J30loOHMvavelxFvzenC1IJlzluNe71FEhm6Qz6syDloH8IXbCfhhGwfPD3HgcF29vW384g+jD8TgbmTm3tA7U5YaE4Z1JyrFgRBEOpGvcdjuYx0BTk/n2A6mmb3kkpTlxv29vLF6REIdMHplcWb1hoLKVgoZdn82BpPWZhPZE2bkMg56N1LyG+RyORJ5/J8/2yYF+7vpyPo5VH7sLnB+Qc39XjKNsLQ8orzJgiCILQAVp0nLLgMdwXI2yZ8tqtvufMGsKsnxFQ8h955I1x8ZMVr8rbGJ2HTMjqDS8Omo+ZzjeabhuMZM10hfBZ699Hf7ieTs/n8oxeJpXO8/Moh2v1eTutRkt5uuPDQph5PxmMJgiAILUVZwUIdnbfS6tLLhjpXvGagM4CtITF0PUw9DZnEsmvyWmNhoz2+mq212VgWNm0fAOWpmXgbCyfY3e2HhYvQs5dXHjVi8Xf+9TidAS+3HRrA8iiCPh9j7UdhbJNFC1qqTQVBEIQWoqxgoY7O21BnUbxdOdq14jUDHQEA5rqvMhWGE48vu8a2wSvOWxlu2LR8ysJwTcRbLm8zFk5yeWfKvEZdO9jT38YL95uCk596wW4CTnizI+jlXPBymD0B6djGH7SQ89acofLmXLUgCIJQN8oKFqw65rx1F8Xbav3mBjuNeLvYdiV7wIRO995Sdk1ea7zkyTbpG3ktcMOm0dIpCx3DEKu+eJtYSJGzNQdD8eLjAH/6U9cxHklyw57e4hICXk56L+Nl2obJ48tey3XjiDdUc3pYzblqQRAEoW6UFSzU0XkbdcTb7776ilWvcZ23iXwndO+Bi48uuyZva7wqL33eSgh4PVgeVcx5A5P3VgPn7fy8CWXvDjhjrxzxNtod4sa9faiSn7H2gMUz6oD5ZvyHG3/QJhdv8pMqCIIgVESp2VbPlKGgz+LMH7667M19KQMdfgBmY2nYeQOMLRdvtm2cN0S8FVBK0VE6nB5MxemFzVV5roQr3kY8rngbXPXadr+XiVw3dO3clHhTOo+tVV0LbjZDc0pOQRAEoW5YVv1nm7pcSriBCbMFvB5momnYdRMsnIfYdNk1eadViDhv5XQEvOVh0969kAxDaqGqj3N2Lo7PUvTYYXOgfWjVazuDzpp2XL9p582mOYUbiHgTBEEQKsRqgAkL60UpxUBHgNlYBnaa2ZhLQ6e22ypEqk3L6Ax6iZaGTXv3m8/hs1V7DK0133pmmmt39eCJT5t+fP6Ve/aBqYKNp3Ow4zqYex5Sixt8YBst4k0QBEFoFdyCBY9a2/lqBAY7A0xHUzB6rclxuviDsvNuqxCk2rSMrqCPaCpbPNDniLf5M1W5/1Q2z+/925M8Px3j9dfvNNMbOlZ33cCIt5jrvMGK1cPrQWmbfBNLoOZduSAIglAX3IKFRnfdXC4f6eSJsQVyVggGL4fxJeLN1vjIgSXOWymdQS+LyZWct+qIt49/+yR/9+B52v0Wr7l61ISznWKF1egO+VhMZtGj15kDGw2dahu7SYsVQMSbIAiCUCFuyluzJHvfftkA0VSOJy4uwI4bjPNWMtg8b7vOm+S8ldIV8rFY6rwFu6Ctvyph04Vklk/ed5pXXTXCDz74cvra/Ua8ta9erADQ2+YjZ2uiVjf07Nm4eLMlbCoIgiC0EJZTYtosztttBwdQCr5zYtZUnCbnzQxNh3zexqfyYEnYtJSupTlvYNy3+dObvu+zs3HSOZsfv35noQHvepy3njZTPRyJZzdXtKDz2E0sgZp35YIgCEJdcAsW6l1pul562/3cvK+Pz/9gjPzoDeZgSd6bbRuBIgUL5XSFTM6bbRddSgYOw+zz676PRCbHXR+9l/tOzJQdn1hIArCjx5lJm01CemHNnLdeV7wlM0a8hc9AYn7d6ymiRbwJgiAIrYPruK021aARefst+zg/n+BYeAAsf1nem50z4q1ZRyXViq6gD1tDPFPivg0egegEJCPruo97np7ixFSMv7j3VNnxiYUUUGy0XGjfsobz1ttmBHY4kS0pWnhsXWspRUm1qSAIgtBKuOLN20Ti7RVHh2n3W9x7egFGroaLxXCbnXPyuqRgoYyukBGzi6Wh08HLzefZE+u6jy89Pg7AZUMdZccnFlL4vR6T6wYQd5y59YZNExlTPQwbCp0qnZdqU0EQBKF18Dah8+a1PFyzq4fHLkRM0cLEY5A3osS2HfEmzlsZnUEjZsvahQweMZ9nnl3z9nlb892Ts859lOfOTSykGO0OFlvNxKbM50tMV4AS5y2egVAv9B3YWN6bOG+CIAhCK1FoFdIkOW8u1+3p4ZmJRTI7XwCZGEw+AYB2nDdliXgrpcsRb2XtQnr2gjcE02uLt9MzMVJZM0O0rGoVmIgkiyFTKBFva7cKASdsCk7RwmNrrmUZWqObWAI178oFQRCEulAoWGgi5w3gut09ZPOaZwJOuO3sd4FiwYI4b+UUwqbJEuHl8cDw0XXlmT05bsZo9bX7WUguEW8LKXZ0h4oH3Jy3NVqFeC0PXUGvCZuCcVEXLkBs5pK3W4oiL33eBEEQhNahWLBQ54VUyLW7egB4LByA/ssK4k3njBBQkvNWRsF5W+KasfNG43bZ+Uve/smLiwS8Hm7Y01Mm3iKJDBMLSfb0l4zBik2ZHnLreA162/1F523XTebzhQfXvF0pypbZpoIgCEILYTVp2HS4K0Bfu5+nxxfhwEuMeMumsPNSbboSXSE3bLpUvN0A2TjMPHfJ2z87ucjlI53LnLdvPTuNreGlR0ragqyjx5tLT5ufcKnz5g3B2fvXddsiEjYVBEEQWgirycZjuSiluHK0i6cmFuDwq4wAOXNfoVWIVJuW0xlcodoUjGCCZWPGlnJ+PsHe/nZnpFXxPr7xzBRDnQGu3tldvHgd0xVc+tp8zMcd8eb1w+6b4dx313VbFyVNegVBEIRWolnFG8DRHV2cmIyR3XMb+Dvg2S9zcX4RkIKFpfgsD71tPiYXU+Un+g9BoAsuPrrqbfO2ZiKSYmdviK6gj2Q2TyZniheOX1zghQf6y6uVY1Prdt4GOwPMRNPFA3tvg8knIRle93NTWku1qSAIgtA6uOHSZpltWsqVO7rI5G2em83AkVeRe/Jf+dS3jgMw2N2xxq1bj/0D7ZyeiZUdOzOfJDd8bdmUiqVMLabI2ZpdvSG6nfYeC0kzrWFyIcWu3pJiBa2dsOmlpyu4DHUGmY2lybuTH/beBmg4X0nem42WggVBEAShVWhm5+3Gvb0APHouDNe/DW9mkTcGHwGguz10qZu2JPsHOjgzGy98Px5J8tI/OsY3FnfB1JOQTa14u4sRM/5qZ0+o0N5jIZllNpYmm9fsKG0TkolBLrlu522oK4CtYS7uuG+7bjJTM86uP3QqYVNBEAShpWhm8bazJ8Rod5Dvn51nvPdmztrDvE1/2ZyUgoVlHBhsZ2oxTTxtctb++OtmssLj9gGwczB5fMXbjYUTAOzqbSurWnVFXWGmKax7NJbLUGcAgOlFR7z5QrDzpgrFmxbnTRAEQWgdmlm8KaW4aV8fD5+Z58vHJ/nL/GuLJ0W8LePAQDtAwX37zvOmn9pU19XmgrHvr3i7i+Gi8+ZWrS4ksiUzTUvF2/qmK7gMdhrXrizv7eCPmN5z0al13YdCJiwIgiAILUSztgpxedMNO5mLZ/jwV5/l4a5X1ns5Dc3+waJ4m1pMMe0IprFcD3TvgQsPrXi7i5Ek/e1+Qn6LESdEOrGQYrwknFpgndMVXFznrUy8HXmV+Xzi7nXdh9K2hE0FQRCE1qFQsNCEzhvAnUeG+NTP38zrrt3Br77iKLzhL8yJnt31XVgD4oqsiYUkx8fMxITukI9YOge7X2DEm9bLbje5kCqItpGuIF6PYiyc4GIkSZvfKkxvAIrTESqoNgWYjpbk2w0fhZ498MyX1vfEtBQsVA2l1PuVUt9XSi0qpWaUUl9SSl215BqllPqQUmpcKZVUSh1TSh2t15oFQRBaDctqbucN4MWHB/nfb72e11+3E657K/zerBlyLpTRGfTREfAysZDi+MUFPApu3tdHPJOD3S+E6AQsjC273eRimpEuI94sj2JHT4gL4SSPX4iwt7+9OJAejPOmLAj1rWtNQZ9FV9BbcAEBUAquehOc+lYxh+4SSNi0utwJ/DlwK/AjQA74hlKq9BV9H/AbwHuAm4Fp4B6lVOfWLlUQBKE1adbZppdEGvSuykh3kMmFFE9eXODQUAeDnQFTwLD7BeaCFUKnU4sphksqSnf1hvjeqVl+cD7Cm27YWX7x4kXoHKlo3pq7pjKufSvoPDzxj2ve3qNtbKx1P16j0VDiTWv9Cq31p7TWT2qtjwM/CwwCt4Fx3YBfAz6itf681vpJ4O1AJ/DTdVq2IAhCS1GcbbqNxJuwKiNdQSYWUjxxcYGrdnbTEbBM2HT4KvC1wYWHy65P5/LMxzMF5w1gd28bs7EMAa+Hn7hxV/kDzJ+u2PXc0RNifCHJ+bkEv/TpR4imsjB4BPbcAg99EvK5S95eYRu3rklpKPG2Ap2YNbptk/cDI8DX3Qu01kngPoxbJwiCINQYV7x5Rby1BCPdQR4fizATTXP1zm7aA15SWZscHjOkfonz5rbwKBVvblPeH7t2Bz1t/vIHmDtVsXgb7Q4xEUnx/37reb721BRffmLCnLj1V2HhPBz/p0veXmkbu4lz3hq9LvpjwGPA95zvR5zPS2uBp4AlPqxBKfUu4F0Aw8PDHDt2rOqLLCUWi9X8MVoN2dPqIvtZfVptT+NZk6Aenp+r2fNutT2tNZvZz3QkU6hJyE2fZjJixlx97Vv3cpU9wp6J+/nON+/GtoxYOxHOAzB19jmOxU8BkJnNoYCj/tmydVi5OHckZjkVgQsVrC8dzjAXz3LuohFt33r0GUYTp0EHuaHzMgJf/R0enu0h721b8fZ9uSzApn7G6vkz2rDiTSn1J8DtwO1a6/xG70dr/UngkwA33XSTvvPOO6uzwFU4duwYtX6MVkP2tLrIflafVtvTWDoH3/waQ4MD3HnnTTV5jFbb01qzmf28EDjLl049BcDbXnMn//bYRf7hueNcf/OL2LE3C5/5Z158oB323wFA9PFxeOiH3HXHCzkyYtLRX2xr3nJXkl29S8TU+GPwXTh408s4eOX61zffNca/PP84zy96gDz3nMvx+tuu5rXX7IDDfwl//XLumP17ePP/Bc/y3LZn7veQ9/g29TNWz5/RhvQMlVIfBd4K/IjW+nTJqUnn89J64uGSc4IgCEIN2ZYFC8KqHBg0M18/+NorCfkt2gPG94mnc2Y0FZSFTicWTC+3kZKCBY9HsasnBF/5DfjzW+G5fzcn5p23+A2ETQEiiWzh2K985odkcrYJ5d713+DZL8M//Rwk5pfdXunmrjZtOOdNKfUx4C3AS7XWzy45fQYj0l4OfN+5PgjcAfzmVq5TEAShVSkULDRxwrewfm492M99v/lS9vQb16zDEW+maKEPBo6UFS2cmY3T1+4vzDQt8Nhn4Pt/bb7+3C/Cf/wunHsAvEHoP1jRmkqb/P7BG67CUorf+dfjPD4W4eZ9fXDLLwMa7vkg/OnVcM2b4dDLoP8QLIwxaE9z0bu/8s1oEBpKvCmlPo6pMH0DEFZKuTluMa11TGutlVJ/CvyOUupZ4ATwASAGfKYOSxYEQWg5mnk8llA5SqmCcANKnDcno2nXTXDia6ZZr1Kcnomz3xmrVcYP/w4Gr4C3fQ4+cSv8yzth+hm47C4zn7QCRrqDhQkOr7l6FEspPvCF49x/ctaIN4Bb3g0H7oQH/swIx0f+v8LtPbqDJ3f/NNdU9KiNQ0OJN+CXnc/fXHL894EPOV//TyAEfBzoBR4C7tJaR7digYIgCK2Oq9lEvLUm7QGTQxZzhtUzcg089vcQnYSuUc7MxnnJ4SVzSmPTcP57cOdvQ/cuePUfw7+8w5y76o0Vr8Hv9fDA+38Ev+UpNPy9bncP//DwBX7+1n3Fitbho/Djn4DX/BFMPQ3hM/zZg/N8dmo3d7/prg09/0agoXLetNZqlY8PlVyjtdYf0lqPaq2DWuuXOP3eBEEQhC1AKYXlUU09YUHYOB2lOW8Ao45/NfkE0VSW6Wi6MBO1wMlvABouf435/uqfgJ/9ghlNdsWPbWgdAa9VNqnhQz92lNlYmt/+/HH00pFd/nbYfTNc82Y+t3CEaw+M0Bls3sbMDSXeBEEQhObAcgSc0HoUwqYZR7wNO1MsJ57g7GwCgANLw6bjPwR/Bww50yyVgoMvNaPJVqgG3QjX7Orhva84wt1PTfIvP7i44jWxdI6zcwmuGOmqymPWCxFvgiAIQsVYHiUTFlqUdv+SnLdgl6kWnXyc8/NGvO3pW0G8jVxT0QisjfCuOw5w/Z4ePvzVZ1hMZZedf3ZiEYArRkW8CYIgCC2GhE1bl4DXSIdktqQF68g1MPFEoU1IaTUo+RxMPgk7rqv52jwexXvvOsJcPMP3zyxvEfK0I96u3CHiTRAEQWgxdve1sbuvsgpBYXvg8SiCPg+pUvE2eg1EzjE3O0Ob36IrVFIPOXsCckkYvW5L1nfZkOlLdzGSXHbuvhOz7OgOMlrSg64ZabRqU0EQBKEJ+Oqv3l7vJQh1JOSzSGZKnbdrAfDNPMlo98GyQgLmTprPg4e3ZG0DHQH8Xg8Xw0Xx9viFCH/w5ad55FyYt9+yt3x9TYiIN0EQBKFimv3NT9gcIZ9VHjZ1Kk67F55mR99V5ReHz5jPvVvTFNfjUezsCTEWTqK1ZjaW4a1/9SAJR2zedXRkjXtofES8CYIgCIJQEUH/EvHWMQTtQwwkTrNj/5Jw+vwZCPVBqGfL1rerN8RYJMkHvvAkf//QeQC+9Cu3MxtPc+vB/i1bR60Q8SYIgiAIQkW0+S1SpWFTwB44zK4zFxjtWZJPNn+64tmlm2VnT4hnnpni8QsRAH7yxl1cvat7S9dQS6RgQRAEQRCEilgWNgUSXQe5TF1kpDNQfnH4DPRt7RzRXb0hZmMZAD742iv5yJuadRDWyoh4EwRBEAShIoIriLdY10G6VIIhFSkezGVgYWzLnbcb9/YVvr5pX++2aygt4k0QBEEQhIpYVm0KRNqNQBtInys5eB60vWXFCi63HOyn05kEcXmTT1NYCcl5EwRBEAShIkJLCxaAudA+AHriZ4oH50+bz1vsvAEc+807GQsn8Xu3n08l4k0QBEEQhIpYyXmbV30s6hBd0VPFg26bkC3OeQPo7wjQ3xFY+8ImZPvJUUEQBEEQaspKOW/xTJ5TeiehhZPFg/OnzUD69sEtXuH2RsSbIAiCIAgVEfJb5eOxgFg6x0l7B77w88WD82dMvps0da4qIt4EQRAEQaiINp9FNq/J5u3CsVg6x/N6J574NCQj5mAd2oS0AiLeBEEQBEGoiJDfAihz3+LpHBc8u803M8+BnYfwWRFvNUDEmyAIgiAIFRH0GfFWmvcWS+cY9+8138w+B4vjkM/UpdJ0uyPiTRAEQRCEigg54i2VKQ2b5okFR8EKGOfNbROyxT3eWgFpFSIIgiAIQkW4YdPkkrBpKOiHjsMwewIGLjMnxHmrOuK8CYIgCIJQEaGVwqapHB0BLwwehplnjfNm+aFrR72WuW0R8SYIgiAIQkW4OW+JTK5wLJZ2xNvAEYhcgIknoHcfeKw6rXL7IuJNEARBEISK6AyarKvFZLl4aw94Yd/tgIbT34Yd19dphdsbEW+CIAiCIFTE3v42AE7PxgrH4q7ztudF0D5kDl795nosb9sj4k0QBEEQhIroDPoY6QpyctqIN601UVe8eSy45s3QswcO3FnfhW5TRLwJgiAIglAxh4Y6CuJtMZUjk7MZ7HQGwb/s9+GXHwJLmlrUAhFvgiAIgiBUjCvetNZML6YAGOoKmpOWF/xtdVzd9kbEmyAIgiAIFXPZcAeJTJ5zcwmmFtMADLvOm1BTxM8UBEEQBKFi7jg0CMDXnppkoMOItmHXeRNqijhvgiAIgiBUzJ7+Nq7d1c2Xn5hg0gmbinjbGkS8CYIgCIKwIe46OsLxiws8PxWlK+gtjM0SaouIN0EQBEEQNsQ1u7oB+Naz0+K6bSEi3gRBEARB2BBHdxjxtpjKiXjbQkS8CYIgCIKwIfra/YWvX3Sgr44raS1EvAmCIAiCsGFesN+Itl+4bX+dV9I6SKsQQRAEQRA2zF+//SZS2bwZSi9sCbLTgiAIgiBsmK6gj66gr97LaCkkbCoIgiAIgtBEiHgTBEEQBEFoIkS8CYIgCIIgNBEi3gRBEARBEJoIEW+CIAiCIAhNhIg3QRAEQRCEJkLEmyAIgiAIQhMh4k0QBEEQBKGJEPEmCIIgCILQRIh4EwRBEARBaCJEvAmCIAiCIDQRIt4EQRAEQRCaCBFvgiAIgiAITYSIN0EQBEEQhCZCxJsgCIIgCEITobTW9V7DlqGUmgHO1fhhBoDZGj9GqyF7Wl1kP6uP7Gn1kT2tLrKf1Wcr9nSv1npw6cGWEm9bgVLqEa31TfVex3ZC9rS6yH5WH9nT6iN7Wl1kP6tPPfdUwqaCIAiCIAhNhIg3QRAEQRCEJkLEW/X5ZL0XsA2RPa0usp/VR/a0+sieVhfZz+pTtz2VnDdBEARBEIQmQpw3QRAEQRCEJkLEmyAIgiAIQhMh4k0QBEEQBKGJEPFWJZRSv6yUOqOUSimlHlVK3VHvNTUqSqkXK6W+qJS6qJTSSqmfX3JeKaU+pJQaV0ollVLHlFJHl1zTq5T6tFJqwfn4tFKqZyufR6OglHq/Uur7SqlFpdSMUupLSqmrllwje1oBSql3K6WecPZ0USn1PaXUa0rOy35uAudnViul/qzkmOxpBTh7pZd8TJacl/3cAEqpUaXU3zp/S1NKqaeVUi8pOd8Q+yrirQoopd4CfAz4MHA98ADw70qpPXVdWOPSATwJ/GcgucL59wG/AbwHuBmYBu5RSnWWXPMZ4Abglc7HDcCna7jmRuZO4M+BW4EfAXLAN5RSfSXXyJ5WxhjwW5g9uAn4FvAFpdQ1znnZzw2ilHoR8C7giSWnZE8r5zlgtOTj6pJzsp8V4gis+wEFvAa4ArN/0yWXNca+aq3lY5MfwEPAXy059jzwh/VeW6N/ADHg50u+V8AE8Lslx0JAFPgl5/srAA3cVnLN7c6xI/V+TvX+wIjjPPA62dOq7us88Euyn5vaw27gFPBS4BjwZ85x2dPK9/JDwJOrnJP93Niefhi4/xLnG2ZfxXnbJEopP3Aj8PUlp76OcUKEytgPjFCyn1rrJHAfxf28BSP6Hii53f1AHNlzgE6Mqx52vpc93QRKKUsp9VMYUfwAsp+b4ZPA57TW315yXPZ0YxxwwndnlFL/oJQ64ByX/dwYbwAeUkr9o1JqWin1mFLqV5RSyjnfMPsq4m3zDAAWMLXk+BTmRRYqw92zS+3nCDCjnX9pAJyvp5E9BxPCfwz4nvO97OkGUEpdrZSKAWngL4Af11ofR/ZzQyil3gkcAj6wwmnZ08p5CPh5TFjunZg9eEAp1Y/s50Y5APwycBp4BeZv6UeAdzvnG2ZfvdW6I0EQ6o9S6k8wFv3tWut8vdfT5DwHXIcJ9f0E8LdKqTvruJ6mRSl1BBOSul1rna33erYDWut/L/1eKfUgRnS8HXiwLotqfjzAI1rr9zvf/1ApdRlGvP3Z6jfbesR52zyzmPyi4SXHh4HJ5ZcLa+Du2aX2cxIYLLGycb4eooX3XCn1UeCtwI9orU+XnJI93QBa64zW+qTW+lHnj/ljwK8j+7kRbsFEKZ5SSuWUUjngJcAvO1/POdfJnm4QrXUMeAq4DPkZ3SgTwNNLjj0DuMWHDbOvIt42idY6AzwKvHzJqZdTHvMW1scZzA94YT+VUkHgDor7+T1M/tEtJbe7BWinRfdcKfUxisLt2SWnZU+rgwcIIPu5Eb6AqYS8ruTjEeAfnK9PIHu6KZz9uhwjQORndGPcDxxZcuwwcM75unH2td7VHdvhA3gLkAHegak0+RgmYXFvvdfWiB/OD/Z1zkcC+KDz9R7n/G8BC8Abgaswf+DHgc6S+/h34LjzS3GL8/WX6v3c6rSfHwcWMW1CRko+OkqukT2tbE8/gvmDvA8jOv4QsIFXyX5WbY+P4VSbyp5uaP/+CONe7gdeCHzZ+TuwV/Zzw3t6M5AFfheTn/mTzh6+u+SahtjXum/WdvnAJDmexSQ3Pwq8uN5ratQPTF8yvcLH3zjnFaYMfgJIAfcCVy25j17g75w/VovO1z31fm512s+V9lIDHyq5Rva0sj39G8x/22lMovE3gFfIflZ1j49RLt5kTyvbP1c0ZICLwOeBK2U/N72vrwEed/bsBPCrgGq0fVXOAwmCIAiCIAhNgOS8CYIgCIIgNBEi3gRBEARBEJoIEW+CIAiCIAhNhIg3QRAEQRCEJkLEmyAIgiAIQhMh4k0QBEEQBKGJEPEmCMK2Rin1IaXUkxXe5phSasOzDJVSn1JKfbBa97cZlFIPK6XeVI/HFgShNoh4EwSh4VBK/Y1S6ssrHL9JKaWVUvsquDu3E31VUUqdVUq9d4XjVwNvAP605PAbgfcvvXaL+APgI0op+XsvCNsE+WUWBGFbo7WOaa3n1r6yarwH+LzWerFkDfNa6+gWrqGUrwKdwKvq9PiCIFQZEW+CIDQ1SqkrlVJfUUpFlVLTSqnPKqVGSs6XhU2VUl6l1EeVUmHn46NKqU8opY4tuWuPUurDSqlZ537/yHWvnGv3Av/LcQK1c9wC3gx8ackay8Kmjmv3AaXUXyqlFpVSY0qp31zjeX5IKfWkUurtzu3jTnjWr5T6ZaXUBaXUnFLqT0pdNq11HiPg3lrRxgqC0LCIeBMEoWlRSo0C9wFPAi8AXgZ0AP92iTDhe4GfB94BvAjzd/CnV7juZ4AccCvwK8CvAW9xzr0RGAP+KzDqfABcA3QDj6xj+b+OGVh9A/A/gP+plLpljdvsA14PvNZZw08CX8QM1L7LeU7vAX58ye0epgahY0EQ6oO33gsQBEFYhVcqpWJLji0VZP8JeFxr/VvuAaXUzwHzwE0Y0bKU/wz8D631553rfw145QrXPa21dosOTiil3gn8KPBZrfW8UioPRLXWkyW32QtozNDqtfi61tp14/63UupXnfv/3iVuYwG/oLVeAJ5USt2NEWU7tdYZ4Bml1P3ASzGDyl3GgZ1KKa/WOreOtQmC0MCIeBMEoVG5D3jXkmNXAf9a8v2NwItXEHkAB1ki3pRS3cBI6XGttVZKPQzsXnL7J5Z8Pw4MrbHmEJDVWttrXLfR+z/vCDeXKeCEI9xKjy29nySggCCw0l4JgtBEiHgTBKFRSWitT5YeUEr1LLnGA3wFEwpdytQmHz+75HvN2qkms4BfKdWmtU7U4P5Xus1Kx6wlx/qAlNZahJsgbAMk500QhGbmB8BR4JzW+uSSj2XVnY5rNYnJEQNAKaVKv6+ADMtF0mPO5ys3cH+15CrMXgmCsA0Q8SYIQjPzcUyBwD8qpV6olDqglHqZUuqTSqnOVW7zMeB9SqkfV0odAf4YU3CgK3zss8AdSqmdSqkBAK31DEYk3b6RJ1ND7gDurvciBEGoDiLeBEFoWrTW48BtgI0RJ09hBF3a+ViJPwI+DXwKeNA59q9AqsKH/yAmT+4UMFNy/JOYStWGQCm1E1Mx+6l6r0UQhOqgtK70n01BEITthVLqh8B3tdbvqcJ9BYFngZ/VWn9n04vb/Hr+F9CttV5a/CEIQpMiBQuCILQUSqm9wCuAewEf8E5Mf7Z3VuP+tdYpp11JXzXurwpMY9xGQRC2CeK8CYLQUiildgOfBa7GpI48Dfye1vrrdV2YIAjCOhHxJgiCIAiC0ERIwYIgCIIgCEITIeJNEARBEAShiRDxJgiCIAiC0ESIeBMEQRAEQWgiRLwJgiAIgiA0Ef8/RrLDX4B0AQsAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9389, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIBZdUI09Xi8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(y_test[:500,2])\n",
        "plt.grid()\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Relative Humidity\")\n",
        "\n",
        "plt.savefig('RH_graph.png', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "id": "KIBZdUI09Xi8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDZAFjl7UTtL"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(y_test[:147,0])\n",
        "plt.grid()\n",
        "plt.xlabel(\"Height\")\n",
        "plt.ylabel(\"Pressure\")\n",
        "\n",
        "plt.savefig('Pressure_graph.png', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "id": "yDZAFjl7UTtL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC5dMDc1oC72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "f982d579-3018-44b6-82f1-12b1642de984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lambda_14_layer_call_fn, lambda_14_layer_call_and_return_conditional_losses, dwt_conv1d_layer_7_layer_call_fn, dwt_conv1d_layer_7_layer_call_and_return_conditional_losses while saving (showing 5 of 31). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-4a6fd4bbe00d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#saving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'abc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_model_pressure.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
            "\u001b[0;31mTypeError\u001b[0m: Unable to serialize [[0 0]\n [5 5]\n [0 0]] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."
          ]
        }
      ],
      "source": [
        "#saving\n",
        "import pickle\n",
        "model.save('abc')\n",
        "pickle.dump(model,open('saved_model_pressure.pkl','wb'))\n",
        "\n",
        "#import\n",
        "#lmodel = pickle.load(open('saved_model_pressure.pkl','rb'))"
      ],
      "id": "OC5dMDc1oC72"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7gyUzIx5bQz"
      },
      "outputs": [],
      "source": [
        "t=x_test_vband\n",
        "print(np.shape(t))\n",
        "t=np.reshape(t, (len(x_test),15, 1))\n",
        "y_pred = model.predict(t)\n",
        "y_pred.shape"
      ],
      "id": "l7gyUzIx5bQz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN2k4eqLPE7F"
      },
      "source": [
        "# New"
      ],
      "id": "CN2k4eqLPE7F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5mq8wGNPNrS"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res"
      ],
      "id": "S5mq8wGNPNrS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e6D02IGPQIm"
      },
      "outputs": [],
      "source": [
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    # x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "\n",
        "    for dim in mlp_units:\n",
        "        x = tfa.activations.mish(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    x=Flatten()(x)\n",
        "    outputs = layers.Dense(1)(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "id": "9e6D02IGPQIm"
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = 23,1\n",
        "print(input_shape)\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=12,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"mean_squared_error\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4)\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=10, \\\n",
        "    restore_best_weights=True)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8gktYWzcdDW",
        "outputId": "aab018c5-6bef-45d0-cdb5-a65480488c14"
      },
      "id": "n8gktYWzcdDW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23, 1)\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None, 23, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " layer_normalization_56 (LayerN  (None, 23, 1)       2           ['input_9[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_28 (Multi  (None, 23, 1)       21505       ['layer_normalization_56[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_63 (Dropout)           (None, 23, 1)        0           ['multi_head_attention_28[0][0]']\n",
            "                                                                                                  \n",
            " tf.__operators__.add_56 (TFOpL  (None, 23, 1)       0           ['dropout_63[0][0]',             \n",
            " ambda)                                                           'input_9[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_57 (LayerN  (None, 23, 1)       2           ['tf.__operators__.add_56[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_57 (Conv1D)             (None, 23, 4)        8           ['layer_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_64 (Dropout)           (None, 23, 4)        0           ['conv1d_57[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_58 (Conv1D)             (None, 23, 1)        5           ['dropout_64[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_57 (TFOpL  (None, 23, 1)       0           ['conv1d_58[0][0]',              \n",
            " ambda)                                                           'tf.__operators__.add_56[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_58 (LayerN  (None, 23, 1)       2           ['tf.__operators__.add_57[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_29 (Multi  (None, 23, 1)       21505       ['layer_normalization_58[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_65 (Dropout)           (None, 23, 1)        0           ['multi_head_attention_29[0][0]']\n",
            "                                                                                                  \n",
            " tf.__operators__.add_58 (TFOpL  (None, 23, 1)       0           ['dropout_65[0][0]',             \n",
            " ambda)                                                           'tf.__operators__.add_57[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_59 (LayerN  (None, 23, 1)       2           ['tf.__operators__.add_58[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_59 (Conv1D)             (None, 23, 4)        8           ['layer_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_66 (Dropout)           (None, 23, 4)        0           ['conv1d_59[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_60 (Conv1D)             (None, 23, 1)        5           ['dropout_66[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_59 (TFOpL  (None, 23, 1)       0           ['conv1d_60[0][0]',              \n",
            " ambda)                                                           'tf.__operators__.add_58[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_60 (LayerN  (None, 23, 1)       2           ['tf.__operators__.add_59[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_30 (Multi  (None, 23, 1)       21505       ['layer_normalization_60[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_67 (Dropout)           (None, 23, 1)        0           ['multi_head_attention_30[0][0]']\n",
            "                                                                                                  \n",
            " tf.__operators__.add_60 (TFOpL  (None, 23, 1)       0           ['dropout_67[0][0]',             \n",
            " ambda)                                                           'tf.__operators__.add_59[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_61 (LayerN  (None, 23, 1)       2           ['tf.__operators__.add_60[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_61 (Conv1D)             (None, 23, 4)        8           ['layer_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_68 (Dropout)           (None, 23, 4)        0           ['conv1d_61[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_62 (Conv1D)             (None, 23, 1)        5           ['dropout_68[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_61 (TFOpL  (None, 23, 1)       0           ['conv1d_62[0][0]',              \n",
            " ambda)                                                           'tf.__operators__.add_60[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_62 (LayerN  (None, 23, 1)       2           ['tf.__operators__.add_61[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_31 (Multi  (None, 23, 1)       21505       ['layer_normalization_62[0][0]', \n",
            " HeadAttention)                                                   'layer_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_69 (Dropout)           (None, 23, 1)        0           ['multi_head_attention_31[0][0]']\n",
            "                                                                                                  \n",
            " tf.__operators__.add_62 (TFOpL  (None, 23, 1)       0           ['dropout_69[0][0]',             \n",
            " ambda)                                                           'tf.__operators__.add_61[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_63 (LayerN  (None, 23, 1)       2           ['tf.__operators__.add_62[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_63 (Conv1D)             (None, 23, 4)        8           ['layer_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_70 (Dropout)           (None, 23, 4)        0           ['conv1d_63[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_64 (Conv1D)             (None, 23, 1)        5           ['dropout_70[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_63 (TFOpL  (None, 23, 1)       0           ['conv1d_64[0][0]',              \n",
            " ambda)                                                           'tf.__operators__.add_62[0][0]']\n",
            "                                                                                                  \n",
            " tf.convert_to_tensor_8 (TFOpLa  (None, 23, 1)       0           ['tf.__operators__.add_63[0][0]']\n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.math.softplus_8 (TFOpLambda  (None, 23, 1)       0           ['tf.convert_to_tensor_8[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.tanh_8 (TFOpLambda)    (None, 23, 1)        0           ['tf.math.softplus_8[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply_8 (TFOpLambda  (None, 23, 1)       0           ['tf.convert_to_tensor_8[0][0]', \n",
            " )                                                                'tf.math.tanh_8[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_71 (Dropout)           (None, 23, 1)        0           ['tf.math.multiply_8[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)            (None, 23)           0           ['dropout_71[0][0]']             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            24          ['flatten_4[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 86,112\n",
            "Trainable params: 86,112\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    x_fit,\n",
        "    y_fit,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=300,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVRPWu0fczSA",
        "outputId": "e58b33dd-14d5-4bcd-cc08-1b90ebe48916"
      },
      "id": "FVRPWu0fczSA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "26/26 [==============================] - 16s 159ms/step - loss: 233358.0469 - val_loss: 150980.7344\n",
            "Epoch 2/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 225983.5938 - val_loss: 141722.1562\n",
            "Epoch 3/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 217655.6562 - val_loss: 132538.2188\n",
            "Epoch 4/50\n",
            "26/26 [==============================] - 4s 145ms/step - loss: 206508.8906 - val_loss: 123641.9062\n",
            "Epoch 5/50\n",
            "26/26 [==============================] - 4s 146ms/step - loss: 193841.0938 - val_loss: 114980.3828\n",
            "Epoch 6/50\n",
            "26/26 [==============================] - 4s 145ms/step - loss: 184389.6094 - val_loss: 106471.3438\n",
            "Epoch 7/50\n",
            "26/26 [==============================] - 4s 158ms/step - loss: 170935.7031 - val_loss: 98594.4297\n",
            "Epoch 8/50\n",
            "26/26 [==============================] - 4s 145ms/step - loss: 163154.5781 - val_loss: 90984.0312\n",
            "Epoch 9/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 153877.2031 - val_loss: 83865.3125\n",
            "Epoch 10/50\n",
            "26/26 [==============================] - 4s 144ms/step - loss: 149508.7344 - val_loss: 77061.0625\n",
            "Epoch 11/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 133199.5312 - val_loss: 70704.4297\n",
            "Epoch 12/50\n",
            "26/26 [==============================] - 4s 154ms/step - loss: 131492.7500 - val_loss: 64354.4961\n",
            "Epoch 13/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 118809.6641 - val_loss: 58511.4023\n",
            "Epoch 14/50\n",
            "26/26 [==============================] - 4s 154ms/step - loss: 112625.1484 - val_loss: 52967.2852\n",
            "Epoch 15/50\n",
            "26/26 [==============================] - 4s 143ms/step - loss: 103770.6094 - val_loss: 47815.9492\n",
            "Epoch 16/50\n",
            "26/26 [==============================] - 4s 140ms/step - loss: 96497.8047 - val_loss: 43242.2070\n",
            "Epoch 17/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 90904.7578 - val_loss: 38874.3164\n",
            "Epoch 18/50\n",
            "26/26 [==============================] - 4s 140ms/step - loss: 83705.5469 - val_loss: 35228.8633\n",
            "Epoch 19/50\n",
            "26/26 [==============================] - 4s 140ms/step - loss: 80457.4062 - val_loss: 31950.7441\n",
            "Epoch 20/50\n",
            "26/26 [==============================] - 4s 153ms/step - loss: 72819.6719 - val_loss: 29009.4785\n",
            "Epoch 21/50\n",
            "26/26 [==============================] - 4s 141ms/step - loss: 66573.5703 - val_loss: 26290.2422\n",
            "Epoch 22/50\n",
            "26/26 [==============================] - 4s 140ms/step - loss: 62726.8008 - val_loss: 23854.4844\n",
            "Epoch 23/50\n",
            "26/26 [==============================] - 4s 152ms/step - loss: 57672.0195 - val_loss: 21709.8906\n",
            "Epoch 24/50\n",
            "26/26 [==============================] - 4s 141ms/step - loss: 53038.7070 - val_loss: 19867.0879\n",
            "Epoch 25/50\n",
            "26/26 [==============================] - 4s 153ms/step - loss: 51010.0117 - val_loss: 18133.9512\n",
            "Epoch 26/50\n",
            "26/26 [==============================] - 4s 150ms/step - loss: 47558.7812 - val_loss: 16538.7500\n",
            "Epoch 27/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 45130.9766 - val_loss: 15139.4590\n",
            "Epoch 28/50\n",
            "26/26 [==============================] - 4s 141ms/step - loss: 41902.9336 - val_loss: 13880.1631\n",
            "Epoch 29/50\n",
            "26/26 [==============================] - 4s 141ms/step - loss: 39584.2305 - val_loss: 12635.7305\n",
            "Epoch 30/50\n",
            "26/26 [==============================] - 4s 144ms/step - loss: 36749.0820 - val_loss: 11613.9531\n",
            "Epoch 31/50\n",
            "26/26 [==============================] - 4s 153ms/step - loss: 35892.2539 - val_loss: 10710.0859\n",
            "Epoch 32/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 32987.8828 - val_loss: 10050.7451\n",
            "Epoch 33/50\n",
            "26/26 [==============================] - 4s 154ms/step - loss: 31399.0195 - val_loss: 9650.7969\n",
            "Epoch 34/50\n",
            "26/26 [==============================] - 4s 141ms/step - loss: 29618.3887 - val_loss: 9286.2910\n",
            "Epoch 35/50\n",
            "26/26 [==============================] - 4s 152ms/step - loss: 29917.5254 - val_loss: 8941.7832\n",
            "Epoch 36/50\n",
            "26/26 [==============================] - 4s 142ms/step - loss: 27276.1465 - val_loss: 8635.1963\n",
            "Epoch 37/50\n",
            "26/26 [==============================] - 4s 141ms/step - loss: 25705.7930 - val_loss: 8382.2998\n",
            "Epoch 38/50\n",
            "26/26 [==============================] - 4s 140ms/step - loss: 24559.4980 - val_loss: 8137.6787\n",
            "Epoch 39/50\n",
            "26/26 [==============================] - 4s 140ms/step - loss: 24616.8594 - val_loss: 7920.2485\n",
            "Epoch 40/50\n",
            "26/26 [==============================] - 4s 141ms/step - loss: 23063.3379 - val_loss: 7726.0181\n",
            "Epoch 41/50\n",
            "26/26 [==============================] - 4s 140ms/step - loss: 22181.9688 - val_loss: 7554.1606\n",
            "Epoch 42/50\n",
            "26/26 [==============================] - 4s 140ms/step - loss: 21386.4688 - val_loss: 7357.4692\n",
            "Epoch 43/50\n",
            "26/26 [==============================] - 4s 154ms/step - loss: 20215.3164 - val_loss: 6997.8330\n",
            "Epoch 44/50\n",
            "26/26 [==============================] - 4s 152ms/step - loss: 19811.6406 - val_loss: 6642.7754\n",
            "Epoch 45/50\n",
            "26/26 [==============================] - 4s 140ms/step - loss: 19212.5566 - val_loss: 6309.0518\n",
            "Epoch 46/50\n",
            "26/26 [==============================] - 4s 153ms/step - loss: 18539.7441 - val_loss: 5971.7480\n",
            "Epoch 47/50\n",
            "26/26 [==============================] - 4s 140ms/step - loss: 17928.0762 - val_loss: 5714.7314\n",
            "Epoch 48/50\n",
            "26/26 [==============================] - 4s 140ms/step - loss: 17425.9395 - val_loss: 5460.2744\n",
            "Epoch 49/50\n",
            "26/26 [==============================] - 4s 140ms/step - loss: 16853.1152 - val_loss: 5192.8433\n",
            "Epoch 50/50\n",
            "26/26 [==============================] - 4s 141ms/step - loss: 16488.8848 - val_loss: 4945.9761\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd67040f640>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J38JhhI_YVqk"
      },
      "id": "J38JhhI_YVqk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Timepass\n"
      ],
      "metadata": {
        "id": "SVoLINF2A91-"
      },
      "id": "SVoLINF2A91-"
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import nan\n",
        "from numpy import isnan\n",
        "from pandas import read_csv\n",
        "from pandas import to_numeric\n",
        " \n",
        "# fill missing values with a value at the same time one day ago\n",
        "def fill_missing(values):\n",
        " one_day = 60 * 24\n",
        " for row in range(values.shape[0]):\n",
        "  for col in range(values.shape[1]):\n",
        "    if isnan(values[row, col]):\n",
        "      values[row, col] = values[row - one_day, col]\n",
        " \n",
        "# load all data\n",
        "dataset = read_csv('household_power_consumption.txt', sep=';', header=0, low_memory=False, infer_datetime_format=True, parse_dates={'datetime':[0,1]}, index_col=['datetime'])\n",
        "# mark all missing values\n",
        "dataset.replace('?', nan, inplace=True)\n",
        "# make dataset numeric\n",
        "dataset = dataset.astype('float32')\n",
        "# fill missing\n",
        "fill_missing(dataset.values)\n",
        "# add a column for for the remainder of sub metering\n",
        "values = dataset.values\n",
        "dataset['sub_metering_4'] = (values[:,0] * 1000 / 60) - (values[:,4] + values[:,5] + values[:,6])\n",
        "# save updated dataset\n",
        "dataset.to_csv('household_power_consumption.csv')"
      ],
      "metadata": {
        "id": "nG2w7CA1BAGT"
      },
      "id": "nG2w7CA1BAGT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "!pip install keras-tuner --upgrade --quiet\n",
        "#from CNN import CNN\n",
        "from Transformer import Transformer\n",
        "\n",
        "from utils import series_to_supervised\n"
      ],
      "metadata": {
        "id": "uENGcK-CB_ZS"
      },
      "id": "uENGcK-CB_ZS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('household_power_consumption.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])"
      ],
      "metadata": {
        "id": "-pZ62HIfCDGQ"
      },
      "id": "-pZ62HIfCDGQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resample data to daily\n",
        "daily_groups = dataset.resample('D')\n",
        "daily_data = daily_groups.sum()\n",
        "\n",
        "# We choose to keep only Global_active_power\n",
        "to_drop = ['Global_reactive_power', 'Voltage',\n",
        "       'Global_intensity', 'Sub_metering_1', 'Sub_metering_2',\n",
        "       'Sub_metering_3', 'sub_metering_4']\n",
        "daily_data.drop(columns=to_drop, inplace=True)\n",
        "\n",
        "# add calendar-related features\n",
        "daily_data['day'] = pd.DatetimeIndex(daily_data.index).day\n",
        "daily_data['weekday'] = ((pd.DatetimeIndex(daily_data.index).dayofweek) // 5 == 1).astype(float)\n",
        "daily_data['season'] = [month%12 // 3 + 1 for month in pd.DatetimeIndex(daily_data.index).month]\n",
        "\n",
        "# summarize\n",
        "print(daily_data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4drDUSNC2Qg",
        "outputId": "e4c025b3-a182-458b-8963-5a73d40e141a"
      },
      "id": "C4drDUSNC2Qg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 352 entries, 2006-12-16 to 2007-12-02\n",
            "Freq: D\n",
            "Data columns (total 4 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   Global_active_power  352 non-null    float64\n",
            " 1   day                  352 non-null    int64  \n",
            " 2   weekday              352 non-null    float64\n",
            " 3   season               352 non-null    int64  \n",
            "dtypes: float64(2), int64(2)\n",
            "memory usage: 13.8 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "look_back = 7\n",
        "n_features = daily_data.shape[1]\n",
        "\n",
        "# Walk-forward data split to avoid data leakage\n",
        "X_train, y_train, X_test, y_test, scale_X = series_to_supervised(daily_data, train_size=0.8, n_in=look_back, n_out=7, target_column='Global_active_power', dropnan=True, scale_X=True)\n",
        "\n",
        "# reshape input to be 3D [samples, timesteps, features]\n",
        "X_train_reshaped = X_train.values.reshape((-1,look_back,n_features))\n",
        "X_test_reshaped = X_test.values.reshape((-1,look_back,n_features))\n",
        "\n",
        "y_train_reshaped = y_train.values\n",
        "y_test_reshaped = y_test.values"
      ],
      "metadata": {
        "id": "bRy2ZxGODhXy"
      },
      "id": "bRy2ZxGODhXy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Testing the Transformer\n",
        "tr = Transformer()\n",
        "tr.train(X_train_reshaped,y_train_reshaped)\n",
        "_, rmse_result, mae_result, smape_result, r2_result = tr.evaluate(X_test_reshaped,y_test_reshaped)\n",
        "\n",
        "\n",
        "print('Result \\n RMSE = %.2f [kWh] \\n MAE = %.2f [kWh]\\n R2 = %.1f [%%]' % (rmse_result,\n",
        "                                                                            mae_result,\n",
        "                                                                            r2_result*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfcxaV8ZEF7F",
        "outputId": "44249201-7abf-46af-aa9c-0dcfbb5cc0a2"
      },
      "id": "yfcxaV8ZEF7F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 7, 4)]       0           []                               \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 7, 4)        8           ['input_1[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " multi_head_attention (MultiHea  (None, 7, 4)        19460       ['layer_normalization[0][0]',    \n",
            " dAttention)                                                      'layer_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 7, 4)         0           ['multi_head_attention[0][0]']   \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 7, 4)        0           ['dropout[0][0]',                \n",
            " da)                                                              'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 7, 4)        8           ['tf.__operators__.add[0][0]']   \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 7, 4)         20          ['layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 7, 4)         0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 7, 4)         20          ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None, 7, 4)        0           ['conv1d_1[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 7, 4)        8           ['tf.__operators__.add_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (MultiH  (None, 7, 4)        19460       ['layer_normalization_2[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 7, 4)         0           ['multi_head_attention_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None, 7, 4)        0           ['dropout_2[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 7, 4)        8           ['tf.__operators__.add_2[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 7, 4)         20          ['layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 7, 4)         0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 7, 4)         20          ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None, 7, 4)        0           ['conv1d_3[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_4 (LayerNo  (None, 7, 4)        8           ['tf.__operators__.add_3[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (MultiH  (None, 7, 4)        19460       ['layer_normalization_4[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 7, 4)         0           ['multi_head_attention_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  (None, 7, 4)        0           ['dropout_4[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_5 (LayerNo  (None, 7, 4)        8           ['tf.__operators__.add_4[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 7, 4)         20          ['layer_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 7, 4)         0           ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 7, 4)         20          ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  (None, 7, 4)        0           ['conv1d_5[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_4[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_6 (LayerNo  (None, 7, 4)        8           ['tf.__operators__.add_5[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (MultiH  (None, 7, 4)        19460       ['layer_normalization_6[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 7, 4)         0           ['multi_head_attention_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  (None, 7, 4)        0           ['dropout_6[0][0]',              \n",
            " mbda)                                                            'tf.__operators__.add_5[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_7 (LayerNo  (None, 7, 4)        8           ['tf.__operators__.add_6[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 7, 4)         20          ['layer_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 7, 4)         0           ['conv1d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 7, 4)         20          ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TFOpLa  (None, 7, 4)        0           ['conv1d_7[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 7)           0           ['tf.__operators__.add_7[0][0]'] \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          1024        ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 7)            903         ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 79,991\n",
            "Trainable params: 79,991\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 1151262.7500 - rmse: 1094.5461 - mae: 449.3511 - smape: 99.9984 - coeff_determination: -0.2215"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: loss improved from inf to 1151262.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 21s 74ms/step - loss: 1151262.7500 - rmse: 1094.5461 - mae: 449.3511 - smape: 99.9984 - coeff_determination: -0.2215\n",
            "Epoch 2/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1118362.7500 - rmse: 1056.7454 - mae: 435.4991 - smape: 99.9977 - coeff_determination: -0.2047"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: loss improved from 1151262.75000 to 1151233.12500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1151233.1250 - rmse: 1107.1001 - mae: 449.3559 - smape: 99.9976 - coeff_determination: -0.2394\n",
            "Epoch 3/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1163584.5000 - rmse: 1067.0029 - mae: 451.7144 - smape: 99.9977 - coeff_determination: -0.2178"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3: loss did not improve from 1151233.12500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1151243.1250 - rmse: 1047.5730 - mae: 449.3665 - smape: 99.9977 - coeff_determination: -0.2175\n",
            "Epoch 4/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1177011.5000 - rmse: 1082.7288 - mae: 459.5031 - smape: 99.9974 - coeff_determination: -0.2195"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4: loss improved from 1151233.12500 to 1151218.87500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1151218.8750 - rmse: 1034.8275 - mae: 449.3703 - smape: 99.9975 - coeff_determination: -0.1996\n",
            "Epoch 5/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1172757.5000 - rmse: 1082.4252 - mae: 455.6173 - smape: 99.9968 - coeff_determination: -0.2157"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5: loss improved from 1151218.87500 to 1151211.12500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 1151211.1250 - rmse: 1042.9695 - mae: 449.3724 - smape: 99.9968 - coeff_determination: -0.2078\n",
            "Epoch 6/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1074032.6250 - rmse: 1032.8832 - mae: 421.1003 - smape: 99.9967 - coeff_determination: -0.1987"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6: loss improved from 1151211.12500 to 1151180.12500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 1151180.1250 - rmse: 1140.4932 - mae: 449.3835 - smape: 99.9964 - coeff_determination: -0.2676\n",
            "Epoch 7/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1193124.2500 - rmse: 1089.5297 - mae: 463.7543 - smape: 99.9957 - coeff_determination: -0.2207"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7: loss improved from 1151180.12500 to 1151147.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1151147.7500 - rmse: 1003.4949 - mae: 449.4013 - smape: 99.9958 - coeff_determination: -0.1977\n",
            "Epoch 8/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1211679.1250 - rmse: 1096.1122 - mae: 472.9772 - smape: 99.9949 - coeff_determination: -0.2278"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8: loss improved from 1151147.75000 to 1151140.25000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1151140.2500 - rmse: 945.5753 - mae: 449.4287 - smape: 99.9951 - coeff_determination: -0.1861\n",
            "Epoch 9/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1120349.2500 - rmse: 1057.7218 - mae: 437.5409 - smape: 99.9943 - coeff_determination: -0.2062"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9: loss improved from 1151140.25000 to 1151106.87500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 1151106.8750 - rmse: 1105.1010 - mae: 449.4479 - smape: 99.9941 - coeff_determination: -0.2329\n",
            "Epoch 10/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1202413.2500 - rmse: 1085.7729 - mae: 466.0733 - smape: 99.9936 - coeff_determination: -0.2231"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10: loss improved from 1151106.87500 to 1151048.00000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1151048.0000 - rmse: 973.3874 - mae: 449.4727 - smape: 99.9937 - coeff_determination: -0.2007\n",
            "Epoch 11/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1155783.5000 - rmse: 1066.2142 - mae: 452.1918 - smape: 99.9922 - coeff_determination: -0.2185"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11: loss improved from 1151048.00000 to 1150990.50000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 1150990.5000 - rmse: 1059.7747 - mae: 449.5253 - smape: 99.9923 - coeff_determination: -0.2108\n",
            "Epoch 12/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1132057.3750 - rmse: 1060.7990 - mae: 443.3663 - smape: 99.9906 - coeff_determination: -0.2108"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12: loss improved from 1150990.50000 to 1150886.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 1150886.6250 - rmse: 1091.3109 - mae: 449.5582 - smape: 99.9902 - coeff_determination: -0.2214\n",
            "Epoch 13/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1188661.1250 - rmse: 1082.8884 - mae: 464.0914 - smape: 99.9887 - coeff_determination: -0.2238"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13: loss improved from 1150886.62500 to 1150854.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1150854.6250 - rmse: 1008.5250 - mae: 449.6505 - smape: 99.9890 - coeff_determination: -0.1966\n",
            "Epoch 14/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1154196.8750 - rmse: 1072.2793 - mae: 449.1929 - smape: 99.9864 - coeff_determination: -0.2113"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14: loss improved from 1150854.62500 to 1150741.00000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1150741.0000 - rmse: 1066.7982 - mae: 449.6843 - smape: 99.9862 - coeff_determination: -0.2163\n",
            "Epoch 15/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1117650.5000 - rmse: 1054.3715 - mae: 437.3603 - smape: 99.9851 - coeff_determination: -0.2059"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15: loss improved from 1150741.00000 to 1150664.00000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1150664.0000 - rmse: 1105.3441 - mae: 449.7813 - smape: 99.9843 - coeff_determination: -0.2330\n",
            "Epoch 16/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1184377.3750 - rmse: 1086.4863 - mae: 464.0391 - smape: 99.9810 - coeff_determination: -0.2216"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16: loss improved from 1150664.00000 to 1150517.00000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1150517.0000 - rmse: 1020.5342 - mae: 449.8436 - smape: 99.9814 - coeff_determination: -0.1932\n",
            "Epoch 17/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1149344.0000 - rmse: 1062.9199 - mae: 449.0615 - smape: 99.9800 - coeff_determination: -0.2138"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 17: loss improved from 1150517.00000 to 1150480.00000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1150480.0000 - rmse: 1066.6566 - mae: 449.9610 - smape: 99.9803 - coeff_determination: -0.2161\n",
            "Epoch 18/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1179090.7500 - rmse: 1085.6453 - mae: 461.6718 - smape: 99.9763 - coeff_determination: -0.2200"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 18: loss improved from 1150480.00000 to 1150284.37500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1150284.3750 - rmse: 1030.8317 - mae: 450.0419 - smape: 99.9761 - coeff_determination: -0.1969\n",
            "Epoch 19/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1201623.5000 - rmse: 1090.6516 - mae: 470.9981 - smape: 99.9719 - coeff_determination: -0.2276"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 19: loss improved from 1150284.37500 to 1150040.50000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1150040.5000 - rmse: 976.3849 - mae: 450.0981 - smape: 99.9726 - coeff_determination: -0.1881\n",
            "Epoch 20/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1142005.0000 - rmse: 1067.6603 - mae: 447.4854 - smape: 99.9688 - coeff_determination: -0.2101"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 20: loss improved from 1150040.50000 to 1149914.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1149914.7500 - rmse: 1080.8359 - mae: 450.2518 - smape: 99.9688 - coeff_determination: -0.2152\n",
            "Epoch 21/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1169214.8750 - rmse: 1081.2039 - mae: 456.9419 - smape: 99.9661 - coeff_determination: -0.2143"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 21: loss improved from 1149914.75000 to 1149849.37500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 1149849.3750 - rmse: 1045.9984 - mae: 450.4138 - smape: 99.9664 - coeff_determination: -0.2034\n",
            "Epoch 22/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1111434.6250 - rmse: 1049.8917 - mae: 434.6292 - smape: 99.9620 - coeff_determination: -0.2022"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 22: loss improved from 1149849.37500 to 1149552.00000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1149552.0000 - rmse: 1108.2482 - mae: 450.5106 - smape: 99.9605 - coeff_determination: -0.2423\n",
            "Epoch 23/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1081735.3750 - rmse: 1039.6829 - mae: 428.9765 - smape: 99.9630 - coeff_determination: -0.2012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 23: loss improved from 1149552.00000 to 1149505.25000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 1149505.2500 - rmse: 1135.4641 - mae: 450.6816 - smape: 99.9602 - coeff_determination: -0.2428\n",
            "Epoch 24/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1151186.2500 - rmse: 1069.4523 - mae: 451.6024 - smape: 99.9522 - coeff_determination: -0.2122"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 24: loss improved from 1149505.25000 to 1149179.37500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 1149179.3750 - rmse: 1066.7422 - mae: 450.8164 - smape: 99.9530 - coeff_determination: -0.2105\n",
            "Epoch 25/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1149034.1250 - rmse: 1064.7972 - mae: 451.7296 - smape: 99.9495 - coeff_determination: -0.2130"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 25: loss improved from 1149179.37500 to 1148956.25000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 1148956.2500 - rmse: 1066.0924 - mae: 450.9960 - smape: 99.9490 - coeff_determination: -0.2095\n",
            "Epoch 26/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1184225.2500 - rmse: 1082.8810 - mae: 464.1799 - smape: 99.9439 - coeff_determination: -0.2190"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 26: loss improved from 1148956.25000 to 1148859.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1148859.7500 - rmse: 1013.9922 - mae: 451.1719 - smape: 99.9451 - coeff_determination: -0.1954\n",
            "Epoch 27/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1131545.1250 - rmse: 1058.9800 - mae: 447.2881 - smape: 99.9378 - coeff_determination: -0.2114"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 27: loss improved from 1148859.75000 to 1148566.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 1148566.6250 - rmse: 1087.1063 - mae: 451.4289 - smape: 99.9384 - coeff_determination: -0.2146\n",
            "Epoch 28/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1102750.5000 - rmse: 1045.6869 - mae: 434.6802 - smape: 99.9308 - coeff_determination: -0.2012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 28: loss improved from 1148566.62500 to 1148117.50000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 1148117.5000 - rmse: 1113.8494 - mae: 451.5706 - smape: 99.9284 - coeff_determination: -0.2391\n",
            "Epoch 29/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1135138.1250 - rmse: 1055.9836 - mae: 444.7876 - smape: 99.9244 - coeff_determination: -0.2068"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 29: loss improved from 1148117.50000 to 1147710.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1147710.7500 - rmse: 1078.2206 - mae: 451.8367 - smape: 99.9222 - coeff_determination: -0.2269\n",
            "Epoch 30/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1143568.6250 - rmse: 1061.4209 - mae: 453.2629 - smape: 99.9123 - coeff_determination: -0.2156"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 30: loss improved from 1147710.75000 to 1147421.12500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1147421.1250 - rmse: 1069.4248 - mae: 452.0342 - smape: 99.9135 - coeff_determination: -0.2071\n",
            "Epoch 31/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1178984.6250 - rmse: 1081.6934 - mae: 462.8145 - smape: 99.9106 - coeff_determination: -0.2145"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 31: loss improved from 1147421.12500 to 1147175.50000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 1147175.5000 - rmse: 1020.8283 - mae: 452.2608 - smape: 99.9108 - coeff_determination: -0.1973\n",
            "Epoch 32/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1146014.5000 - rmse: 1069.6973 - mae: 453.2130 - smape: 99.8991 - coeff_determination: -0.2090"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 32: loss improved from 1147175.50000 to 1146677.87500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1146677.8750 - rmse: 1070.9785 - mae: 452.7189 - smape: 99.8988 - coeff_determination: -0.2063\n",
            "Epoch 33/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1186285.0000 - rmse: 1085.8163 - mae: 467.3130 - smape: 99.8931 - coeff_determination: -0.2168"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 33: loss improved from 1146677.87500 to 1146528.12500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1146528.1250 - rmse: 1005.4758 - mae: 452.8896 - smape: 99.8960 - coeff_determination: -0.1914\n",
            "Epoch 34/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1157275.6250 - rmse: 1074.5387 - mae: 455.9365 - smape: 99.8834 - coeff_determination: -0.2081"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 34: loss improved from 1146528.12500 to 1146007.50000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 1146007.5000 - rmse: 1054.9459 - mae: 453.2773 - smape: 99.8829 - coeff_determination: -0.2065\n",
            "Epoch 35/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1147845.3750 - rmse: 1065.6917 - mae: 455.3333 - smape: 99.8777 - coeff_determination: -0.2114"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 35: loss improved from 1146007.50000 to 1145737.37500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 1145737.3750 - rmse: 1063.2437 - mae: 453.5612 - smape: 99.8789 - coeff_determination: -0.2053\n",
            "Epoch 36/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1140403.7500 - rmse: 1060.9600 - mae: 450.4342 - smape: 99.8752 - coeff_determination: -0.2063"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 36: loss improved from 1145737.37500 to 1145564.50000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1145564.5000 - rmse: 1070.9067 - mae: 453.8782 - smape: 99.8747 - coeff_determination: -0.2162\n",
            "Epoch 37/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1129729.0000 - rmse: 1062.5439 - mae: 448.6680 - smape: 99.8570 - coeff_determination: -0.2030"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 37: loss improved from 1145564.50000 to 1144777.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 1144777.6250 - rmse: 1086.8141 - mae: 454.3673 - smape: 99.8556 - coeff_determination: -0.2148\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 1143753.7500 - rmse: 1009.8128 - mae: 454.5258 - smape: 99.8377 - coeff_determination: -0.1929"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 38: loss improved from 1144777.62500 to 1143753.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 84ms/step - loss: 1143753.7500 - rmse: 1009.8128 - mae: 454.5258 - smape: 99.8377 - coeff_determination: -0.1929\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 1143820.5000 - rmse: 1080.7258 - mae: 455.1514 - smape: 99.8368 - coeff_determination: -0.2147"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 39: loss did not improve from 1143753.75000\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 1143820.5000 - rmse: 1080.7258 - mae: 455.1514 - smape: 99.8368 - coeff_determination: -0.2147\n",
            "Epoch 40/200\n",
            "3/5 [=================>............] - ETA: 0s - loss: 1162871.6250 - rmse: 1073.3429 - mae: 458.9216 - smape: 99.8244 - coeff_determination: -0.2049"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 40: loss improved from 1143753.75000 to 1142896.37500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 1142896.3750 - rmse: 1082.3711 - mae: 455.4313 - smape: 99.8213 - coeff_determination: -0.2143\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 1142480.0000 - rmse: 1062.2634 - mae: 455.8884 - smape: 99.8129 - coeff_determination: -0.2229"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 41: loss improved from 1142896.37500 to 1142480.00000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 1142480.0000 - rmse: 1062.2634 - mae: 455.8884 - smape: 99.8129 - coeff_determination: -0.2229\n",
            "Epoch 42/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1152844.1250 - rmse: 1065.4523 - mae: 458.9720 - smape: 99.7912 - coeff_determination: -0.2063"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 42: loss improved from 1142480.00000 to 1141329.87500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 1141329.8750 - rmse: 1046.7655 - mae: 456.3174 - smape: 99.7895 - coeff_determination: -0.2040\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 1140927.2500 - rmse: 1074.7484 - mae: 457.0924 - smape: 99.7734 - coeff_determination: -0.2060"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 43: loss improved from 1141329.87500 to 1140927.25000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 89ms/step - loss: 1140927.2500 - rmse: 1074.7484 - mae: 457.0924 - smape: 99.7734 - coeff_determination: -0.2060\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 1140155.1250 - rmse: 1067.1399 - mae: 457.5773 - smape: 99.7622 - coeff_determination: -0.2132"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 44: loss improved from 1140927.25000 to 1140155.12500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 83ms/step - loss: 1140155.1250 - rmse: 1067.1399 - mae: 457.5773 - smape: 99.7622 - coeff_determination: -0.2132\n",
            "Epoch 45/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1127561.1250 - rmse: 1057.5883 - mae: 452.0034 - smape: 99.7491 - coeff_determination: -0.1968"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 45: loss improved from 1140155.12500 to 1139021.00000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1139021.0000 - rmse: 1077.1205 - mae: 458.4286 - smape: 99.7417 - coeff_determination: -0.2141\n",
            "Epoch 46/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1047358.3750 - rmse: 1012.7776 - mae: 421.3968 - smape: 99.7529 - coeff_determination: -0.1790"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 46: loss improved from 1139021.00000 to 1138297.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1138297.6250 - rmse: 1138.2664 - mae: 458.7746 - smape: 99.7205 - coeff_determination: -0.2969\n",
            "Epoch 47/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1181523.3750 - rmse: 1074.8362 - mae: 475.8809 - smape: 99.6848 - coeff_determination: -0.2099"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 47: loss improved from 1138297.62500 to 1136681.37500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1136681.3750 - rmse: 981.7505 - mae: 459.5104 - smape: 99.6904 - coeff_determination: -0.1794\n",
            "Epoch 48/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1133523.1250 - rmse: 1061.2952 - mae: 458.2327 - smape: 99.6798 - coeff_determination: -0.1961"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 48: loss improved from 1136681.37500 to 1136155.87500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1136155.8750 - rmse: 1066.3918 - mae: 460.4373 - smape: 99.6764 - coeff_determination: -0.2024\n",
            "Epoch 49/200\n",
            "3/5 [=================>............] - ETA: 0s - loss: 1060966.0000 - rmse: 1027.8800 - mae: 430.4877 - smape: 99.6976 - coeff_determination: -0.1794"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 49: loss improved from 1136155.87500 to 1136010.12500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 1136010.1250 - rmse: 1023.3889 - mae: 461.2082 - smape: 99.6700 - coeff_determination: -0.1864\n",
            "Epoch 50/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1128789.2500 - rmse: 1061.8513 - mae: 462.1632 - smape: 99.6283 - coeff_determination: -0.1964"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 50: loss improved from 1136010.12500 to 1134268.25000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 1134268.2500 - rmse: 1071.0912 - mae: 461.9453 - smape: 99.6333 - coeff_determination: -0.1921\n",
            "Epoch 51/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1097766.5000 - rmse: 1044.4590 - mae: 446.7689 - smape: 99.6395 - coeff_determination: -0.1858"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 51: loss improved from 1134268.25000 to 1133970.87500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1133970.8750 - rmse: 1100.2830 - mae: 462.5005 - smape: 99.6279 - coeff_determination: -0.2262\n",
            "Epoch 52/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1136841.5000 - rmse: 1061.3656 - mae: 468.0669 - smape: 99.5778 - coeff_determination: -0.1975"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 52: loss improved from 1133970.87500 to 1132118.37500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 1132118.3750 - rmse: 1054.1790 - mae: 463.7242 - smape: 99.5872 - coeff_determination: -0.1841\n",
            "Epoch 53/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1103058.1250 - rmse: 1049.1538 - mae: 451.3907 - smape: 99.5636 - coeff_determination: -0.1824"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 53: loss improved from 1132118.37500 to 1130190.87500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1130190.8750 - rmse: 1091.7716 - mae: 464.1446 - smape: 99.5485 - coeff_determination: -0.2178\n",
            "Epoch 54/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1068815.6250 - rmse: 1031.6830 - mae: 443.6214 - smape: 99.5563 - coeff_determination: -0.1801"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 54: loss improved from 1130190.87500 to 1130068.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 1130068.6250 - rmse: 1120.3347 - mae: 465.4017 - smape: 99.5408 - coeff_determination: -0.2289\n",
            "Epoch 55/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1114851.1250 - rmse: 1054.8470 - mae: 464.4314 - smape: 99.4997 - coeff_determination: -0.1907"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 55: loss improved from 1130068.62500 to 1128747.87500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1128747.8750 - rmse: 1077.6228 - mae: 466.4726 - smape: 99.5060 - coeff_determination: -0.1887\n",
            "Epoch 56/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1123682.8750 - rmse: 1057.2607 - mae: 462.7872 - smape: 99.4647 - coeff_determination: -0.1816"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 56: loss improved from 1128747.87500 to 1126302.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1126302.7500 - rmse: 1062.2356 - mae: 467.8424 - smape: 99.4479 - coeff_determination: -0.2031\n",
            "Epoch 57/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1121023.7500 - rmse: 1052.9355 - mae: 465.4011 - smape: 99.4547 - coeff_determination: -0.1851"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 57: loss improved from 1126302.75000 to 1125883.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1125883.7500 - rmse: 1062.2419 - mae: 468.7134 - smape: 99.4468 - coeff_determination: -0.1947\n",
            "Epoch 58/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1151042.1250 - rmse: 1067.3485 - mae: 479.4982 - smape: 99.4110 - coeff_determination: -0.1917"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 58: loss improved from 1125883.75000 to 1124213.37500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1124213.3750 - rmse: 1017.1377 - mae: 470.0149 - smape: 99.4146 - coeff_determination: -0.1740\n",
            "Epoch 59/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1062903.8750 - rmse: 1023.8417 - mae: 449.9590 - smape: 99.3874 - coeff_determination: -0.1711"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 59: loss improved from 1124213.37500 to 1121379.37500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1121379.3750 - rmse: 1110.2340 - mae: 471.1700 - smape: 99.3640 - coeff_determination: -0.2193\n",
            "Epoch 60/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1138410.2500 - rmse: 1062.7661 - mae: 478.1334 - smape: 99.3410 - coeff_determination: -0.1849"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 60: loss improved from 1121379.37500 to 1120902.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 1120902.6250 - rmse: 1031.5529 - mae: 472.7272 - smape: 99.3376 - coeff_determination: -0.1748\n",
            "Epoch 61/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1149786.7500 - rmse: 1067.5824 - mae: 483.9591 - smape: 99.2870 - coeff_determination: -0.1855"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 61: loss improved from 1120902.62500 to 1119202.00000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1119202.0000 - rmse: 1008.6261 - mae: 473.9027 - smape: 99.2850 - coeff_determination: -0.1671\n",
            "Epoch 62/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1121085.0000 - rmse: 1057.3257 - mae: 478.5402 - smape: 99.2292 - coeff_determination: -0.1806"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 62: loss improved from 1119202.00000 to 1116601.50000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1116601.5000 - rmse: 1049.8295 - mae: 474.9720 - smape: 99.2445 - coeff_determination: -0.1690\n",
            "Epoch 63/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1139499.7500 - rmse: 1063.3628 - mae: 484.9454 - smape: 99.1692 - coeff_determination: -0.1786"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 63: loss improved from 1116601.50000 to 1113740.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1113740.6250 - rmse: 1014.8998 - mae: 476.4123 - smape: 99.1715 - coeff_determination: -0.1632\n",
            "Epoch 64/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1109906.3750 - rmse: 1048.9099 - mae: 475.7443 - smape: 99.1438 - coeff_determination: -0.1696"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 64: loss improved from 1113740.62500 to 1110953.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 1110953.6250 - rmse: 1051.6204 - mae: 477.9792 - smape: 99.1182 - coeff_determination: -0.1766\n",
            "Epoch 65/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1145852.7500 - rmse: 1068.6044 - mae: 495.9664 - smape: 99.0290 - coeff_determination: -0.1797"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 65: loss improved from 1110953.62500 to 1109175.37500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1109175.3750 - rmse: 993.9108 - mae: 480.3593 - smape: 99.0637 - coeff_determination: -0.1485\n",
            "Epoch 66/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1125258.3750 - rmse: 1053.2207 - mae: 489.6190 - smape: 99.0333 - coeff_determination: -0.1757"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 66: loss improved from 1109175.37500 to 1107918.87500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1107918.8750 - rmse: 1022.7977 - mae: 482.1830 - smape: 99.0513 - coeff_determination: -0.1609\n",
            "Epoch 67/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1098663.0000 - rmse: 1044.2460 - mae: 483.9237 - smape: 99.0019 - coeff_determination: -0.1667"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 67: loss improved from 1107918.87500 to 1105524.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 1105524.7500 - rmse: 1056.5422 - mae: 484.1586 - smape: 99.0135 - coeff_determination: -0.1628\n",
            "Epoch 68/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1109872.7500 - rmse: 1050.4679 - mae: 487.1613 - smape: 99.0004 - coeff_determination: -0.1664"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 68: loss improved from 1105524.75000 to 1104894.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1104894.7500 - rmse: 1042.3582 - mae: 485.5456 - smape: 98.9934 - coeff_determination: -0.1611\n",
            "Epoch 69/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1123765.5000 - rmse: 1058.4076 - mae: 495.7991 - smape: 98.8920 - coeff_determination: -0.1670"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 69: loss improved from 1104894.75000 to 1102450.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 1102450.6250 - rmse: 1018.6188 - mae: 487.3307 - smape: 98.9145 - coeff_determination: -0.1493\n",
            "Epoch 70/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1101838.5000 - rmse: 1044.2930 - mae: 494.2469 - smape: 98.8064 - coeff_determination: -0.1647"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 70: loss improved from 1102450.62500 to 1098937.12500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1098937.1250 - rmse: 1040.3168 - mae: 489.7298 - smape: 98.8440 - coeff_determination: -0.1516\n",
            "Epoch 71/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1116283.1250 - rmse: 1052.2308 - mae: 500.8122 - smape: 98.7589 - coeff_determination: -0.1627"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 71: loss improved from 1098937.12500 to 1097128.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 1097128.6250 - rmse: 1017.3097 - mae: 492.0506 - smape: 98.7893 - coeff_determination: -0.1441\n",
            "Epoch 72/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1094252.0000 - rmse: 1043.9369 - mae: 493.1518 - smape: 98.7412 - coeff_determination: -0.1564"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 72: loss improved from 1097128.62500 to 1095488.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1095488.6250 - rmse: 1046.4875 - mae: 493.2867 - smape: 98.7366 - coeff_determination: -0.1532\n",
            "Epoch 73/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1070476.2500 - rmse: 1033.2358 - mae: 483.9258 - smape: 98.7350 - coeff_determination: -0.1420"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 73: loss improved from 1095488.62500 to 1092079.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1092079.7500 - rmse: 1068.3141 - mae: 496.0685 - smape: 98.6603 - coeff_determination: -0.1790\n",
            "Epoch 74/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1043999.0000 - rmse: 1021.4015 - mae: 482.0584 - smape: 98.6454 - coeff_determination: -0.1393"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 74: loss improved from 1092079.75000 to 1088823.37500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1088823.3750 - rmse: 1089.4316 - mae: 497.6166 - smape: 98.5960 - coeff_determination: -0.1722\n",
            "Epoch 75/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1032731.6875 - rmse: 1014.2646 - mae: 479.5504 - smape: 98.5883 - coeff_determination: -0.1373"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 75: loss improved from 1088823.37500 to 1087164.12500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1087164.1250 - rmse: 1095.3937 - mae: 499.0710 - smape: 98.5358 - coeff_determination: -0.1778\n",
            "Epoch 76/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1101822.2500 - rmse: 1048.4556 - mae: 507.3226 - smape: 98.4149 - coeff_determination: -0.1405"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 76: loss improved from 1087164.12500 to 1080197.25000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1080197.2500 - rmse: 1007.4214 - mae: 502.3795 - smape: 98.4075 - coeff_determination: -0.1351\n",
            "Epoch 77/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1093873.1250 - rmse: 1037.9432 - mae: 509.9795 - smape: 98.3387 - coeff_determination: -0.1385"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 77: loss improved from 1080197.25000 to 1077144.12500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1077144.1250 - rmse: 1008.3024 - mae: 506.0921 - smape: 98.3224 - coeff_determination: -0.1303\n",
            "Epoch 78/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1071288.5000 - rmse: 1031.9249 - mae: 503.7084 - smape: 98.3565 - coeff_determination: -0.1350"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 78: loss did not improve from 1077144.12500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1077978.3750 - rmse: 1043.9114 - mae: 506.1111 - smape: 98.3227 - coeff_determination: -0.1372\n",
            "Epoch 79/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1044479.7500 - rmse: 1014.2035 - mae: 499.9846 - smape: 98.2213 - coeff_determination: -0.1259"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 79: loss improved from 1077144.12500 to 1072040.00000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1072040.0000 - rmse: 1059.7498 - mae: 510.5970 - smape: 98.1910 - coeff_determination: -0.1479\n",
            "Epoch 80/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1115622.1250 - rmse: 1042.6912 - mae: 530.3193 - smape: 98.0973 - coeff_determination: -0.1454"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 80: loss improved from 1072040.00000 to 1070556.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1070556.7500 - rmse: 943.9601 - mae: 512.9431 - smape: 98.1536 - coeff_determination: -0.1164\n",
            "Epoch 81/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1052226.8750 - rmse: 1024.6157 - mae: 511.2799 - smape: 98.1278 - coeff_determination: -0.1259"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 81: loss improved from 1070556.75000 to 1070025.25000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 1070025.2500 - rmse: 1054.1096 - mae: 515.3591 - smape: 98.1286 - coeff_determination: -0.1305\n",
            "Epoch 82/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1075122.5000 - rmse: 1033.4595 - mae: 522.2582 - smape: 97.9818 - coeff_determination: -0.1279"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 82: loss improved from 1070025.25000 to 1066409.87500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 1066409.8750 - rmse: 1018.3625 - mae: 518.9909 - smape: 97.9955 - coeff_determination: -0.1173\n",
            "Epoch 83/200\n",
            "3/5 [=================>............] - ETA: 0s - loss: 1045891.3125 - rmse: 1022.2366 - mae: 516.1951 - smape: 97.9031 - coeff_determination: -0.1139"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 83: loss improved from 1066409.87500 to 1056918.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 1056918.7500 - rmse: 1041.3635 - mae: 519.9951 - smape: 97.8479 - coeff_determination: -0.1182\n",
            "Epoch 84/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1074610.5000 - rmse: 1025.1942 - mae: 528.7939 - smape: 97.8096 - coeff_determination: -0.1217"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 84: loss did not improve from 1056918.75000\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 1058518.0000 - rmse: 997.2285 - mae: 523.1478 - smape: 97.8355 - coeff_determination: -0.1122\n",
            "Epoch 85/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1008369.0000 - rmse: 1001.4528 - mae: 513.5267 - smape: 97.7119 - coeff_determination: -0.1032"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 85: loss improved from 1056918.75000 to 1052232.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 1052232.7500 - rmse: 1069.5530 - mae: 526.7693 - smape: 97.6868 - coeff_determination: -0.1257\n",
            "Epoch 86/200\n",
            "3/5 [=================>............] - ETA: 0s - loss: 1075224.3750 - rmse: 1036.1772 - mae: 540.0732 - smape: 97.6334 - coeff_determination: -0.1185"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 86: loss improved from 1052232.75000 to 1049902.12500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 1049902.1250 - rmse: 1029.4822 - mae: 527.4102 - smape: 97.6958 - coeff_determination: -0.1043\n",
            "Epoch 87/200\n",
            "3/5 [=================>............] - ETA: 0s - loss: 1079145.3750 - rmse: 1038.2992 - mae: 547.1115 - smape: 97.3325 - coeff_determination: -0.1034"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 87: loss improved from 1049902.12500 to 1040154.00000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 1040154.0000 - rmse: 968.7288 - mae: 530.5269 - smape: 97.4503 - coeff_determination: -0.0811\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 1041332.1875 - rmse: 1009.1774 - mae: 533.9986 - smape: 97.4311 - coeff_determination: -0.0870"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 88: loss did not improve from 1040154.00000\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 1041332.1875 - rmse: 1009.1774 - mae: 533.9986 - smape: 97.4311 - coeff_determination: -0.0870\n",
            "Epoch 89/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1092731.6250 - rmse: 1036.9038 - mae: 553.6302 - smape: 97.2687 - coeff_determination: -0.1096"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 89: loss did not improve from 1040154.00000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 1040419.1875 - rmse: 906.3657 - mae: 534.6014 - smape: 97.3648 - coeff_determination: -0.0972\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 1032535.3750 - rmse: 1001.6608 - mae: 538.3718 - smape: 97.2013 - coeff_determination: -0.0962"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 90: loss improved from 1040154.00000 to 1032535.37500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 88ms/step - loss: 1032535.3750 - rmse: 1001.6608 - mae: 538.3718 - smape: 97.2013 - coeff_determination: -0.0962\n",
            "Epoch 91/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1057684.6250 - rmse: 1027.9532 - mae: 553.6184 - smape: 97.0025 - coeff_determination: -0.0910"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 91: loss improved from 1032535.37500 to 1028351.31250, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 1028351.3125 - rmse: 967.6525 - mae: 541.2163 - smape: 97.0930 - coeff_determination: -0.0743\n",
            "Epoch 92/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1013877.1250 - rmse: 1000.4406 - mae: 539.9698 - smape: 96.9842 - coeff_determination: -0.0779"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 92: loss improved from 1028351.31250 to 1021851.50000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 1021851.5000 - rmse: 1015.5685 - mae: 543.1896 - smape: 96.9882 - coeff_determination: -0.0837\n",
            "Epoch 93/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 995788.7500 - rmse: 997.8768 - mae: 537.1935 - smape: 96.9931 - coeff_determination: -0.0714"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 93: loss did not improve from 1021851.50000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 1022383.3750 - rmse: 1041.3047 - mae: 547.8887 - smape: 96.9205 - coeff_determination: -0.0971\n",
            "Epoch 94/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1070245.1250 - rmse: 1032.3683 - mae: 568.0954 - smape: 96.8425 - coeff_determination: -0.0874"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 94: loss did not improve from 1021851.50000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1023312.0625 - rmse: 920.1965 - mae: 552.1252 - smape: 96.9010 - coeff_determination: -0.0598\n",
            "Epoch 95/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1020463.6250 - rmse: 1010.0648 - mae: 558.0537 - smape: 96.6707 - coeff_determination: -0.0738"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 95: loss improved from 1021851.50000 to 1017030.50000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1017030.5000 - rmse: 1003.8516 - mae: 554.8984 - smape: 96.7168 - coeff_determination: -0.0666\n",
            "Epoch 96/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1044101.3750 - rmse: 1017.9091 - mae: 567.3818 - smape: 96.5906 - coeff_determination: -0.0748"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 96: loss improved from 1017030.50000 to 1014206.12500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 1014206.1250 - rmse: 956.3123 - mae: 554.9724 - smape: 96.6870 - coeff_determination: -0.0675\n",
            "Epoch 97/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1015929.3750 - rmse: 1006.0685 - mae: 562.1847 - smape: 96.3761 - coeff_determination: -0.0582"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 97: loss improved from 1014206.12500 to 1001638.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1001638.6250 - rmse: 978.9517 - mae: 555.8676 - smape: 96.4462 - coeff_determination: -0.0520\n",
            "Epoch 98/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 975161.8750 - rmse: 984.5108 - mae: 549.4575 - smape: 96.5223 - coeff_determination: -0.0498"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 98: loss improved from 1001638.62500 to 1000980.18750, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 1000980.1875 - rmse: 1027.7429 - mae: 559.7459 - smape: 96.3548 - coeff_determination: -0.0745\n",
            "Epoch 99/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1018251.0625 - rmse: 1005.7510 - mae: 573.7338 - smape: 96.1437 - coeff_determination: -0.0598"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 99: loss improved from 1000980.18750 to 998304.93750, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 998304.9375 - rmse: 966.8218 - mae: 563.1780 - smape: 96.2955 - coeff_determination: -0.0435\n",
            "Epoch 100/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 990275.8750 - rmse: 991.6855 - mae: 563.5474 - smape: 96.0175 - coeff_determination: -0.0423  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 100: loss improved from 998304.93750 to 986270.56250, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 986270.5625 - rmse: 984.9640 - mae: 560.9171 - smape: 96.0960 - coeff_determination: -0.0381\n",
            "Epoch 101/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1016984.3750 - rmse: 1006.5659 - mae: 577.1558 - smape: 96.0341 - coeff_determination: -0.0557"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 101: loss did not improve from 986270.56250\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 996111.0000 - rmse: 965.2366 - mae: 570.2151 - smape: 96.1268 - coeff_determination: -0.0425\n",
            "Epoch 102/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 997470.0625 - rmse: 993.0499 - mae: 575.9043 - smape: 95.7378 - coeff_determination: -0.0342"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 102: loss improved from 986270.56250 to 975497.68750, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 975497.6875 - rmse: 949.4242 - mae: 568.4209 - smape: 95.8050 - coeff_determination: -0.0306\n",
            "Epoch 103/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1003088.5000 - rmse: 995.2001 - mae: 577.7043 - smape: 95.7577 - coeff_determination: -0.0406"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 103: loss did not improve from 975497.68750\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 981621.6250 - rmse: 953.0363 - mae: 571.9088 - smape: 95.7943 - coeff_determination: -0.0362\n",
            "Epoch 104/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 958073.6250 - rmse: 971.5876 - mae: 569.7456 - smape: 95.6595 - coeff_determination: -0.0233  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 104: loss improved from 975497.68750 to 971560.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 971560.6250 - rmse: 996.5178 - mae: 572.9057 - smape: 95.6578 - coeff_determination: -0.0319\n",
            "Epoch 105/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 946626.7500 - rmse: 967.2748 - mae: 565.6379 - smape: 95.4860 - coeff_determination: -0.0154  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 105: loss improved from 971560.62500 to 961765.50000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 961765.5000 - rmse: 994.7391 - mae: 567.6331 - smape: 95.5528 - coeff_determination: -0.0154\n",
            "Epoch 106/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 969038.8125 - rmse: 984.0198 - mae: 576.5568 - smape: 95.4371 - coeff_determination: -0.0148"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 106: loss did not improve from 961765.50000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 963601.9375 - rmse: 973.8505 - mae: 576.0961 - smape: 95.4273 - coeff_determination: -0.0188\n",
            "Epoch 107/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 927364.5625 - rmse: 958.8207 - mae: 566.6108 - smape: 95.4913 - coeff_determination: -0.0050"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 107: loss improved from 961765.50000 to 957367.18750, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 957367.1875 - rmse: 1009.4952 - mae: 579.5380 - smape: 95.3050 - coeff_determination: -0.0309\n",
            "Epoch 108/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1006599.1250 - rmse: 1002.3690 - mae: 599.7216 - smape: 95.2271 - coeff_determination: -0.0244"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 108: loss did not improve from 957367.18750\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 965093.0000 - rmse: 903.2306 - mae: 585.4791 - smape: 95.3194 - coeff_determination: -0.0043\n",
            "Epoch 109/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 921199.3125 - rmse: 956.5660 - mae: 570.4575 - smape: 94.9977 - coeff_determination: 0.0094"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 109: loss improved from 957367.18750 to 940145.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 940145.6250 - rmse: 990.0634 - mae: 577.5215 - smape: 94.9037 - coeff_determination: 0.0013\n",
            "Epoch 110/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 952506.7500 - rmse: 975.8092 - mae: 585.7650 - smape: 95.1250 - coeff_determination: -0.0029"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 110: loss did not improve from 940145.62500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 954152.8750 - rmse: 978.8641 - mae: 588.2265 - smape: 95.1001 - coeff_determination: -0.0105\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 939520.4375 - rmse: 917.2739 - mae: 588.0406 - smape: 94.7993 - coeff_determination: -0.0094"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 111: loss improved from 940145.62500 to 939520.43750, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 939520.4375 - rmse: 917.2739 - mae: 588.0406 - smape: 94.7993 - coeff_determination: -0.0094\n",
            "Epoch 112/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 941345.0000 - rmse: 967.1378 - mae: 587.8566 - smape: 94.5650 - coeff_determination: 0.0173"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 112: loss improved from 939520.43750 to 928748.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 928748.6250 - rmse: 942.6802 - mae: 581.1672 - smape: 94.6591 - coeff_determination: 0.0272\n",
            "Epoch 113/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 921907.9375 - rmse: 955.6078 - mae: 581.6044 - smape: 94.7933 - coeff_determination: 0.0165"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 113: loss improved from 928748.62500 to 923363.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 923363.6250 - rmse: 959.2381 - mae: 587.1236 - smape: 94.4451 - coeff_determination: 0.0286\n",
            "Epoch 114/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 941932.5625 - rmse: 966.9828 - mae: 600.0690 - smape: 94.2502 - coeff_determination: 0.0140   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 114: loss did not improve from 923363.62500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 924881.1250 - rmse: 932.8182 - mae: 592.3643 - smape: 94.4233 - coeff_determination: 0.0261\n",
            "Epoch 115/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 919135.7500 - rmse: 951.9097 - mae: 593.6477 - smape: 94.3020 - coeff_determination: 0.0264"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 115: loss improved from 923363.62500 to 919249.18750, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 919249.1875 - rmse: 953.4845 - mae: 593.2002 - smape: 94.3219 - coeff_determination: 0.0289\n",
            "Epoch 116/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 892977.5000 - rmse: 943.7512 - mae: 583.2288 - smape: 94.2198 - coeff_determination: 0.0450"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 116: loss improved from 919249.18750 to 907324.31250, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 907324.3125 - rmse: 969.6799 - mae: 589.5126 - smape: 94.1020 - coeff_determination: 0.0321\n",
            "Epoch 117/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 908420.8125 - rmse: 950.1436 - mae: 588.1284 - smape: 94.1441 - coeff_determination: 0.0317 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 117: loss did not improve from 907324.31250\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 914085.8750 - rmse: 961.1888 - mae: 589.1078 - smape: 94.2140 - coeff_determination: 0.0286\n",
            "Epoch 118/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 911105.0000 - rmse: 948.5978 - mae: 602.1852 - smape: 93.7463 - coeff_determination: 0.0436   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 118: loss improved from 907324.31250 to 904601.87500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 904601.8750 - rmse: 937.0483 - mae: 598.2099 - smape: 93.9612 - coeff_determination: 0.0286\n",
            "Epoch 119/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 934101.0000 - rmse: 960.7611 - mae: 604.3492 - smape: 93.7089 - coeff_determination: 0.0416  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 119: loss improved from 904601.87500 to 902569.56250, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 902569.5625 - rmse: 889.3455 - mae: 593.4318 - smape: 93.9260 - coeff_determination: -0.0046\n",
            "Epoch 120/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 934465.7500 - rmse: 965.8731 - mae: 605.9023 - smape: 93.8835 - coeff_determination: 0.0426  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 120: loss did not improve from 902569.56250\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 906774.0000 - rmse: 904.4814 - mae: 597.6422 - smape: 93.9859 - coeff_determination: 0.0411\n",
            "Epoch 121/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 900676.3750 - rmse: 941.4752 - mae: 601.7643 - smape: 93.7284 - coeff_determination: 0.0361  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 121: loss improved from 902569.56250 to 896186.25000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 896186.2500 - rmse: 934.2388 - mae: 600.0047 - smape: 93.7045 - coeff_determination: 0.0507\n",
            "Epoch 122/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 901007.1250 - rmse: 942.5285 - mae: 595.2191 - smape: 93.5524 - coeff_determination: 0.0569"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 122: loss improved from 896186.25000 to 886169.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 886169.7500 - rmse: 913.1385 - mae: 590.4926 - smape: 93.6084 - coeff_determination: 0.0613\n",
            "Epoch 123/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 868057.3750 - rmse: 925.2788 - mae: 592.6143 - smape: 93.3134 - coeff_determination: 0.0800"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 123: loss improved from 886169.75000 to 882627.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 882627.7500 - rmse: 952.9479 - mae: 596.7479 - smape: 93.4487 - coeff_determination: 0.0532\n",
            "Epoch 124/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 884118.1250 - rmse: 939.3288 - mae: 597.6301 - smape: 93.1125 - coeff_determination: 0.0723"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 124: loss improved from 882627.75000 to 879368.00000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 879368.0000 - rmse: 930.1581 - mae: 592.5764 - smape: 93.3437 - coeff_determination: 0.0510\n",
            "Epoch 125/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 867968.5000 - rmse: 931.0886 - mae: 591.5609 - smape: 93.0676 - coeff_determination: 0.0818"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 125: loss improved from 879368.00000 to 869552.31250, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 869552.3125 - rmse: 934.2469 - mae: 593.2589 - smape: 93.1525 - coeff_determination: 0.0719\n",
            "Epoch 126/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 896633.8750 - rmse: 945.2017 - mae: 606.4166 - smape: 93.2040 - coeff_determination: 0.0670"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 126: loss did not improve from 869552.31250\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 887471.7500 - rmse: 927.1707 - mae: 602.4099 - smape: 93.4178 - coeff_determination: 0.0432\n",
            "Epoch 127/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 876755.2500 - rmse: 933.6066 - mae: 606.7125 - smape: 92.9367 - coeff_determination: 0.0766  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 127: loss did not improve from 869552.31250\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 875023.6250 - rmse: 930.7842 - mae: 605.4754 - smape: 93.0449 - coeff_determination: 0.0698\n",
            "Epoch 128/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 892772.5000 - rmse: 944.5745 - mae: 612.6991 - smape: 93.0679 - coeff_determination: 0.0713"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 128: loss did not improve from 869552.31250\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 875591.6875 - rmse: 908.2863 - mae: 606.0425 - smape: 93.1252 - coeff_determination: 0.0677\n",
            "Epoch 129/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 847835.1250 - rmse: 917.1240 - mae: 595.4963 - smape: 92.5711 - coeff_determination: 0.1091  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 129: loss improved from 869552.31250 to 848079.25000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 848079.2500 - rmse: 918.3334 - mae: 593.6162 - smape: 92.7186 - coeff_determination: 0.0940\n",
            "Epoch 130/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 868000.3750 - rmse: 930.4266 - mae: 613.2887 - smape: 92.5342 - coeff_determination: 0.0903"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 130: loss did not improve from 848079.25000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 861169.1250 - rmse: 916.9197 - mae: 605.8727 - smape: 92.8550 - coeff_determination: 0.0729\n",
            "Epoch 131/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 852306.1250 - rmse: 916.4541 - mae: 599.0189 - smape: 92.8581 - coeff_determination: 0.0893  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 131: loss improved from 848079.25000 to 847901.56250, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 847901.5625 - rmse: 908.9735 - mae: 599.9198 - smape: 92.6471 - coeff_determination: 0.1154\n",
            "Epoch 132/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 858566.6250 - rmse: 925.8397 - mae: 601.9782 - smape: 92.8584 - coeff_determination: 0.0940"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 132: loss did not improve from 847901.56250\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 855334.0625 - rmse: 919.5757 - mae: 600.2979 - smape: 92.8312 - coeff_determination: 0.0994\n",
            "Epoch 133/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 854970.5000 - rmse: 919.5508 - mae: 602.4924 - smape: 92.4473 - coeff_determination: 0.1054  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 133: loss improved from 847901.56250 to 845482.75000, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 845482.7500 - rmse: 900.9959 - mae: 599.7651 - smape: 92.4570 - coeff_determination: 0.1057\n",
            "Epoch 134/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 835574.1875 - rmse: 912.1467 - mae: 593.2111 - smape: 92.8112 - coeff_determination: 0.1081"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 134: loss did not improve from 845482.75000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 846818.9375 - rmse: 933.5536 - mae: 600.4117 - smape: 92.5204 - coeff_determination: 0.1048\n",
            "Epoch 135/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 847166.5625 - rmse: 917.4018 - mae: 603.5593 - smape: 92.2208 - coeff_determination: 0.1249"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 135: loss improved from 845482.75000 to 836810.18750, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 836810.1875 - rmse: 896.4098 - mae: 600.4301 - smape: 92.3282 - coeff_determination: 0.1001\n",
            "Epoch 136/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 816944.6250 - rmse: 899.6212 - mae: 591.6143 - smape: 92.4311 - coeff_determination: 0.1118"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 136: loss improved from 836810.18750 to 834790.87500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 834790.8750 - rmse: 933.1792 - mae: 596.8340 - smape: 92.3217 - coeff_determination: 0.1046\n",
            "Epoch 137/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 852360.1250 - rmse: 922.2732 - mae: 615.1050 - smape: 91.8391 - coeff_determination: 0.1249"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 137: loss did not improve from 834790.87500\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 836699.8125 - rmse: 888.7397 - mae: 610.1538 - smape: 92.1048 - coeff_determination: 0.0307\n",
            "Epoch 138/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 802218.6875 - rmse: 893.5164 - mae: 590.7609 - smape: 92.4356 - coeff_determination: 0.1163"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 138: loss improved from 834790.87500 to 833180.43750, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 833180.4375 - rmse: 948.1879 - mae: 602.7767 - smape: 92.1087 - coeff_determination: 0.1064\n",
            "Epoch 139/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 822920.0000 - rmse: 906.4329 - mae: 595.4832 - smape: 92.2721 - coeff_determination: 0.1238"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 139: loss improved from 833180.43750 to 824653.31250, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 824653.3125 - rmse: 909.9959 - mae: 596.7354 - smape: 92.0496 - coeff_determination: 0.1379\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 820031.1250 - rmse: 849.8563 - mae: 600.8070 - smape: 91.8440 - coeff_determination: 0.0764"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 140: loss improved from 824653.31250 to 820031.12500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 820031.1250 - rmse: 849.8563 - mae: 600.8070 - smape: 91.8440 - coeff_determination: 0.0764\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 833625.7500 - rmse: 854.8241 - mae: 606.7121 - smape: 91.9252 - coeff_determination: 0.0485"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 141: loss did not improve from 820031.12500\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 833625.7500 - rmse: 854.8241 - mae: 606.7121 - smape: 91.9252 - coeff_determination: 0.0485\n",
            "Epoch 142/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 829240.5000 - rmse: 908.6149 - mae: 606.8107 - smape: 91.6458 - coeff_determination: 0.1286"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 142: loss improved from 820031.12500 to 813876.93750, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 813876.9375 - rmse: 875.4412 - mae: 598.7228 - smape: 91.7383 - coeff_determination: 0.1478\n",
            "Epoch 143/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 792707.1875 - rmse: 881.9645 - mae: 589.4865 - smape: 91.8275 - coeff_determination: 0.1548  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 143: loss did not improve from 813876.93750\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 817266.3125 - rmse: 927.9594 - mae: 597.6956 - smape: 91.8365 - coeff_determination: 0.1168\n",
            "Epoch 144/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 807811.0000 - rmse: 894.5095 - mae: 598.3813 - smape: 91.3070 - coeff_determination: 0.1599"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 144: loss improved from 813876.93750 to 805810.56250, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 88ms/step - loss: 805810.5625 - rmse: 891.2970 - mae: 598.6795 - smape: 91.3949 - coeff_determination: 0.1437\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 826453.2500 - rmse: 909.8283 - mae: 604.1890 - smape: 91.7467 - coeff_determination: 0.1282"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 145: loss did not improve from 805810.56250\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 826453.2500 - rmse: 909.8283 - mae: 604.1890 - smape: 91.7467 - coeff_determination: 0.1282\n",
            "Epoch 146/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 826416.8750 - rmse: 907.2252 - mae: 601.7266 - smape: 91.7181 - coeff_determination: 0.1323"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 146: loss did not improve from 805810.56250\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 818871.3750 - rmse: 891.9240 - mae: 598.0413 - smape: 91.8107 - coeff_determination: 0.1369\n",
            "Epoch 147/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 847929.7500 - rmse: 920.0950 - mae: 617.2717 - smape: 91.6583 - coeff_determination: 0.1139"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 147: loss did not improve from 805810.56250\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 841604.6875 - rmse: 907.3835 - mae: 611.9269 - smape: 91.7477 - coeff_determination: 0.1132\n",
            "Epoch 148/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 790336.3750 - rmse: 886.4296 - mae: 597.1420 - smape: 91.1989 - coeff_determination: 0.1540"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 148: loss did not improve from 805810.56250\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 809949.5000 - rmse: 923.1232 - mae: 603.9200 - smape: 91.3021 - coeff_determination: 0.1140\n",
            "Epoch 149/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 837866.3750 - rmse: 914.3138 - mae: 615.5452 - smape: 91.3924 - coeff_determination: 0.1260"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 149: loss did not improve from 805810.56250\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 819604.5000 - rmse: 873.9901 - mae: 607.4462 - smape: 91.7248 - coeff_determination: 0.0862\n",
            "Epoch 150/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 800014.7500 - rmse: 887.0937 - mae: 592.5651 - smape: 91.5595 - coeff_determination: 0.1310"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 150: loss improved from 805810.56250 to 798589.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 798589.6250 - rmse: 885.6599 - mae: 594.5558 - smape: 91.2717 - coeff_determination: 0.1705\n",
            "Epoch 151/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 830064.0000 - rmse: 908.7241 - mae: 606.1611 - smape: 91.3717 - coeff_determination: 0.1230"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 151: loss did not improve from 798589.62500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 819024.0625 - rmse: 885.8011 - mae: 603.9893 - smape: 91.5134 - coeff_determination: 0.1189\n",
            "Epoch 152/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 818413.8125 - rmse: 903.6345 - mae: 603.7798 - smape: 91.9874 - coeff_determination: 0.1051"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 152: loss did not improve from 798589.62500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 822133.9375 - rmse: 911.1229 - mae: 605.3918 - smape: 91.5080 - coeff_determination: 0.1498\n",
            "Epoch 153/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 778872.8125 - rmse: 880.3167 - mae: 592.9597 - smape: 91.0493 - coeff_determination: 0.1496"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 153: loss did not improve from 798589.62500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 808230.8125 - rmse: 933.1004 - mae: 603.4067 - smape: 91.0544 - coeff_determination: 0.1052\n",
            "Epoch 154/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 816334.1250 - rmse: 900.3550 - mae: 607.1357 - smape: 91.3028 - coeff_determination: 0.1359"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 154: loss did not improve from 798589.62500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 822089.3750 - rmse: 912.1499 - mae: 608.7777 - smape: 91.3594 - coeff_determination: 0.1385\n",
            "Epoch 155/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 814118.3750 - rmse: 902.2297 - mae: 609.0386 - smape: 90.7392 - coeff_determination: 0.1492"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 155: loss did not improve from 798589.62500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 805174.5000 - rmse: 883.3426 - mae: 603.2578 - smape: 91.0804 - coeff_determination: 0.1215\n",
            "Epoch 156/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 757283.5625 - rmse: 869.3899 - mae: 585.3895 - smape: 91.1684 - coeff_determination: 0.1623"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 156: loss improved from 798589.62500 to 795609.62500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 795609.6250 - rmse: 936.3195 - mae: 597.8285 - smape: 91.1184 - coeff_determination: 0.1327\n",
            "Epoch 157/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 773939.9375 - rmse: 878.4974 - mae: 585.2905 - smape: 91.2810 - coeff_determination: 0.1683"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 157: loss did not improve from 795609.62500\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 799070.5625 - rmse: 924.4253 - mae: 595.0694 - smape: 91.0382 - coeff_determination: 0.1303\n",
            "Epoch 158/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 798259.1875 - rmse: 893.0717 - mae: 596.1981 - smape: 90.8779 - coeff_determination: 0.1434"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 158: loss did not improve from 795609.62500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 803162.4375 - rmse: 902.8021 - mae: 599.9099 - smape: 90.7738 - coeff_determination: 0.1639\n",
            "Epoch 159/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 811447.1250 - rmse: 896.8138 - mae: 604.3702 - smape: 90.9353 - coeff_determination: 0.1561  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 159: loss did not improve from 795609.62500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 797728.5625 - rmse: 867.5975 - mae: 600.0059 - smape: 90.9999 - coeff_determination: 0.1648\n",
            "Epoch 160/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 810161.1875 - rmse: 895.8764 - mae: 599.6653 - smape: 90.5746 - coeff_determination: 0.1592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 160: loss did not improve from 795609.62500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 797614.6250 - rmse: 869.4738 - mae: 595.3471 - smape: 90.9346 - coeff_determination: 0.0654\n",
            "Epoch 161/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 800147.0000 - rmse: 888.1575 - mae: 595.3313 - smape: 90.7069 - coeff_determination: 0.1464"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 161: loss did not improve from 795609.62500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 803777.5000 - rmse: 896.6160 - mae: 598.5225 - smape: 90.8326 - coeff_determination: 0.1111\n",
            "Epoch 162/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 811814.5000 - rmse: 897.1426 - mae: 598.5415 - smape: 90.7379 - coeff_determination: 0.1615"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 162: loss improved from 795609.62500 to 785903.81250, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 785903.8125 - rmse: 834.9651 - mae: 586.6964 - smape: 90.9887 - coeff_determination: 0.1736\n",
            "Epoch 163/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 779857.4375 - rmse: 880.5652 - mae: 589.3140 - smape: 90.7064 - coeff_determination: 0.1780"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 163: loss improved from 785903.81250 to 784624.18750, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 784624.1875 - rmse: 890.5679 - mae: 592.3002 - smape: 90.8623 - coeff_determination: 0.1293\n",
            "Epoch 164/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 790727.4375 - rmse: 883.7852 - mae: 598.5331 - smape: 90.6603 - coeff_determination: 0.1136 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 164: loss did not improve from 784624.18750\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 789596.9375 - rmse: 882.5620 - mae: 597.4897 - smape: 90.8800 - coeff_determination: 0.1194\n",
            "Epoch 165/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 775932.5625 - rmse: 879.7303 - mae: 583.8778 - smape: 90.9202 - coeff_determination: 0.1673"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 165: loss did not improve from 784624.18750\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 793702.9375 - rmse: 913.2584 - mae: 592.4396 - smape: 90.7605 - coeff_determination: 0.1459\n",
            "Epoch 166/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 790720.9375 - rmse: 886.4783 - mae: 599.7339 - smape: 90.8191 - coeff_determination: 0.1630"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 166: loss did not improve from 784624.18750\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 795944.6250 - rmse: 897.3417 - mae: 600.5289 - smape: 90.8355 - coeff_determination: 0.1430\n",
            "Epoch 167/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 806051.9375 - rmse: 894.9344 - mae: 588.2582 - smape: 91.1231 - coeff_determination: 0.1558"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 167: loss did not improve from 784624.18750\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 794841.3125 - rmse: 871.3198 - mae: 586.6881 - smape: 91.0221 - coeff_determination: 0.1602\n",
            "Epoch 168/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 809795.0000 - rmse: 896.5375 - mae: 599.3243 - smape: 90.7512 - coeff_determination: 0.1605  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 168: loss did not improve from 784624.18750\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 795885.1250 - rmse: 866.6943 - mae: 591.9238 - smape: 90.9569 - coeff_determination: 0.1455\n",
            "Epoch 169/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 812598.4375 - rmse: 899.3374 - mae: 591.8095 - smape: 90.4449 - coeff_determination: 0.1710"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 169: loss did not improve from 784624.18750\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 793274.8125 - rmse: 855.6294 - mae: 584.0959 - smape: 90.9205 - coeff_determination: -0.0306\n",
            "Epoch 170/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 801330.6250 - rmse: 892.5049 - mae: 595.4084 - smape: 90.4704 - coeff_determination: 0.1567"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 170: loss improved from 784624.18750 to 783508.87500, saving model to checkpoint/Transformer.best20032023_08:09:13.hdf5\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 783508.8750 - rmse: 852.4743 - mae: 586.4271 - smape: 90.6589 - coeff_determination: 0.1693\n",
            "Epoch 171/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 761674.5000 - rmse: 871.6587 - mae: 579.6503 - smape: 90.7731 - coeff_determination: 0.1687"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 171: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 801277.7500 - rmse: 940.4050 - mae: 595.6978 - smape: 90.7698 - coeff_determination: 0.1093\n",
            "Epoch 172/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 799836.3750 - rmse: 891.3279 - mae: 590.7075 - smape: 90.8051 - coeff_determination: 0.1267"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 172: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 808483.8125 - rmse: 908.6198 - mae: 594.8018 - smape: 90.9176 - coeff_determination: 0.1282\n",
            "Epoch 173/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 818047.1250 - rmse: 897.2919 - mae: 595.1715 - smape: 91.1887 - coeff_determination: 0.1438"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 173: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 811088.6250 - rmse: 884.2463 - mae: 594.2920 - smape: 91.0260 - coeff_determination: 0.1596\n",
            "Epoch 174/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 803591.2500 - rmse: 892.4679 - mae: 590.4857 - smape: 90.7851 - coeff_determination: 0.1502"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 174: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 790991.2500 - rmse: 865.7572 - mae: 586.9814 - smape: 91.0003 - coeff_determination: 0.1288\n",
            "Epoch 175/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 791599.8750 - rmse: 887.6816 - mae: 581.8621 - smape: 90.9737 - coeff_determination: 0.1525"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 175: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 795135.8750 - rmse: 895.1301 - mae: 583.8657 - smape: 90.9297 - coeff_determination: 0.1519\n",
            "Epoch 176/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 812885.1875 - rmse: 900.0632 - mae: 592.8064 - smape: 91.5131 - coeff_determination: 0.1293"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 176: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 820415.3125 - rmse: 914.8765 - mae: 599.3282 - smape: 91.2848 - coeff_determination: 0.0992\n",
            "Epoch 177/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 818104.0000 - rmse: 898.5136 - mae: 591.2734 - smape: 91.6467 - coeff_determination: 0.1333"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 177: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 819362.5625 - rmse: 902.2057 - mae: 591.5226 - smape: 91.2108 - coeff_determination: 0.1446\n",
            "Epoch 178/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 826395.8750 - rmse: 908.0447 - mae: 594.9841 - smape: 91.0341 - coeff_determination: 0.1457"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 178: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 804367.9375 - rmse: 857.3441 - mae: 588.6026 - smape: 91.1663 - coeff_determination: 0.0953\n",
            "Epoch 179/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 817641.7500 - rmse: 904.0197 - mae: 592.6920 - smape: 91.2211 - coeff_determination: 0.1469"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 179: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 797567.1875 - rmse: 858.1173 - mae: 585.1123 - smape: 91.1951 - coeff_determination: 0.1922\n",
            "Epoch 180/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 799600.3750 - rmse: 893.0943 - mae: 587.8375 - smape: 91.3224 - coeff_determination: 0.1408"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 180: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 806339.3750 - rmse: 906.4495 - mae: 590.0837 - smape: 91.1443 - coeff_determination: 0.1652\n",
            "Epoch 181/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 818702.2500 - rmse: 902.0844 - mae: 596.1081 - smape: 90.7657 - coeff_determination: 0.1506"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 181: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 798159.6875 - rmse: 855.4684 - mae: 588.5738 - smape: 90.9269 - coeff_determination: 0.1189\n",
            "Epoch 182/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 808862.2500 - rmse: 889.0775 - mae: 594.2694 - smape: 90.7000 - coeff_determination: 0.1478"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 182: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 802783.3750 - rmse: 878.4788 - mae: 587.3175 - smape: 91.1062 - coeff_determination: 0.1190\n",
            "Epoch 183/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 788032.1875 - rmse: 882.7153 - mae: 585.4259 - smape: 91.0593 - coeff_determination: 0.1625"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 183: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 810794.4375 - rmse: 925.1946 - mae: 592.0710 - smape: 91.1447 - coeff_determination: 0.0980\n",
            "Epoch 184/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 806361.8125 - rmse: 896.8762 - mae: 583.9777 - smape: 91.0142 - coeff_determination: 0.1665"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 184: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 815897.3125 - rmse: 915.3530 - mae: 592.6390 - smape: 91.1516 - coeff_determination: 0.0199\n",
            "Epoch 185/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 806168.5000 - rmse: 892.4962 - mae: 586.6304 - smape: 90.7624 - coeff_determination: 0.1539  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 185: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 789416.0000 - rmse: 855.9135 - mae: 579.8806 - smape: 91.0713 - coeff_determination: 0.1133\n",
            "Epoch 186/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 799585.2500 - rmse: 891.9655 - mae: 588.1247 - smape: 91.5711 - coeff_determination: 0.1518"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 186: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 791827.3750 - rmse: 875.9825 - mae: 588.3019 - smape: 91.1026 - coeff_determination: 0.1898\n",
            "Epoch 187/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 790844.0000 - rmse: 885.5529 - mae: 582.6396 - smape: 91.1404 - coeff_determination: 0.1522"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 187: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 792748.7500 - rmse: 890.1296 - mae: 586.6720 - smape: 90.8590 - coeff_determination: 0.1845\n",
            "Epoch 188/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 807920.0000 - rmse: 897.5781 - mae: 580.3868 - smape: 90.6651 - coeff_determination: 0.1756"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 188: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 792364.8125 - rmse: 863.2368 - mae: 577.2438 - smape: 91.0420 - coeff_determination: 0.0024\n",
            "Epoch 189/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 824442.1875 - rmse: 906.1816 - mae: 591.2567 - smape: 91.7065 - coeff_determination: 0.1318 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 189: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 815051.1875 - rmse: 886.7819 - mae: 590.2883 - smape: 91.3980 - coeff_determination: 0.1541\n",
            "Epoch 190/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 833881.1250 - rmse: 911.6678 - mae: 598.8975 - smape: 91.1510 - coeff_determination: 0.1451"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 190: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 807218.0625 - rmse: 848.0219 - mae: 588.8547 - smape: 91.2237 - coeff_determination: 0.1666\n",
            "Epoch 191/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 809763.0000 - rmse: 899.3503 - mae: 586.3300 - smape: 91.3552 - coeff_determination: 0.1455"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 191: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 808817.0000 - rmse: 897.5446 - mae: 585.8607 - smape: 91.4345 - coeff_determination: 0.1288\n",
            "Epoch 192/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 789292.5625 - rmse: 887.5136 - mae: 575.5189 - smape: 91.7062 - coeff_determination: 0.1322"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 192: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 801857.4375 - rmse: 911.6341 - mae: 584.3482 - smape: 91.1215 - coeff_determination: 0.1570\n",
            "Epoch 193/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 829665.0000 - rmse: 904.1194 - mae: 595.8210 - smape: 91.2344 - coeff_determination: 0.1412"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 193: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 815862.0000 - rmse: 875.6491 - mae: 589.4003 - smape: 91.3997 - coeff_determination: 0.1477\n",
            "Epoch 194/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 838207.1250 - rmse: 913.0126 - mae: 594.0159 - smape: 91.1579 - coeff_determination: 0.1088"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 194: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 829728.4375 - rmse: 895.9426 - mae: 592.2155 - smape: 91.2603 - coeff_determination: 0.0969\n",
            "Epoch 195/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 839736.0000 - rmse: 910.0678 - mae: 601.8773 - smape: 90.6679 - coeff_determination: 0.1337  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 195: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 815959.0625 - rmse: 856.1428 - mae: 591.1750 - smape: 91.0637 - coeff_determination: 0.1088\n",
            "Epoch 196/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 797892.1250 - rmse: 892.0780 - mae: 587.8369 - smape: 90.5378 - coeff_determination: 0.1685"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 196: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 784513.9375 - rmse: 862.8192 - mae: 581.3567 - smape: 90.8593 - coeff_determination: 0.1330\n",
            "Epoch 197/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 812298.8125 - rmse: 894.3309 - mae: 593.6631 - smape: 90.7915 - coeff_determination: 0.1408"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 197: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 798121.6875 - rmse: 864.6178 - mae: 587.9443 - smape: 90.8559 - coeff_determination: 0.1594\n",
            "Epoch 198/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 767500.4375 - rmse: 875.3344 - mae: 576.6671 - smape: 90.8154 - coeff_determination: 0.1642"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 198: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 792832.8125 - rmse: 921.6425 - mae: 586.0428 - smape: 90.7710 - coeff_determination: 0.1456\n",
            "Epoch 199/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 773409.8125 - rmse: 875.9854 - mae: 572.1400 - smape: 91.3279 - coeff_determination: 0.1326"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 199: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 806126.7500 - rmse: 934.4115 - mae: 587.5839 - smape: 90.7065 - coeff_determination: 0.1221\n",
            "Epoch 200/200\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 782716.5000 - rmse: 883.3501 - mae: 583.4291 - smape: 90.8099 - coeff_determination: 0.1579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 200: loss did not improve from 783508.87500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 790637.0625 - rmse: 899.1185 - mae: 585.0224 - smape: 90.5396 - coeff_determination: 0.1663\n",
            "3/3 [==============================] - 1s 13ms/step\n",
            "3/3 [==============================] - 1s 11ms/step - loss: 454534.6250 - rmse: 622.9648 - mae: 431.4471 - smape: 98.5603 - coeff_determination: -0.0405\n",
            "Result \n",
            " RMSE = 622.96 [kWh] \n",
            " MAE = 431.45 [kWh]\n",
            " R2 = -4.2 [%]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "SVoLINF2A91-"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}